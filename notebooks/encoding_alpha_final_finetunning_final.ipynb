{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ycl7JuL0anp",
    "outputId": "3cc20ae6-1f7d-4dff-d5e5-6776b863068a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.7/23.7 MB\u001B[0m \u001B[31m62.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m823.6/823.6 kB\u001B[0m \u001B[31m43.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.1/14.1 MB\u001B[0m \u001B[31m68.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m731.7/731.7 MB\u001B[0m \u001B[31m1.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m410.6/410.6 MB\u001B[0m \u001B[31m2.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m121.6/121.6 MB\u001B[0m \u001B[31m13.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.5/56.5 MB\u001B[0m \u001B[31m28.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m124.2/124.2 MB\u001B[0m \u001B[31m12.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m196.0/196.0 MB\u001B[0m \u001B[31m8.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m166.0/166.0 MB\u001B[0m \u001B[31m5.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.1/99.1 kB\u001B[0m \u001B[31m13.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.1/21.1 MB\u001B[0m \u001B[31m58.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n",
      "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
      "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
      "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m290.1/290.1 kB\u001B[0m \u001B[31m6.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.99)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.28.0\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.99)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "#FT1 Installing libraries\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install transformers[torch]\n",
    "!pip install accelerate -U\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D7QOX6cO-wJJ",
    "outputId": "5af9478d-52cd-424d-b1b3-47f28285ca2a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjKToYfc6adY",
    "outputId": "49417e59-12d5-4b13-ac54-9ae214abc692"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wt3T2YTB0ans",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269,
     "referenced_widgets": [
      "e80ff28fa61c4bf7b66e9f933f883459",
      "2e35b3521ef2456796fe6fb2c2563dd4",
      "e9b86d98944a4158ac5e325b9bce29d8",
      "630c3ad086f0450990871c2354adfe59",
      "88734b83019743bcb0825339c7a88b23",
      "462282c30abe4d13ba07fcc2b614e858",
      "3ea8a68984e74c99a4667022575b0bcb",
      "bcf451f4418f4057a8a257fa63f9f19f",
      "5264108c2c894e84b1a17e3f24e128a2",
      "fa6eb28c0004448ca9d57ddfe77592e8",
      "c2afb96ddf7a46b687b5663120d7d2d8",
      "becf2cd329f54f69a39e0e934e0dee52",
      "40b06ec082c24feba9332763b23c3a3b",
      "b37c23a49ca24774b520f1e926ad5fdd",
      "06c69fd05e6b4219a11d16020fb5793b",
      "0e9f8e8f8f8c443c9b42ec21f85951ce",
      "3227256403f441ebbbd36f4e0d67298b",
      "97b8d3640af949b2bdc54ac0d3541020",
      "d841380aadf946e9a9fe38298c13b15a",
      "d1912f4124fc41e2950dbbd9b6ad2c70",
      "08ffe43f797949f3b0bf526af2e1224a",
      "9625d3e8f4034e09842f0e476424affd",
      "11a44798da12452da205bdbf8b49b5f7",
      "a5e6aa5ff3264e858c2a9650f0b62038",
      "28122700c83e40cc8cdd49f0a4576afe",
      "2c9b838e2d9f48d88ab18924ab688e39",
      "c9d5753fee8543bd9cba6892f7ebdea8",
      "b37e461910b14693bd9f11d5c9cd7b12",
      "c29078f6ec5e4cd4a287c049e9bccf6f",
      "2b1759174eec433ebc5e002fd53cf862",
      "73ff3cfd5ab245a09cf9215769234a55",
      "a9192c824bad4e4781a6a7e68adfc1b4",
      "81d6213433ff4faeaaa9622dd45250ac",
      "ca16fc679af04321ac5a62a5dbd951c7",
      "70f7d810a2d1459e96de7cf70d3a5bbf",
      "81840a7dd7bd4a14bce6a0a23747711b",
      "df44cf854f3a4e72bbae4392ac91680a",
      "2666a47bc9624d89a4a50e389c018001",
      "256c82d6dba946429e497310eba68872",
      "51697330d6d9456c8ab0d827150aac8c",
      "df2df5bb2d8c4481921ba093fd799cac",
      "9b31888981d5443187ba5e68f61e2eee",
      "e55056d3cabc4affa674336320d62e6c",
      "f620efe782c34c80844a244ab03bc28d"
     ]
    },
    "outputId": "4af0e386-e44b-47b5-a3dd-d0eae68a681c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e80ff28fa61c4bf7b66e9f933f883459"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "becf2cd329f54f69a39e0e934e0dee52"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11a44798da12452da205bdbf8b49b5f7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca16fc679af04321ac5a62a5dbd951c7"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "#FT2: Importing Bert libraries\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lASrrK4Z6msI",
    "outputId": "c4dec67f-aa11-4ab3-8a8e-7a5534302f72"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                              name      type  price  \\\n",
      "0                Duracell - AAA Batteries (4-Pack)  HardGood   5.49   \n",
      "1  Duracell - AA 1.5V CopperTop Batteries (4-Pack)  HardGood   5.49   \n",
      "2                 Duracell - AA Batteries (8-Pack)  HardGood   7.49   \n",
      "3            Energizer - MAX Batteries AA (4-Pack)  HardGood   4.99   \n",
      "4                  Duracell - C Batteries (4-Pack)  HardGood   8.99   \n",
      "\n",
      "                                         description manufacturer  \\\n",
      "0  Compatible with select electronic devices; AAA...     Duracell   \n",
      "1  Long-lasting energy; DURALOCK Power Preserve t...     Duracell   \n",
      "2  Compatible with select electronic devices; AA ...     Duracell   \n",
      "3  4-pack AA alkaline batteries; battery tester i...    Energizer   \n",
      "4  Compatible with select electronic devices; C s...     Duracell   \n",
      "\n",
      "                                           url              parent_category  \\\n",
      "0                duracell aaa batteries 4 pack  Connected Home & Housewares   \n",
      "1  duracell aa 1 5v coppertop batteries 4 pack  Connected Home & Housewares   \n",
      "2                 duracell aa batteries 8 pack  Connected Home & Housewares   \n",
      "3            energizer max batteries aa 4 pack  Connected Home & Housewares   \n",
      "4                  duracell c batteries 4 pack  Connected Home & Housewares   \n",
      "\n",
      "  sub_category_1        sub_category_2       sub_category_3 sub_category_4  \n",
      "0     Housewares   Household Batteries   Alkaline Batteries        missing  \n",
      "1     Housewares   Household Batteries   Alkaline Batteries        missing  \n",
      "2     Housewares   Household Batteries   Alkaline Batteries        missing  \n",
      "3     Housewares   Household Batteries   Alkaline Batteries        missing  \n",
      "4     Housewares   Household Batteries   Alkaline Batteries        missing  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50041 entries, 0 to 50040\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   name             50040 non-null  object \n",
      " 1   type             50041 non-null  object \n",
      " 2   price            50041 non-null  float64\n",
      " 3   description      50041 non-null  object \n",
      " 4   manufacturer     50041 non-null  object \n",
      " 5   url              50040 non-null  object \n",
      " 6   parent_category  50041 non-null  object \n",
      " 7   sub_category_1   50041 non-null  object \n",
      " 8   sub_category_2   50041 non-null  object \n",
      " 9   sub_category_3   50041 non-null  object \n",
      " 10  sub_category_4   50041 non-null  object \n",
      "dtypes: float64(1), object(10)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "file_path = '/content/drive/MyDrive/anyone_final_project/alpha2_dataset_cleaned.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.fillna(pd.NA)\n",
    "df['type'] = df['type'].fillna('missing')\n",
    "df['manufacturer'] = df['manufacturer'].fillna('missing')\n",
    "df['sub_category_1'] = df['sub_category_1'].fillna('missing')\n",
    "df['sub_category_2'] = df['sub_category_2'].fillna('missing')\n",
    "df['sub_category_3'] = df['sub_category_3'].fillna('missing')\n",
    "df['sub_category_4'] = df['sub_category_4'].fillna('missing')\n",
    "\n",
    "print(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OUzBSTQi6p8v"
   },
   "outputs": [],
   "source": [
    "# stemmer, lemmatizer and stopwords\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from typing import Optional\n",
    "\n",
    "# Initialize NLTK resources\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return 'a'  # Adjective\n",
    "    elif tag.startswith('V'):\n",
    "        return 'v'  # Verb\n",
    "    elif tag.startswith('N'):\n",
    "        return 'n'  # Noun\n",
    "    elif tag.startswith('R'):\n",
    "        return 'r'  # Adverb\n",
    "    else:\n",
    "        return 'n'  # Default to noun if not recognized\n",
    "\n",
    "def remove_extra_new_lines(text):\n",
    "\n",
    "    if pd.isnull(text):  # check if text is nan\n",
    "        return ''  # replace with an empty string\n",
    "\n",
    "    clean_text = [i for i in str(text).splitlines() if i.strip()]\n",
    "    clean_text = ' '.join(clean_text)\n",
    "    return clean_text\n",
    "\n",
    "def remove_extra_whitespace(text: str) -> str:\n",
    "\n",
    "    spaceless_text = re.sub(r'\\s+', ' ', text)\n",
    "    return spaceless_text\n",
    "\n",
    "def remove_special_chars(text: str, remove_digits: Optional[bool] = False) -> str:\n",
    "\n",
    "    if remove_digits:\n",
    "        pattern = r'[^a-zA-Z\\s]'\n",
    "    else:\n",
    "        pattern = r'[^a-zA-Z0-9\\s]'\n",
    "\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def normalize_text(text):\n",
    "\n",
    "    text = remove_extra_new_lines(text)\n",
    "\n",
    "    text = remove_extra_whitespace(text)\n",
    "\n",
    "    text = remove_special_chars(text, remove_digits=False)\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha() and token.lower() not in stop_words]\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    lemmas = [lemmatizer.lemmatize(token, get_wordnet_pos(tag)) for token, tag in tagged_tokens]\n",
    "\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8martjTt6sdd",
    "outputId": "f98427d7-103b-4c75-8231-ac3797bbcc68"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(50041, 13)\n"
     ]
    }
   ],
   "source": [
    "normalization = ['name', 'description']\n",
    "for column in normalization:\n",
    "    df[column + '_normalized'] = df[column].apply(normalize_text)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ryEUvdJ0ant",
    "outputId": "af93ad08-f468-4d99-9a76-eae21e290948"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "name                                      Duracell - AAA Batteries (4-Pack)\n",
      "type                                                               HardGood\n",
      "price                                                                  5.49\n",
      "description               Compatible with select electronic devices; AAA...\n",
      "manufacturer                                                       Duracell\n",
      "url                                           duracell aaa batteries 4 pack\n",
      "parent_category                                 Connected Home & Housewares\n",
      "sub_category_1                                                   Housewares\n",
      "sub_category_2                                          Household Batteries\n",
      "sub_category_3                                           Alkaline Batteries\n",
      "sub_category_4                                                      missing\n",
      "name_normalized                                        duracell aaa battery\n",
      "description_normalized    compatible select electronic device aaa size d...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYTfY_RArpEX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "73cbce89-1574-46a2-c417-43f20ca18c90"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Connected Home & Housewares' 'other' 'Car Electronics & GPS'\n",
      " 'In-Store Only' 'Musical Instruments' 'Toys' 'Video Games'\n",
      " 'Cameras & Camcorders' 'Computers & Tablets' 'Appliances' 'Audio'\n",
      " 'TV & Home Theater' 'Health' 'Name Brands' 'Cell Phones' 'Movies & Music'\n",
      " 'Magnolia Home Theater' 'Geek Squad' 'Best Buy Gift Cards'\n",
      " 'H/VG_X360/Games/B2G1_20130602' 'MP Exclusives' 'Wearable Technology'\n",
      " 'Custom Parts']\n"
     ]
    }
   ],
   "source": [
    "#df['sub_category_1'].fillna('0', inplace=True)\n",
    "#df['sub_category_2'].fillna('0', inplace=True)\n",
    "#df['sub_category_3'].fillna('0', inplace=True)\n",
    "#df['sub_category_4'].fillna('0', inplace=True)\n",
    "print(df['parent_category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33iKb2Pl0anu"
   },
   "outputs": [],
   "source": [
    "#FT3: Creation of the Dataset Class for BERT\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class AlphaDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uwLSa6uB6upR",
    "outputId": "23047cc9-30a2-41e6-e711-6247121dd202"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                              name      type  price  \\\n",
      "0                Duracell - AAA Batteries (4-Pack)  HardGood   5.49   \n",
      "1  Duracell - AA 1.5V CopperTop Batteries (4-Pack)  HardGood   5.49   \n",
      "2                 Duracell - AA Batteries (8-Pack)  HardGood   7.49   \n",
      "3            Energizer - MAX Batteries AA (4-Pack)  HardGood   4.99   \n",
      "4                  Duracell - C Batteries (4-Pack)  HardGood   8.99   \n",
      "\n",
      "                                         description manufacturer  \\\n",
      "0  Compatible with select electronic devices; AAA...     Duracell   \n",
      "1  Long-lasting energy; DURALOCK Power Preserve t...     Duracell   \n",
      "2  Compatible with select electronic devices; AA ...     Duracell   \n",
      "3  4-pack AA alkaline batteries; battery tester i...    Energizer   \n",
      "4  Compatible with select electronic devices; C s...     Duracell   \n",
      "\n",
      "                                           url              parent_category  \\\n",
      "0                duracell aaa batteries 4 pack  Connected Home & Housewares   \n",
      "1  duracell aa 1 5v coppertop batteries 4 pack  Connected Home & Housewares   \n",
      "2                 duracell aa batteries 8 pack  Connected Home & Housewares   \n",
      "3            energizer max batteries aa 4 pack  Connected Home & Housewares   \n",
      "4                  duracell c batteries 4 pack  Connected Home & Housewares   \n",
      "\n",
      "  sub_category_1        sub_category_2       sub_category_3 sub_category_4  \\\n",
      "0     Housewares   Household Batteries   Alkaline Batteries        missing   \n",
      "1     Housewares   Household Batteries   Alkaline Batteries        missing   \n",
      "2     Housewares   Household Batteries   Alkaline Batteries        missing   \n",
      "3     Housewares   Household Batteries   Alkaline Batteries        missing   \n",
      "4     Housewares   Household Batteries   Alkaline Batteries        missing   \n",
      "\n",
      "                 name_normalized  \\\n",
      "0           duracell aaa battery   \n",
      "1  duracell aa coppertop battery   \n",
      "2            duracell aa battery   \n",
      "3       energizer max battery aa   \n",
      "4             duracell c battery   \n",
      "\n",
      "                              description_normalized  \n",
      "0  compatible select electronic device aaa size d...  \n",
      "1  longlasting energy duralock power preserve tec...  \n",
      "2  compatible select electronic device aa size du...  \n",
      "3         aa alkaline battery battery tester include  \n",
      "4  compatible select electronic device c size dur...  \n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "print(df.head())\n",
    "df.shape\n",
    "X = df.drop(columns=['parent_category'])\n",
    "y = df['parent_category']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "with h5py.File('label_encoder.h5', 'w') as hf:\n",
    "    hf.create_dataset('label_encoder', data=label_encoder.classes_)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTKP9HOa0anv"
   },
   "outputs": [],
   "source": [
    "# FT4: Combining 'name' and 'description' columns into a new 'combined_text' column\n",
    "X_train['combined_text'] = X_train['name'].fillna('') + \" \" + X_train['description'].fillna('')\n",
    "X_test['combined_text'] = X_test['name'].fillna('') + \" \" + X_test['description'].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "woBvshjI-gHS"
   },
   "outputs": [],
   "source": [
    "df.shape\n",
    "\n",
    "X_1 = df.drop(columns=['sub_category_1'])\n",
    "y_1 = df['sub_category_1']\n",
    "y_1.fillna('missing', inplace=True)\n",
    "\n",
    "label_encoder_1 = LabelEncoder()\n",
    "y_1_encoded = label_encoder_1.fit_transform(y_1)\n",
    "\n",
    "with h5py.File('label_encoder_1.h5', 'w') as hf:\n",
    "    hf.create_dataset('label_encoder_1', data=label_encoder_1.classes_)\n",
    "\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, y_1_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wYMN3-Aj-f-n"
   },
   "outputs": [],
   "source": [
    "df.shape\n",
    "X_2 = df.drop(columns=['sub_category_2'])\n",
    "y_2 = df['sub_category_2']\n",
    "y_2.fillna('missing', inplace=True)\n",
    "label_encoder_2 = LabelEncoder()\n",
    "y_2_encoded = label_encoder_2.fit_transform(y_2)\n",
    "\n",
    "with h5py.File('label_encoder_2.h5', 'w') as hf:\n",
    "    hf.create_dataset('label_encoder_2', data=label_encoder_2.classes_)\n",
    "\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLrnJPS1-f3n"
   },
   "outputs": [],
   "source": [
    "df.shape\n",
    "X_3 = df.drop(columns=['sub_category_3'])\n",
    "y_3 = df['sub_category_3']\n",
    "y_3.fillna('missing', inplace=True)\n",
    "\n",
    "label_encoder_3 = LabelEncoder()\n",
    "y_3_encoded = label_encoder_3.fit_transform(y_3)\n",
    "\n",
    "with h5py.File('label_encoder_3.h5', 'w') as hf:\n",
    "    hf.create_dataset('label_encoder_3', data=label_encoder_3.classes_)\n",
    "\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_3, y_3_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmO58b37-foH"
   },
   "outputs": [],
   "source": [
    "df.shape\n",
    "X_4 = df.drop(columns=['sub_category_4'])\n",
    "y_4 = df['sub_category_4']\n",
    "y_4.fillna('missing', inplace=True)\n",
    "\n",
    "label_encoder_4 = LabelEncoder()\n",
    "y_4_encoded = label_encoder_4.fit_transform(y_4)\n",
    "\n",
    "with h5py.File('label_encoder_4.h5', 'w') as hf:\n",
    "    hf.create_dataset('label_encoder_4', data=label_encoder_4.classes_)\n",
    "\n",
    "X_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(X_4, y_4_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XxJvoJcBsGfp",
    "outputId": "a2711606-6d2b-4ab4-9096-9822bb4eb6ab"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                              name      type  price  \\\n",
      "0                Duracell - AAA Batteries (4-Pack)  HardGood   5.49   \n",
      "1  Duracell - AA 1.5V CopperTop Batteries (4-Pack)  HardGood   5.49   \n",
      "2                 Duracell - AA Batteries (8-Pack)  HardGood   7.49   \n",
      "3            Energizer - MAX Batteries AA (4-Pack)  HardGood   4.99   \n",
      "4                  Duracell - C Batteries (4-Pack)  HardGood   8.99   \n",
      "\n",
      "                                         description manufacturer  \\\n",
      "0  Compatible with select electronic devices; AAA...     Duracell   \n",
      "1  Long-lasting energy; DURALOCK Power Preserve t...     Duracell   \n",
      "2  Compatible with select electronic devices; AA ...     Duracell   \n",
      "3  4-pack AA alkaline batteries; battery tester i...    Energizer   \n",
      "4  Compatible with select electronic devices; C s...     Duracell   \n",
      "\n",
      "                                           url              parent_category  \\\n",
      "0                duracell aaa batteries 4 pack  Connected Home & Housewares   \n",
      "1  duracell aa 1 5v coppertop batteries 4 pack  Connected Home & Housewares   \n",
      "2                 duracell aa batteries 8 pack  Connected Home & Housewares   \n",
      "3            energizer max batteries aa 4 pack  Connected Home & Housewares   \n",
      "4                  duracell c batteries 4 pack  Connected Home & Housewares   \n",
      "\n",
      "  sub_category_1        sub_category_2       sub_category_3  \\\n",
      "0     Housewares   Household Batteries   Alkaline Batteries   \n",
      "1     Housewares   Household Batteries   Alkaline Batteries   \n",
      "2     Housewares   Household Batteries   Alkaline Batteries   \n",
      "3     Housewares   Household Batteries   Alkaline Batteries   \n",
      "4     Housewares   Household Batteries   Alkaline Batteries   \n",
      "\n",
      "                 name_normalized  \\\n",
      "0           duracell aaa battery   \n",
      "1  duracell aa coppertop battery   \n",
      "2            duracell aa battery   \n",
      "3       energizer max battery aa   \n",
      "4             duracell c battery   \n",
      "\n",
      "                              description_normalized  \n",
      "0  compatible select electronic device aaa size d...  \n",
      "1  longlasting energy duralock power preserve tec...  \n",
      "2  compatible select electronic device aa size du...  \n",
      "3         aa alkaline battery battery tester include  \n",
      "4  compatible select electronic device c size dur...  \n"
     ]
    }
   ],
   "source": [
    "print(X_4.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N_ArCp4U6xB_",
    "outputId": "de309e28-daa6-4fce-b775-a340a6d0e3cf"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(40032, 13)\n",
      "(10009, 13)\n",
      "(40032,)\n",
      "(10009,)\n",
      "9233                            star fox preowned nintendo\n",
      "25631    pioneer networkready ultra hd passthrough av h...\n",
      "19030                     evolve ultimate edition xbox one\n",
      "12044    joby pro series ultraplate quickrelease plate ...\n",
      "18967    aluratek bump w home audio speaker system ipod...\n",
      "                               ...                        \n",
      "11284    samsung class diag lead curved smart ultra hd ...\n",
      "44732    hifonics brutus class mono mosfet subwoofer am...\n",
      "38158    mobile edge premium laptop backpack apple macb...\n",
      "860                                 presonus presonus gray\n",
      "15795      insignia portable bluetooth stereo speaker blue\n",
      "Name: name_normalized, Length: 40032, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print( X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train['name_normalized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfXktfLf6y1M",
    "outputId": "f7d437db-701b-4375-cfe3-e69472dee4d2"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([20,  1, 20, ...,  6, 16,  1])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRwGwPFj0anw"
   },
   "outputs": [],
   "source": [
    "# FT5: Tokenization of training and test data using the 'combined_text' column\n",
    "train_encodings = tokenizer(X_train['combined_text'].tolist(), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(X_test['combined_text'].tolist(), truncation=True, padding=True)\n",
    "\n",
    "# Creation of training and test datasets\n",
    "train_dataset = AlphaDataset(train_encodings, y_train)\n",
    "test_dataset = AlphaDataset(test_encodings, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160,
     "referenced_widgets": [
      "19e710cd65dd42f6b6e9cad415a95543",
      "b33fb027db2049f582d01999b6e781f6",
      "0a8dc7b85690495ca5d606d0041f5df2",
      "7148937877b846c4a41b3bc2008357b4",
      "54326cdb44f54ae0807d93c9ee81199c",
      "78acdd4bd63d4094a805d498cba90e7c",
      "38623c1beb744dbca6b7293a188ce2c2",
      "4e848d2663c74e1db983e16f8ca14a29",
      "6788ea4f28ad4b2580679f26ec449750",
      "44f00a5c78ee4171bdfa0492d05fd127",
      "ab4a681379364c80b8d6b9d901b382c3"
     ]
    },
    "id": "SQmlx6sx0anx",
    "outputId": "14024d4e-a60a-448d-90a3-4af198966813"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19e710cd65dd42f6b6e9cad415a95543"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# FT6: Loading the BERT Model and Configuring Training\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted')\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    class_report = classification_report(labels, preds)\n",
    "    conf_matrix = confusion_matrix(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'classification_report': class_report,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "# Loading the pre-trained BERT model for the classification task\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',  # Use the pre-trained base BERT model\n",
    "    num_labels=len(np.unique(y_encoded))  # Number of labels for classification\n",
    ")\n",
    "\n",
    "# Setting up training parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',            # Directory to save training results\n",
    "    num_train_epochs=5,                # Total number of training epochs\n",
    "    per_device_train_batch_size=8,     # Batch size for training\n",
    "    per_device_eval_batch_size=8,      # Batch size for evaluation\n",
    "    warmup_steps=500,                  # Number of warm-up steps to adjust the learning rate\n",
    "    weight_decay=0.01,                 # Weight decay for regularization\n",
    "    logging_dir='./logs',              # Directory to save logs\n",
    "    evaluation_strategy=\"epoch\"        # Evaluation strategy (can be \"no\", \"steps\", or \"epoch\")\n",
    ")\n",
    "\n",
    "# # Creating a Trainer instance, which will be used to train and evaluate the BERT model\n",
    "trainer = Trainer(\n",
    "    model=model,                      # The BERT model to be trained\n",
    "    args=training_args,               # The training arguments\n",
    "    train_dataset=train_dataset,      # Training dataset\n",
    "    eval_dataset=test_dataset,        # Evaluation dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "Mmf4hZOo0anx",
    "outputId": "fcb38ccb-dee6-4d0d-e375-26dd47dc3b2b"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25020' max='25020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25020/25020 39:47, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.308200</td>\n",
       "      <td>0.304190</td>\n",
       "      <td>0.949645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>0.253794</td>\n",
       "      <td>0.959636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.157700</td>\n",
       "      <td>0.220584</td>\n",
       "      <td>0.963932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.223278</td>\n",
       "      <td>0.967429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.208391</td>\n",
       "      <td>0.969527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=25020, training_loss=0.20577802450465355, metrics={'train_runtime': 2388.6478, 'train_samples_per_second': 83.796, 'train_steps_per_second': 10.475, 'total_flos': 1.460887089611328e+16, 'train_loss': 0.20577802450465355, 'epoch': 5.0})"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# FT7: Training (Fine-Tuning) the BERT Model\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9sYDM9T0anx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0ac30f94-ed76-476d-bac3-049d969f1f97"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('/content/model_finetuned/tokenizer_config.json',\n",
       " '/content/model_finetuned/special_tokens_map.json',\n",
       " '/content/model_finetuned/vocab.txt',\n",
       " '/content/model_finetuned/added_tokens.json')"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# FT8: Saving the model manually after training\n",
    "# Especifica la ruta donde deseas guardar el modelo\n",
    "model_path = \"/content/model_finetuned\"\n",
    "\n",
    "# Guarda el modelo\n",
    "model.save_pretrained(model_path)\n",
    "\n",
    "# Nota: También puedes guardar el Tokenizador si es necesario\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "evaluation_results = trainer.evaluate()\n",
    "\n",
    "# Print evaluation results\n",
    "print(\"Evaluation results:\", evaluation_results)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "BIMpSnj9ksQH",
    "outputId": "aac09166-9f0c-43ed-f5e3-72dbec52772e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-152-80a3890080f2>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mevaluation_results\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m# Print evaluation results\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Evaluation results:\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevaluation_results\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'trainer' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#Prediccion 0\n",
    "text = {\n",
    "    \"name\": \"Trumpet Multimedia - Trumpets That Work 2015 Calendar - Black\",\n",
    "    \"description\": \"TRUMPET MULTIMEDIA Trumpets That Work 2015 Calendar: 2015 calendar; Trumpets That Work design\",\n",
    "    \"price\": 23.95,\n",
    "    \"type\": \"HardGood\",\n",
    "    \"manufacturer\": \"Trumpet Multimedia\",\n",
    "}\n",
    "\n",
    "text['name'] = normalize_text(text['name'])\n",
    "text['description'] = normalize_text(text['description'])\n",
    "text['combined_text'] = text['name'] + \" \" + text['description']\n",
    "\n",
    "model_path = '/content/drive/MyDrive/anyone_final_project/finetunning_1'\n",
    "\n",
    "# Cargar el tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Cargar el modelo\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "def predict(text):\n",
    "    # Preparar los tokens de entrada\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "    # Hacer predicción\n",
    "    model.eval()  # Asegúrate de que el modelo esté en modo evaluación\n",
    "    with torch.no_grad():  # Desactivar la generación de gradientes\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Obtener la predicción de la última capa\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    return predicted_class_id\n"
   ],
   "metadata": {
    "id": "aSM6FSkuSZ7i"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pred = predict(text['combined_text'])\n"
   ],
   "metadata": {
    "id": "-5lgoLYeV-OX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(pred)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aarpo49GXaoh",
    "outputId": "06d4efbd-74b7-4286-9f37-930490024cfb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "19\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "with h5py.File('label_encoder.h5', 'r') as hf:\n",
    "    label_encoder_classes = hf['label_encoder'][:]\n",
    "\n",
    "def compare_predictions(pred, label_encoder_classes):\n",
    "    if 0 <= pred < len(label_encoder_classes):\n",
    "        return label_encoder_classes[pred]\n",
    "    else:\n",
    "        return 'unknown'"
   ],
   "metadata": {
    "id": "6SfDdc-iXkrv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "comp_pred = compare_predictions(pred, label_encoder_classes)\n",
    "print(comp_pred)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sBNyFVhKY_R4",
    "outputId": "416b448e-dae5-424d-b0f8-0d5260a6c51d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b'Toys'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "comp_pred_str = comp_pred.decode(\"utf-8\")\n",
    "print(comp_pred_str)\n",
    "\n",
    "#Aqui termina prediccion 0"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_CjJxR49dw-O",
    "outputId": "33583232-5f95-4966-ce49-61a782e7a18e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Toys\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# model_1 fine tunning bert\n",
    "X_train_1['parent_category'] = X_train_1['parent_category'].apply(normalize_text)\n",
    "X_test_1['parent_category'] = X_test_1['parent_category'].apply(normalize_text)\n",
    "\n",
    "X_train_1['combined_text'] = X_train_1['name'].fillna('') + \" \" + X_train_1['description'].fillna('')+ \" \"+ X_train_1['parent_category']\n",
    "X_test_1['combined_text'] = X_test_1['name'].fillna('') + \" \" + X_test_1['description'].fillna('')+ \" \" + X_test_1['parent_category']"
   ],
   "metadata": {
    "id": "llkbPTGKFcHQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# FT5: Tokenization of training and test data using the 'combined_text' column\n",
    "train_encodings_1 = tokenizer(X_train_1['combined_text'].tolist(), truncation=True, padding=True)\n",
    "test_encodings_1 = tokenizer(X_test_1['combined_text'].tolist(), truncation=True, padding=True)\n",
    "\n",
    "# Creation of training and test datasets\n",
    "train_dataset_1 = AlphaDataset(train_encodings_1, y_train_1)\n",
    "test_dataset_1 = AlphaDataset(test_encodings_1, y_test_1)\n"
   ],
   "metadata": {
    "id": "pfsU4denKpBx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc}\n",
    "\n",
    "# Loading the pre-trained BERT model for the classification task\n",
    "model_1 = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',  # Use the pre-trained base BERT model\n",
    "    num_labels=len(np.unique(y_1_encoded))  # Number of labels for classification\n",
    ")\n",
    "\n",
    "# Setting up training parameters\n",
    "training_args_1 = TrainingArguments(\n",
    "    output_dir='./results',            # Directory to save training results\n",
    "    num_train_epochs=5,                # Total number of training epochs\n",
    "    per_device_train_batch_size=8,     # Batch size for training\n",
    "    per_device_eval_batch_size=8,      # Batch size for evaluation\n",
    "    warmup_steps=500,                  # Number of warm-up steps to adjust the learning rate\n",
    "    weight_decay=0.01,                 # Weight decay for regularization\n",
    "    logging_dir='./logs',              # Directory to save logs\n",
    "    evaluation_strategy=\"epoch\"        # Evaluation strategy (can be \"no\", \"steps\", or \"epoch\")\n",
    ")\n",
    "\n",
    "# # Creating a Trainer instance, which will be used to train and evaluate the BERT model\n",
    "trainer_1 = Trainer(\n",
    "    model=model_1,                      # The BERT model to be trained\n",
    "    args=training_args_1,               # The training arguments\n",
    "    train_dataset=train_dataset_1,      # Training dataset\n",
    "    eval_dataset=test_dataset_1,        # Evaluation dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ADKBzFRRLxLJ",
    "outputId": "c8187bb2-2e4a-4b1f-8ff5-7614d98e7399"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "trainer_1.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "Q2zx32ObNAaC",
    "outputId": "ba04f05a-b953-4c3d-f7eb-aa1203d08855"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25020' max='25020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25020/25020 32:53, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.214900</td>\n",
       "      <td>0.268487</td>\n",
       "      <td>0.938256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.189889</td>\n",
       "      <td>0.959936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.109300</td>\n",
       "      <td>0.186079</td>\n",
       "      <td>0.966031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.091800</td>\n",
       "      <td>0.180614</td>\n",
       "      <td>0.968029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.181010</td>\n",
       "      <td>0.970327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=25020, training_loss=0.23722762163761232, metrics={'train_runtime': 1974.8191, 'train_samples_per_second': 101.356, 'train_steps_per_second': 12.67, 'total_flos': 1.503265851520128e+16, 'train_loss': 0.23722762163761232, 'epoch': 5.0})"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Especifica la ruta donde deseas guardar el modelo\n",
    "model_path = \"/content/drive/MyDrive/anyone_final_project/finetunning_2\"\n",
    "\n",
    "# Guarda el modelo\n",
    "model_1.save_pretrained(model_path)\n",
    "\n",
    "# Nota: También puedes guardar el Tokenizador si es necesario\n",
    "tokenizer.save_pretrained(model_path)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYLHdtmveMxD",
    "outputId": "94eebb78-ec47-46b6-d522-5ffdcc190ea3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('/content/drive/MyDrive/anyone_final_project/finetunning_2/tokenizer_config.json',\n",
       " '/content/drive/MyDrive/anyone_final_project/finetunning_2/special_tokens_map.json',\n",
       " '/content/drive/MyDrive/anyone_final_project/finetunning_2/vocab.txt',\n",
       " '/content/drive/MyDrive/anyone_final_project/finetunning_2/added_tokens.json')"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#Prediccion 1\n",
    "text_1 = {\n",
    "    \"name\": \"Trumpet Multimedia - Trumpets That Work 2015 Calendar - Black\",\n",
    "    \"description\": \"TRUMPET MULTIMEDIA Trumpets That Work 2015 Calendar: 2015 calendar; Trumpets That Work design\",\n",
    "    \"price\": 23.95,\n",
    "    \"type\": \"HardGood\",\n",
    "    \"manufacturer\": \"Trumpet Multimedia\",\n",
    "}\n",
    "\n",
    "text_1['name'] = normalize_text(text_1['name'])\n",
    "text_1['description'] = normalize_text(text_1['description'])\n",
    "comp_pred_str = normalize_text(comp_pred_str)\n",
    "print(comp_pred_str)\n",
    "text_1['combined_text'] = text_1['name'] + \" \" + text_1['description']+ \" \" + comp_pred_str\n",
    "print(text_1)\n",
    "model_1_path = '/content/drive/MyDrive/anyone_final_project/finetunning_2'\n",
    "\n",
    "# Cargar el tokenizer\n",
    "tokenizer_1 = BertTokenizer.from_pretrained(model_1_path)\n",
    "\n",
    "# Cargar el modelo\n",
    "model_1 = BertForSequenceClassification.from_pretrained(model_1_path)\n",
    "\n",
    "\n",
    "def predict_1(text_1):\n",
    "    # Preparar los tokens de entrada\n",
    "    inputs = tokenizer_1(text_1, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "    # Hacer predicción\n",
    "    model_1.eval()  # Asegúrate de que el modelo esté en modo evaluación\n",
    "    with torch.no_grad():  # Desactivar la generación de gradientes\n",
    "        outputs = model_1(**inputs)\n",
    "\n",
    "    # Obtener la predicción de la última capa\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    return predicted_class_id\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KHz0kpvghrUN",
    "outputId": "96f1d529-113a-4c60-b607-83b1826bad78"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "toy\n",
      "{'name': 'trumpet multimedia trumpet work calendar black', 'description': 'trumpet multimedia trumpet work calendar calendar trumpet work design', 'price': 23.95, 'type': 'HardGood', 'manufacturer': 'Trumpet Multimedia', 'combined_text': 'trumpet multimedia trumpet work calendar black trumpet multimedia trumpet work calendar calendar trumpet work design toy'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pred_1 = predict_1(text_1['combined_text'])"
   ],
   "metadata": {
    "id": "2PZn2RHmhrIF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(pred_1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xz-Z-iYSlLc2",
    "outputId": "4edb739a-68e0-487d-c863-c12af417f2f3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "42\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "with h5py.File('label_encoder_1.h5', 'r') as hf:\n",
    "    label_encoder_classes_1 = hf['label_encoder_1'][:]\n",
    "\n",
    "def compare_predictions(pred_1, label_encoder_classes_1):\n",
    "    if 0 <= pred_1 < len(label_encoder_classes_1):\n",
    "        return label_encoder_classes_1[pred_1]\n",
    "    else:\n",
    "        return 'unknown'"
   ],
   "metadata": {
    "id": "CPunlimyhq9G"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "comp_pred_1 = compare_predictions(pred_1, label_encoder_classes_1)\n",
    "print(comp_pred_1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDC0NHxkkyV1",
    "outputId": "289aaacd-669a-4c6e-9c71-5bdb74954fbb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b' Games & Drones'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "comp_pred_str_1 = comp_pred_1.decode(\"utf-8\")\n",
    "print(comp_pred_str_1)\n",
    "\n",
    "#Aqui termina prediccion 1"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9B4Jf9rdkyMe",
    "outputId": "0713a4eb-023c-47a2-b17b-9dd68d86e2d5"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Games & Drones\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# model_2 fine tunning bert\n",
    "X_train_2['parent_category'] = X_train_2['parent_category'].apply(normalize_text)\n",
    "X_test_2['parent_category'] = X_test_2['parent_category'].apply(normalize_text)\n",
    "\n",
    "X_train_2['sub_category_1'] = X_train_2['sub_category_1'].apply(normalize_text)\n",
    "X_test_2['sub_category_1'] = X_test_2['sub_category_1'].apply(normalize_text)\n",
    "\n",
    "\n",
    "X_train_2['combined_text'] = X_train_2['name_normalized'].fillna('') + \" \" + X_train_2['description_normalized'].fillna('') + \" \"+ X_train_2['parent_category'] + \" \"+ X_train_2['sub_category_1']\n",
    "X_test_2['combined_text'] = X_test_2['name_normalized'].fillna('') + \" \" + X_test_2['description_normalized'].fillna('') + \" \" + X_test_2['parent_category'] + \" \"+ X_test_2['sub_category_1']"
   ],
   "metadata": {
    "id": "6ZHfgCAisQhI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Tokenization model_2\n",
    "train_encodings_2 = tokenizer(X_train_2['combined_text'].tolist(), truncation=True, padding=True)\n",
    "test_encodings_2 = tokenizer(X_test_2['combined_text'].tolist(), truncation=True, padding=True)\n",
    "\n",
    "# Creation of training and test datasets\n",
    "train_dataset_2 = AlphaDataset(train_encodings_2, y_train_2)\n",
    "test_dataset_2 = AlphaDataset(test_encodings_2, y_test_2)\n"
   ],
   "metadata": {
    "id": "54QXOh3wsQef"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc}\n",
    "\n",
    "# Loading the pre-trained BERT model for the classification task\n",
    "model_2 = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',  # Use the pre-trained base BERT model\n",
    "    num_labels=len(np.unique(y_2_encoded))  # Number of labels for classification\n",
    ")\n",
    "\n",
    "# Setting up training parameters\n",
    "training_args_2 = TrainingArguments(\n",
    "    output_dir='./results',            # Directory to save training results\n",
    "    num_train_epochs=5,                # Total number of training epochs\n",
    "    per_device_train_batch_size=8,     # Batch size for training\n",
    "    per_device_eval_batch_size=8,      # Batch size for evaluation\n",
    "    warmup_steps=500,                  # Number of warm-up steps to adjust the learning rate\n",
    "    weight_decay=0.01,                 # Weight decay for regularization\n",
    "    logging_dir='./logs',              # Directory to save logs\n",
    "    evaluation_strategy=\"epoch\"        # Evaluation strategy (can be \"no\", \"steps\", or \"epoch\")\n",
    ")\n",
    "\n",
    "# # Creating a Trainer instance, which will be used to train and evaluate the BERT model\n",
    "trainer_2 = Trainer(\n",
    "    model=model_2,                      # The BERT model to be trained\n",
    "    args=training_args_2,               # The training arguments\n",
    "    train_dataset=train_dataset_2,      # Training dataset\n",
    "    eval_dataset=test_dataset_2,        # Evaluation dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8w5fXwksQbp",
    "outputId": "9c5d5a37-f285-497a-c0fb-146639fe4bcf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "trainer_2.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zryXEMvIsQWR",
    "outputId": "8fa7efa8-f576-43f4-eaa0-e117fa112c0b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25020' max='25020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25020/25020 24:57, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.655400</td>\n",
       "      <td>0.650263</td>\n",
       "      <td>0.847337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.387400</td>\n",
       "      <td>0.423119</td>\n",
       "      <td>0.889699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.245500</td>\n",
       "      <td>0.332859</td>\n",
       "      <td>0.920472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.322940</td>\n",
       "      <td>0.931861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.086200</td>\n",
       "      <td>0.318869</td>\n",
       "      <td>0.935058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-4000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-4500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-5000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-5500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-6000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-6500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-7000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-7500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-8000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-8500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-9000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-9500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-10000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-10500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-11000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-11500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-12000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-12500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-13000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-13500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-14000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-14500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-15000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-15500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-16000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-16500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-17000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-17500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-18000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-18500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-19000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-19500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-20000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-20500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-21000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-21500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-22000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-22500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-23000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-23500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-24000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-24500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-25000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=25020, training_loss=0.5096236059610411, metrics={'train_runtime': 1497.3711, 'train_samples_per_second': 133.674, 'train_steps_per_second': 16.709, 'total_flos': 9183059691693120.0, 'train_loss': 0.5096236059610411, 'epoch': 5.0})"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Especifica la ruta donde deseas guardar el modelo\n",
    "model_path = \"/content/drive/MyDrive/anyone_final_project/finetunning_3\"\n",
    "\n",
    "# Guarda el modelo\n",
    "model_2.save_pretrained(model_path)\n",
    "\n",
    "# Nota: También puedes guardar el Tokenizador si es necesario\n",
    "tokenizer.save_pretrained(model_path)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O6RRMp_e-sF1",
    "outputId": "3ec55fa4-b071-46c7-f12d-775c5211433f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('/content/drive/MyDrive/anyone_final_project/finetunning_3/tokenizer_config.json',\n",
       " '/content/drive/MyDrive/anyone_final_project/finetunning_3/special_tokens_map.json',\n",
       " '/content/drive/MyDrive/anyone_final_project/finetunning_3/vocab.txt',\n",
       " '/content/drive/MyDrive/anyone_final_project/finetunning_3/added_tokens.json')"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#Prediccion 2\n",
    "text_2 = {\n",
    "    \"name\": \"Trumpet Multimedia - Trumpets That Work 2015 Calendar - Black\",\n",
    "    \"description\": \"TRUMPET MULTIMEDIA Trumpets That Work 2015 Calendar: 2015 calendar; Trumpets That Work design\",\n",
    "    \"price\": 23.95,\n",
    "    \"type\": \"HardGood\",\n",
    "    \"manufacturer\": \"Trumpet Multimedia\",\n",
    "}\n",
    "\n",
    "text_2['name'] = normalize_text(text_2['name'])\n",
    "text_2['description'] = normalize_text(text_2['description'])\n",
    "comp_pred_str = normalize_text(comp_pred_str)\n",
    "comp_pred_str_1 = normalize_text(comp_pred_str_1)\n",
    "\n",
    "text_2['combined_text'] = text_2['name'] + \" \" + text_2['description']+ \" \" + comp_pred_str + \" \" + comp_pred_str_1\n",
    "print(text_2)\n",
    "model_2_path = '/content/drive/MyDrive/anyone_final_project/finetunning_3'\n",
    "\n",
    "# Cargar el tokenizer\n",
    "tokenizer_2 = BertTokenizer.from_pretrained(model_2_path)\n",
    "\n",
    "# Cargar el modelo\n",
    "model_2 = BertForSequenceClassification.from_pretrained(model_2_path)\n",
    "\n",
    "\n",
    "def predict_2(text_2):\n",
    "    # Preparar los tokens de entrada\n",
    "    inputs = tokenizer_2(text_2, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "    # Hacer predicción\n",
    "    model_2.eval()  # Asegúrate de que el modelo esté en modo evaluación\n",
    "    with torch.no_grad():  # Desactivar la generación de gradientes\n",
    "        outputs = model_2(**inputs)\n",
    "\n",
    "    # Obtener la predicción de la última capa\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    return predicted_class_id"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GzoV0sYbsQSY",
    "outputId": "4c288252-f4d7-4aef-8fe0-d97b72d4dd77"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'name': 'trumpet multimedia trumpet work calendar black', 'description': 'trumpet multimedia trumpet work calendar calendar trumpet work design', 'price': 23.95, 'type': 'HardGood', 'manufacturer': 'Trumpet Multimedia', 'combined_text': 'trumpet multimedia trumpet work calendar black trumpet multimedia trumpet work calendar calendar trumpet work design toy game drone'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pred_2 = predict_2(text_2['combined_text'])\n",
    "print(pred_2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjKSfGG2sQDY",
    "outputId": "18d50176-c83f-4fb4-f6b4-6393c84dea71"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "302\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "with h5py.File('label_encoder_2.h5', 'r') as hf:\n",
    "    label_encoder_classes_2 = hf['label_encoder_2'][:]\n",
    "\n",
    "def compare_predictions(pred_2, label_encoder_classes_2):\n",
    "    if 0 <= pred_2 < len(label_encoder_classes_2):\n",
    "        return label_encoder_classes_2[pred_2]\n",
    "    else:\n",
    "        return 'unknown'"
   ],
   "metadata": {
    "id": "wzv3lNhj-kjT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "comp_pred_2 = compare_predictions(pred_2, label_encoder_classes_2)\n",
    "print(comp_pred_2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXOj0b7U-kZc",
    "outputId": "29d02cf8-6784-4f73-c82e-01d3108694fe"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b' TV'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "comp_pred_str_2 = comp_pred_2.decode(\"utf-8\")\n",
    "print(comp_pred_str_2)\n",
    "\n",
    "#Aqui termina prediccion 2"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OKM3piZUAPpr",
    "outputId": "728cfcd4-3c8f-45cc-c2d7-859193398f6b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " TV\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X_train_3['parent_category'] = X_train_3['parent_category'].apply(normalize_text)\n",
    "X_test_3['parent_category'] = X_test_3['parent_category'].apply(normalize_text)\n",
    "\n",
    "X_train_3['sub_category_1'] = X_train_3['sub_category_1'].apply(normalize_text)\n",
    "X_test_3['sub_category_1'] = X_test_3['sub_category_1'].apply(normalize_text)\n",
    "\n",
    "X_train_3['sub_category_2'] = X_train_3['sub_category_2'].apply(normalize_text)\n",
    "X_test_3['sub_category_2'] = X_test_3['sub_category_2'].apply(normalize_text)\n",
    "\n",
    "\n",
    "X_train_3['combined_text'] = X_train_3['name_normalized'].fillna('') + \" \" + X_train_3['description_normalized'].fillna('') + \" \"+ X_train_3['parent_category'] + \" \"+ X_train_3['sub_category_1'] + \" \"+ X_train_3['sub_category_2']\n",
    "X_test_3['combined_text'] = X_test_3['name_normalized'].fillna('') + \" \" + X_test_3['description_normalized'].fillna('') + \" \" + X_test_3['parent_category'] + \" \"+ X_test_3['sub_category_1'] + \" \"+ X_test_3['sub_category_2']"
   ],
   "metadata": {
    "id": "udS7j1elAl6U"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Tokenization model_3\n",
    "train_encodings_3 = tokenizer(X_train_3['combined_text'].tolist(), truncation=True, padding=True)\n",
    "test_encodings_3 = tokenizer(X_test_3['combined_text'].tolist(), truncation=True, padding=True)\n",
    "\n",
    "# Creation of training and test datasets\n",
    "train_dataset_3 = AlphaDataset(train_encodings_3, y_train_3)\n",
    "test_dataset_3 = AlphaDataset(test_encodings_3, y_test_3)"
   ],
   "metadata": {
    "id": "cE5LEkwVAl3e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc}\n",
    "\n",
    "# Loading the pre-trained BERT model for the classification task\n",
    "model_3 = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',  # Use the pre-trained base BERT model\n",
    "    num_labels=len(np.unique(y_3_encoded))  # Number of labels for classification\n",
    ")\n",
    "\n",
    "# Setting up training parameters\n",
    "training_args_3 = TrainingArguments(\n",
    "    output_dir='./results',            # Directory to save training results\n",
    "    num_train_epochs=5,                # Total number of training epochs\n",
    "    per_device_train_batch_size=8,     # Batch size for training\n",
    "    per_device_eval_batch_size=8,      # Batch size for evaluation\n",
    "    warmup_steps=500,                  # Number of warm-up steps to adjust the learning rate\n",
    "    weight_decay=0.01,                 # Weight decay for regularization\n",
    "    logging_dir='./logs',              # Directory to save logs\n",
    "    evaluation_strategy=\"epoch\"        # Evaluation strategy (can be \"no\", \"steps\", or \"epoch\")\n",
    ")\n",
    "\n",
    "# # Creating a Trainer instance, which will be used to train and evaluate the BERT model\n",
    "trainer_3 = Trainer(\n",
    "    model=model_3,                      # The BERT model to be trained\n",
    "    args=training_args_3,               # The training arguments\n",
    "    train_dataset=train_dataset_3,      # Training dataset\n",
    "    eval_dataset=test_dataset_3,        # Evaluation dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cz7dRCJSAluL",
    "outputId": "1b4164ed-a43f-400c-9d0d-d62dbcb2e90f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "trainer_3.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bfem0QC5AlrU",
    "outputId": "cb0bb421-4655-4172-c993-f3af842cbde0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25020' max='25020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25020/25020 26:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.637700</td>\n",
       "      <td>0.610876</td>\n",
       "      <td>0.839944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.343500</td>\n",
       "      <td>0.372319</td>\n",
       "      <td>0.906085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.296952</td>\n",
       "      <td>0.930263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.139800</td>\n",
       "      <td>0.295632</td>\n",
       "      <td>0.941253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.090200</td>\n",
       "      <td>0.294697</td>\n",
       "      <td>0.944350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-4000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-4500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-5000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-5500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-6000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-6500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-7000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-7500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-8000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-8500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-9000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-9500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-10000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-10500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-11000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-11500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-12000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-12500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-13000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-13500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-14000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-14500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-15000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-15500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-16000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-16500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-17000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-17500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-18000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-18500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-19000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-19500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-20000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-20500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-21000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-21500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-22000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-22500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-23000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-23500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-24000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-24500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-25000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=25020, training_loss=0.46653971724468263, metrics={'train_runtime': 1578.3959, 'train_samples_per_second': 126.812, 'train_steps_per_second': 15.852, 'total_flos': 9489797167518720.0, 'train_loss': 0.46653971724468263, 'epoch': 5.0})"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Especifica la ruta donde deseas guardar el modelo\n",
    "model_path = \"/content/drive/MyDrive/anyone_final_project/finetunning_4\"\n",
    "\n",
    "# Guarda el modelo\n",
    "model_3.save_pretrained(model_path)\n",
    "\n",
    "# Nota: También puedes guardar el Tokenizador si es necesario\n",
    "tokenizer.save_pretrained(model_path)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZcM8GLuAlWV",
    "outputId": "61ac8910-a70d-4fe3-bd83-703fb0628c2e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('/content/drive/MyDrive/anyone_final_project/finetunning_4/tokenizer_config.json',\n",
       " '/content/drive/MyDrive/anyone_final_project/finetunning_4/special_tokens_map.json',\n",
       " '/content/drive/MyDrive/anyone_final_project/finetunning_4/vocab.txt',\n",
       " '/content/drive/MyDrive/anyone_final_project/finetunning_4/added_tokens.json')"
      ]
     },
     "metadata": {},
     "execution_count": 132
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#Prediccion 3\n",
    "text_3 = {\n",
    "    \"name\": \"Trumpet Multimedia - Trumpets That Work 2015 Calendar - Black\",\n",
    "    \"description\": \"TRUMPET MULTIMEDIA Trumpets That Work 2015 Calendar: 2015 calendar; Trumpets That Work design\",\n",
    "    \"price\": 23.95,\n",
    "    \"type\": \"HardGood\",\n",
    "    \"manufacturer\": \"Trumpet Multimedia\",\n",
    "}\n",
    "\n",
    "text_3['name'] = normalize_text(text_3['name'])\n",
    "text_3['description'] = normalize_text(text_3['description'])\n",
    "comp_pred_str = normalize_text(comp_pred_str)\n",
    "comp_pred_str_1 = normalize_text(comp_pred_str_1)\n",
    "comp_pred_str_2 = normalize_text(comp_pred_str_2)\n",
    "\n",
    "text_3['combined_text'] = text_3['name'] + \" \" + text_3['description']+ \" \" + comp_pred_str + \" \" + comp_pred_str_1 + \" \" + comp_pred_str_2\n",
    "print(text_3)\n",
    "model_3_path = \"/content/drive/MyDrive/anyone_final_project/finetunning_4\"\n",
    "\n",
    "# Cargar el tokenizer\n",
    "tokenizer_3 = BertTokenizer.from_pretrained(model_3_path)\n",
    "\n",
    "# Cargar el modelo\n",
    "model_3 = BertForSequenceClassification.from_pretrained(model_3_path)\n",
    "\n",
    "\n",
    "def predict_3(text_3):\n",
    "    # Preparar los tokens de entrada\n",
    "    inputs = tokenizer_3(text_3, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "    # Hacer predicción\n",
    "    model_3.eval()  # Asegúrate de que el modelo esté en modo evaluación\n",
    "    with torch.no_grad():  # Desactivar la generación de gradientes\n",
    "        outputs = model_3(**inputs)\n",
    "\n",
    "    # Obtener la predicción de la última capa\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    return predicted_class_id"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ahckhVBAlTl",
    "outputId": "1a07d6e2-9c9d-448f-9f22-f19329eb605c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'name': 'trumpet multimedia trumpet work calendar black', 'description': 'trumpet multimedia trumpet work calendar calendar trumpet work design', 'price': 23.95, 'type': 'HardGood', 'manufacturer': 'Trumpet Multimedia', 'combined_text': 'trumpet multimedia trumpet work calendar black trumpet multimedia trumpet work calendar calendar trumpet work design toy game drone tv'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pred_3 = predict_3(text_3['combined_text'])\n",
    "print(pred_3)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XxDOP-8YAlMz",
    "outputId": "33d57cab-41a2-41e2-a66a-5378360a6df8"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "175\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "with h5py.File('label_encoder_3.h5', 'r') as hf:\n",
    "    label_encoder_classes_3 = hf['label_encoder_3'][:]\n",
    "\n",
    "def compare_predictions_3(pred_3, label_encoder_classes_3):\n",
    "    if 0 <= pred_3 < len(label_encoder_classes_3):\n",
    "        return label_encoder_classes_3[pred_3]\n",
    "    else:\n",
    "        return 'unknown'"
   ],
   "metadata": {
    "id": "AGYgvtx2Ak9M"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "comp_pred_3 = compare_predictions_3(pred_3, label_encoder_classes_3)\n",
    "print(comp_pred_3)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bpvL1sFTFFDd",
    "outputId": "69078bed-2e91-4f25-e570-964ee0185e88"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b' Movie & Character Toys'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "comp_pred_str_3 = comp_pred_3.decode(\"utf-8\")\n",
    "print(comp_pred_str_3)\n",
    "\n",
    "#Aqui termina prediccion 3"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "no8R8EO-FFBb",
    "outputId": "18ff3b57-83cc-4109-de3d-e93cfd3297e3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Movie & Character Toys\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# model_4 fine tunning bert\n",
    "X_train_4['parent_category'] = X_train_4['parent_category'].apply(normalize_text)\n",
    "X_test_4['parent_category'] = X_test_4['parent_category'].apply(normalize_text)\n",
    "\n",
    "X_train_4['sub_category_1'] = X_train_4['sub_category_1'].apply(normalize_text)\n",
    "X_test_4['sub_category_1'] = X_test_4['sub_category_1'].apply(normalize_text)\n",
    "\n",
    "X_train_4['sub_category_2'] = X_train_4['sub_category_2'].apply(normalize_text)\n",
    "X_test_4['sub_category_2'] = X_test_4['sub_category_2'].apply(normalize_text)\n",
    "\n",
    "X_train_4['sub_category_3'] = X_train_4['sub_category_3'].apply(normalize_text)\n",
    "X_test_4['sub_category_3'] = X_test_4['sub_category_3'].apply(normalize_text)\n",
    "\n",
    "\n",
    "X_train_4['combined_text'] = X_train_4['name_normalized'].fillna('') + \" \" + X_train_4['description_normalized'].fillna('') + \" \"+ X_train_4['parent_category'] + \" \"+ X_train_4['sub_category_1'] + \" \"+ X_train_4['sub_category_2'] + \" \"+ X_train_4['sub_category_3']\n",
    "X_test_4['combined_text'] = X_test_4['name_normalized'].fillna('') + \" \" + X_test_4['description_normalized'].fillna('') + \" \" + X_test_4['parent_category'] + \" \"+ X_test_4['sub_category_1'] + \" \"+ X_test_4['sub_category_2'] + \" \"+ X_test_4['sub_category_3']"
   ],
   "metadata": {
    "id": "SYnD6Tr0FE_G"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Tokenization model_4\n",
    "train_encodings_4 = tokenizer(X_train_4['combined_text'].tolist(), truncation=True, padding=True)\n",
    "test_encodings_4 = tokenizer(X_test_4['combined_text'].tolist(), truncation=True, padding=True)\n",
    "\n",
    "# Creation of training and test datasets\n",
    "train_dataset_4 = AlphaDataset(train_encodings_4, y_train_4)\n",
    "test_dataset_4 = AlphaDataset(test_encodings_4, y_test_4)"
   ],
   "metadata": {
    "id": "BU_8Xl5yFE8S"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc}\n",
    "\n",
    "# Loading the pre-trained BERT model for the classification task\n",
    "model_4 = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',  # Use the pre-trained base BERT model\n",
    "    num_labels=len(np.unique(y_4_encoded))  # Number of labels for classification\n",
    ")\n",
    "\n",
    "# Setting up training parameters\n",
    "training_args_4 = TrainingArguments(\n",
    "    output_dir='./results',            # Directory to save training results\n",
    "    num_train_epochs=5,                # Total number of training epochs\n",
    "    per_device_train_batch_size=8,     # Batch size for training\n",
    "    per_device_eval_batch_size=8,      # Batch size for evaluation\n",
    "    warmup_steps=500,                  # Number of warm-up steps to adjust the learning rate\n",
    "    weight_decay=0.01,                 # Weight decay for regularization\n",
    "    logging_dir='./logs',              # Directory to save logs\n",
    "    evaluation_strategy=\"epoch\"        # Evaluation strategy (can be \"no\", \"steps\", or \"epoch\")\n",
    ")\n",
    "\n",
    "# # Creating a Trainer instance, which will be used to train and evaluate the BERT model\n",
    "trainer_4 = Trainer(\n",
    "    model=model_4,                      # The BERT model to be trained\n",
    "    args=training_args_4,               # The training arguments\n",
    "    train_dataset=train_dataset_4,      # Training dataset\n",
    "    eval_dataset=test_dataset_4,        # Evaluation dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ssQ89IvwFE6c",
    "outputId": "b344913b-e433-4e23-8e41-51f0b48b4fc3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "trainer_4.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uxPhcXZUFE3h",
    "outputId": "c12af83c-1a76-4af9-ded1-a14a3f943388"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25020' max='25020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25020/25020 26:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.368027</td>\n",
       "      <td>0.908882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.312200</td>\n",
       "      <td>0.263175</td>\n",
       "      <td>0.932261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.226800</td>\n",
       "      <td>0.216670</td>\n",
       "      <td>0.946448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.216731</td>\n",
       "      <td>0.956239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.109700</td>\n",
       "      <td>0.191630</td>\n",
       "      <td>0.962134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-4000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-4500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-5000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-5500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-6000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-6500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-7000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-7500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-8000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-8500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-9000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-9500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-10000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-10500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-11000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-11500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-12000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-12500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-13000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-13500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-14000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-14500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-15000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-15500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-16000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-16500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-17000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-17500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-18000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-18500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-19000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-19500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-20000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-20500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-21000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-21500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-22000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-22500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-23000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-23500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-24000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-24500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-25000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=25020, training_loss=0.30645013392733916, metrics={'train_runtime': 1580.4546, 'train_samples_per_second': 126.647, 'train_steps_per_second': 15.831, 'total_flos': 9579720222057600.0, 'train_loss': 0.30645013392733916, 'epoch': 5.0})"
      ]
     },
     "metadata": {},
     "execution_count": 141
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Especifica la ruta donde deseas guardar el modelo\n",
    "model_path = \"/content/drive/MyDrive/anyone_final_project/finetunning_5\"\n",
    "\n",
    "# Guarda el modelo\n",
    "model_4.save_pretrained(model_path)\n",
    "\n",
    "# Nota: También puedes guardar el Tokenizador si es necesario\n",
    "tokenizer.save_pretrained(model_path)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qryzRbUGFE06",
    "outputId": "9fefc18b-a8d8-40e1-d07e-51c24806add4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('/content/drive/MyDrive/anyone_final_project/finetunning_5/tokenizer_config.json',\n",
       " '/content/drive/MyDrive/anyone_final_project/finetunning_5/special_tokens_map.json',\n",
       " '/content/drive/MyDrive/anyone_final_project/finetunning_5/vocab.txt',\n",
       " '/content/drive/MyDrive/anyone_final_project/finetunning_5/added_tokens.json')"
      ]
     },
     "metadata": {},
     "execution_count": 142
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#Prediccion 4\n",
    "\n",
    "text_4 = {\n",
    "    \"name\": \"Trumpet Multimedia - Trumpets That Work 2015 Calendar - Black\",\n",
    "    \"description\": \"TRUMPET MULTIMEDIA Trumpets That Work 2015 Calendar: 2015 calendar; Trumpets That Work design\",\n",
    "    \"price\": 23.95,\n",
    "    \"type\": \"HardGood\",\n",
    "    \"manufacturer\": \"Trumpet Multimedia\",\n",
    "}\n",
    "\n",
    "text_4['name'] = normalize_text(text_4['name'])\n",
    "text_4['description'] = normalize_text(text_4['description'])\n",
    "comp_pred_str = normalize_text(comp_pred_str)\n",
    "comp_pred_str_1 = normalize_text(comp_pred_str_1)\n",
    "comp_pred_str_2 = normalize_text(comp_pred_str_2)\n",
    "comp_pred_str_3 = normalize_text(comp_pred_str_3)\n",
    "\n",
    "text_4['combined_text'] = text_4['name'] + \" \" + text_4['description']+ \" \" + comp_pred_str + \" \" + comp_pred_str_1 + \" \" + comp_pred_str_2 + \" \" + comp_pred_str_3\n",
    "print(text_4)\n",
    "\n",
    "model_4_path = \"/content/drive/MyDrive/anyone_final_project/finetunning_5\"\n",
    "\n",
    "# Cargar el tokenizer\n",
    "tokenizer_4 = BertTokenizer.from_pretrained(model_4_path)\n",
    "\n",
    "# Cargar el modelo\n",
    "model_4 = BertForSequenceClassification.from_pretrained(model_4_path)\n",
    "\n",
    "\n",
    "def predict_4(text_4):\n",
    "    # Preparar los tokens de entrada\n",
    "    inputs = tokenizer_4(text_4, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "    # Hacer predicción\n",
    "    model_4.eval()  # Asegúrate de que el modelo esté en modo evaluación\n",
    "    with torch.no_grad():  # Desactivar la generación de gradientes\n",
    "        outputs = model_4(**inputs)\n",
    "\n",
    "    # Obtener la predicción de la última capa\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    return predicted_class_id"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMeOp787FEyS",
    "outputId": "cf60c543-33e7-4047-eb76-9645f7c1a6d3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'name': 'trumpet multimedia trumpet work calendar black', 'description': 'trumpet multimedia trumpet work calendar calendar trumpet work design', 'price': 23.95, 'type': 'HardGood', 'manufacturer': 'Trumpet Multimedia', 'combined_text': 'trumpet multimedia trumpet work calendar black trumpet multimedia trumpet work calendar calendar trumpet work design toy game drone tv movie character toy'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pred_4 = predict_4(text_4['combined_text'])\n",
    "print(pred_4)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQJd4Ry5FEvv",
    "outputId": "f86c2d73-a784-4912-81e2-06d834d0c43f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "93\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "with h5py.File('label_encoder_4.h5', 'r') as hf:\n",
    "    label_encoder_classes_4 = hf['label_encoder_4'][:]\n",
    "\n",
    "def compare_predictions_4(pred_4, label_encoder_classes_4):\n",
    "    if 0 <= pred_4 < len(label_encoder_classes_4):\n",
    "        return label_encoder_classes_4[pred_4]\n",
    "    else:\n",
    "        return 'unknown'"
   ],
   "metadata": {
    "id": "zEThT0_1FEtZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "comp_pred_4 = compare_predictions_4(pred_4, label_encoder_classes_4)\n",
    "print(comp_pred_4)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvbu5kRoFErE",
    "outputId": "9c1dc27b-ff48-4c48-f247-cf1296811aa6"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b' More Pop Culture Merchandise'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "comp_pred_str_4 = comp_pred_4.decode(\"utf-8\")\n",
    "print(comp_pred_str_4)\n",
    "\n",
    "#Aqui termina prediccion 4"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AK_PrxwrFEoh",
    "outputId": "c5968fc1-3117-4146-84b6-5dd9b9f524e3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " More Pop Culture Merchandise\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "ZCaQccbIFEhe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wdo3ct0S6zga"
   },
   "source": [
    "One Hot Encoder y Scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiMYODyT5cLA"
   },
   "source": [
    "Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kHamdvAY64SL",
    "outputId": "3ba4f976-5075-4373-e89a-7638a17ae8c5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of X_train_encoded: (40032, 2195)\n",
      "Data type of X_train_encoded: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Data type of elements in X_train_encoded: float64\n",
      "Shape of X_test_encoded: (10009, 2195)\n",
      "Data type of X_test_encoded: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Data type of elements in X_test_encoded: float64\n",
      "Shape of X_train_scaled: (40032, 1)\n",
      "Data type of elements in X_train_scaled: float64\n",
      "Shape of X_test_scaled: (10009, 1)\n",
      "Data type of elements in X_test_scaled: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import pickle\n",
    "\n",
    "# Define columns\n",
    "categorical_columns = ['type', 'manufacturer']\n",
    "numerical_columns = ['price']\n",
    "text_columns = ['name_normalized', 'description_normalized']\n",
    "\n",
    "# Fill missing values\n",
    "X_train[categorical_columns] = X_train[categorical_columns].fillna('missing')\n",
    "X_test[categorical_columns] = X_test[categorical_columns].fillna('missing')\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train_encoded = encoder.fit_transform(X_train[categorical_columns])\n",
    "X_test_encoded = encoder.transform(X_test[categorical_columns])\n",
    "\n",
    "\n",
    "# Save the encoder\n",
    "with open('encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(encoder, file)\n",
    "\n",
    "# Information about X_train_encoded and X_test_encoded\n",
    "print(\"Shape of X_train_encoded:\", X_train_encoded.shape)\n",
    "print(\"Data type of X_train_encoded:\", type(X_train_encoded))\n",
    "print(\"Data type of elements in X_train_encoded:\", X_train_encoded.dtype)\n",
    "print(\"Shape of X_test_encoded:\", X_test_encoded.shape)\n",
    "print(\"Data type of X_test_encoded:\", type(X_test_encoded))\n",
    "print(\"Data type of elements in X_test_encoded:\", X_test_encoded.dtype)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[numerical_columns])\n",
    "X_test_scaled = scaler.transform(X_test[numerical_columns])\n",
    "\n",
    "# Save scaler\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "\n",
    "# Print information about X_train_scaled and X_test_scaled\n",
    "print(\"Shape of X_train_scaled:\", X_train_scaled.shape)\n",
    "print(\"Data type of elements in X_train_scaled:\", X_train_scaled.dtype)\n",
    "print(\"Shape of X_test_scaled:\", X_test_scaled.shape)\n",
    "print(\"Data type of elements in X_test_scaled:\", X_test_scaled.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t14kj_745e3A"
   },
   "source": [
    "Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4rrKOHZ_4_AK",
    "outputId": "bd1b3f38-75f9-494e-dbf6-9bd87d1f6832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_encoded_1: (40032, 2218)\n",
      "Data type of X_train_encoded_1: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Data type of elements in X_train_encoded_1: float64\n",
      "Shape of X_test_encoded_1: (10009, 2218)\n",
      "Data type of X_test_encoded_1: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Data type of elements in X_test_encoded_1: float64\n",
      "Shape of X_train_scaled_1: (40032, 1)\n",
      "Data type of elements in X_train_scaled_1: float64\n",
      "Shape of X_test_scaled_1: (10009, 1)\n",
      "Data type of elements in X_test_scaled_1: float64\n"
     ]
    }
   ],
   "source": [
    "# Define columns\n",
    "categorical_columns_1 = ['type', 'manufacturer', 'parent_category']\n",
    "# numerical_columns = ['price']\n",
    "# text_columns = ['name_normalized', 'description_normalized']\n",
    "\n",
    "# Fill missing values\n",
    "X_train_1[categorical_columns_1] = X_train_1[categorical_columns_1].fillna('missing')\n",
    "X_test_1[categorical_columns_1] = X_test_1[categorical_columns_1].fillna('missing')\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder_1 = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train_encoded_1 = encoder_1.fit_transform(X_train_1[categorical_columns_1])\n",
    "X_test_encoded_1 = encoder_1.transform(X_test_1[categorical_columns_1])\n",
    "\n",
    "with open('encoder_1.pkl', 'wb') as file:\n",
    "    pickle.dump(encoder_1, file)\n",
    "\n",
    "\n",
    "\n",
    "# Print information about X_train_encoded and X_test_encoded\n",
    "print(\"Shape of X_train_encoded_1:\", X_train_encoded_1.shape)\n",
    "print(\"Data type of X_train_encoded_1:\", type(X_train_encoded_1))\n",
    "print(\"Data type of elements in X_train_encoded_1:\", X_train_encoded_1.dtype)\n",
    "print(\"Shape of X_test_encoded_1:\", X_test_encoded_1.shape)\n",
    "print(\"Data type of X_test_encoded_1:\", type(X_test_encoded_1))\n",
    "print(\"Data type of elements in X_test_encoded_1:\", X_test_encoded_1.dtype)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler_1 = StandardScaler()\n",
    "X_train_scaled_1 = scaler_1.fit_transform(X_train_1[numerical_columns])\n",
    "X_test_scaled_1 = scaler_1.transform(X_test_1[numerical_columns])\n",
    "\n",
    "with open('scaler_1.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler_1, file)\n",
    "\n",
    "# Print information about X_train_scaled and X_test_scaled\n",
    "print(\"Shape of X_train_scaled_1:\", X_train_scaled_1.shape)\n",
    "print(\"Data type of elements in X_train_scaled_1:\", X_train_scaled_1.dtype)\n",
    "print(\"Shape of X_test_scaled_1:\", X_test_scaled_1.shape)\n",
    "print(\"Data type of elements in X_test_scaled_1:\", X_test_scaled_1.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4uI4css5hqx"
   },
   "source": [
    "Stage 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSlE-ZXJ4-5Q",
    "outputId": "cb5f926f-438b-42f9-ab8b-6c1f9f7ba5bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_encoded_2: (40032, 2332)\n",
      "Data type of X_train_encoded_2: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Data type of elements in X_train_encoded_2: float64\n",
      "Shape of X_test_encoded_2: (10009, 2332)\n",
      "Data type of X_test_encoded_2: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Data type of elements in X_test_encoded_2: float64\n",
      "Shape of X_train_scaled_2: (40032, 1)\n",
      "Data type of elements in X_train_scaled_2: float64\n",
      "Shape of X_test_scaled_2: (10009, 1)\n",
      "Data type of elements in X_test_scaled_2: float64\n"
     ]
    }
   ],
   "source": [
    "# Define columns\n",
    "categorical_columns_2 = ['type', 'manufacturer', 'parent_category', 'sub_category_1']\n",
    "# numerical_columns = ['price']\n",
    "# text_columns = ['name_normalized', 'description_normalized']\n",
    "\n",
    "# Fill missing values\n",
    "X_train_2[categorical_columns_2] = X_train_2[categorical_columns_2].fillna('missing')\n",
    "X_test_2[categorical_columns_2] = X_test_2[categorical_columns_2].fillna('missing')\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder_2 = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train_encoded_2 = encoder_2.fit_transform(X_train_2[categorical_columns_2])\n",
    "X_test_encoded_2 = encoder_2.transform(X_test_2[categorical_columns_2])\n",
    "\n",
    "with open('encoder_2.pkl', 'wb') as file:\n",
    "    pickle.dump(encoder_2, file)\n",
    "\n",
    "\n",
    "# Print information about X_train_encoded and X_test_encoded\n",
    "print(\"Shape of X_train_encoded_2:\", X_train_encoded_2.shape)\n",
    "print(\"Data type of X_train_encoded_2:\", type(X_train_encoded_2))\n",
    "print(\"Data type of elements in X_train_encoded_2:\", X_train_encoded_2.dtype)\n",
    "print(\"Shape of X_test_encoded_2:\", X_test_encoded_2.shape)\n",
    "print(\"Data type of X_test_encoded_2:\", type(X_test_encoded_2))\n",
    "print(\"Data type of elements in X_test_encoded_2:\", X_test_encoded_2.dtype)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler_2 = StandardScaler()\n",
    "X_train_scaled_2 = scaler_2.fit_transform(X_train_2[numerical_columns])\n",
    "X_test_scaled_2 = scaler_2.transform(X_test_2[numerical_columns])\n",
    "\n",
    "with open('scaler_2.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler_2, file)\n",
    "\n",
    "\n",
    "# Print information about X_train_scaled and X_test_scaled\n",
    "print(\"Shape of X_train_scaled_2:\", X_train_scaled_2.shape)\n",
    "print(\"Data type of elements in X_train_scaled_2:\", X_train_scaled_2.dtype)\n",
    "print(\"Shape of X_test_scaled_2:\", X_test_scaled_2.shape)\n",
    "print(\"Data type of elements in X_test_scaled_2:\", X_test_scaled_2.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjEeJaua5jYm"
   },
   "source": [
    "Stage 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7UWrFjTJ4-y7",
    "outputId": "14c5078c-21d3-4614-8393-a3daa5372ea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_encoded_3: (40032, 2681)\n",
      "Data type of X_train_encoded_3: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Data type of elements in X_train_encoded_3: float64\n",
      "Shape of X_test_encoded_3: (10009, 2681)\n",
      "Data type of X_test_encoded_3: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Data type of elements in X_test_encoded_3: float64\n",
      "Shape of X_train_scaled_3: (40032, 1)\n",
      "Data type of elements in X_train_scaled_3: float64\n",
      "Shape of X_test_scaled_3: (10009, 1)\n",
      "Data type of elements in X_test_scaled_3: float64\n"
     ]
    }
   ],
   "source": [
    "# Define columns\n",
    "categorical_columns_3 = ['type', 'manufacturer', 'parent_category', 'sub_category_1', 'sub_category_2']\n",
    "# numerical_columns = ['price']\n",
    "# text_columns = ['name_normalized', 'description_normalized']\n",
    "\n",
    "# Fill missing values\n",
    "X_train_3[categorical_columns_3] = X_train_3[categorical_columns_3].fillna('missing')\n",
    "X_test_3[categorical_columns_3] = X_test_3[categorical_columns_3].fillna('missing')\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder_3 = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train_encoded_3 = encoder_3.fit_transform(X_train_3[categorical_columns_3])\n",
    "X_test_encoded_3 = encoder_3.transform(X_test_3[categorical_columns_3])\n",
    "\n",
    "\n",
    "with open('encoder_3.pkl', 'wb') as file:\n",
    "    pickle.dump(encoder_3, file)\n",
    "\n",
    "# Print information about X_train_encoded and X_test_encoded\n",
    "print(\"Shape of X_train_encoded_3:\", X_train_encoded_3.shape)\n",
    "print(\"Data type of X_train_encoded_3:\", type(X_train_encoded_3))\n",
    "print(\"Data type of elements in X_train_encoded_3:\", X_train_encoded_3.dtype)\n",
    "print(\"Shape of X_test_encoded_3:\", X_test_encoded_3.shape)\n",
    "print(\"Data type of X_test_encoded_3:\", type(X_test_encoded_3))\n",
    "print(\"Data type of elements in X_test_encoded_3:\", X_test_encoded_3.dtype)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler_3 = StandardScaler()\n",
    "X_train_scaled_3 = scaler_3.fit_transform(X_train_3[numerical_columns])\n",
    "X_test_scaled_3 = scaler_3.transform(X_test_3[numerical_columns])\n",
    "\n",
    "with open('scaler_3.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler_3, file)\n",
    "\n",
    "\n",
    "# Print information about X_train_scaled and X_test_scaled\n",
    "print(\"Shape of X_train_scaled_3:\", X_train_scaled_3.shape)\n",
    "print(\"Data type of elements in X_train_scaled_3:\", X_train_scaled_3.dtype)\n",
    "print(\"Shape of X_test_scaled_3:\", X_test_scaled_3.shape)\n",
    "print(\"Data type of elements in X_test_scaled_3:\", X_test_scaled_3.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zX9LC3rA5k-T"
   },
   "source": [
    "Stage 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0E-BaTiE4-rh",
    "outputId": "0fc98aa5-895c-4d65-e0c7-d19d5a80f750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_encoded_4: (40032, 2997)\n",
      "Data type of X_train_encoded_4: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Data type of elements in X_train_encoded_4: float64\n",
      "Shape of X_test_encoded_4: (10009, 2997)\n",
      "Data type of X_test_encoded_4: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Data type of elements in X_test_encoded_4: float64\n",
      "Shape of X_train_scaled_4: (40032, 1)\n",
      "Data type of elements in X_train_scaled_4: float64\n",
      "Shape of X_test_scaled_4: (10009, 1)\n",
      "Data type of elements in X_test_scaled_4: float64\n"
     ]
    }
   ],
   "source": [
    "# Define columns\n",
    "categorical_columns_4 = ['type', 'manufacturer', 'parent_category', 'sub_category_1', 'sub_category_2', 'sub_category_3']\n",
    "# numerical_columns = ['price']\n",
    "# text_columns = ['name_normalized', 'description_normalized']\n",
    "\n",
    "# Fill missing values\n",
    "X_train_4[categorical_columns_4] = X_train_4[categorical_columns_4].fillna('missing')\n",
    "X_test_4[categorical_columns_4] = X_test_4[categorical_columns_4].fillna('missing')\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder_4 = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train_encoded_4 = encoder_4.fit_transform(X_train_4[categorical_columns_4])\n",
    "X_test_encoded_4 = encoder_4.transform(X_test_4[categorical_columns_4])\n",
    "\n",
    "with open('encoder_4.pkl', 'wb') as file:\n",
    "    pickle.dump(encoder_4, file)\n",
    "\n",
    "# Print information about X_train_encoded and X_test_encoded\n",
    "print(\"Shape of X_train_encoded_4:\", X_train_encoded_4.shape)\n",
    "print(\"Data type of X_train_encoded_4:\", type(X_train_encoded_4))\n",
    "print(\"Data type of elements in X_train_encoded_4:\", X_train_encoded_4.dtype)\n",
    "print(\"Shape of X_test_encoded_4:\", X_test_encoded_4.shape)\n",
    "print(\"Data type of X_test_encoded_4:\", type(X_test_encoded_4))\n",
    "print(\"Data type of elements in X_test_encoded_4:\", X_test_encoded_4.dtype)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler_4 = StandardScaler()\n",
    "X_train_scaled_4 = scaler_4.fit_transform(X_train_4[numerical_columns])\n",
    "X_test_scaled_4 = scaler_4.transform(X_test_4[numerical_columns])\n",
    "\n",
    "with open('scaler_4.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler_4, file)\n",
    "\n",
    "\n",
    "# Print information about X_train_scaled and X_test_scaled\n",
    "print(\"Shape of X_train_scaled_4:\", X_train_scaled_4.shape)\n",
    "print(\"Data type of elements in X_train_scaled_4:\", X_train_scaled_4.dtype)\n",
    "print(\"Shape of X_test_scaled_4:\", X_test_scaled_4.shape)\n",
    "print(\"Data type of elements in X_test_scaled_4:\", X_test_scaled_4.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CgYBDhCwHKQA"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# Stage 1\n",
    "X_train_processed = hstack([X_train_encoded, X_train_scaled]).astype(np.float32).toarray()\n",
    "X_test_processed = hstack([X_test_encoded, X_test_scaled]).astype(np.float32).toarray()\n",
    "\n",
    "# Stage 2\n",
    "X_train_processed_1 = hstack([X_train_encoded_1, X_train_scaled_1]).astype(np.float32).toarray()\n",
    "X_test_processed_1 = hstack([X_test_encoded_1, X_test_scaled_1]).astype(np.float32).toarray()\n",
    "\n",
    "# Stage 3\n",
    "X_train_processed_2 = hstack([X_train_encoded_2, X_train_scaled_2]).astype(np.float32).toarray()\n",
    "X_test_processed_2 = hstack([X_test_encoded_2, X_test_scaled_2]).astype(np.float32).toarray()\n",
    "\n",
    "# Stage 4\n",
    "X_train_processed_3 = hstack([X_train_encoded_3, X_train_scaled_3]).astype(np.float32).toarray()\n",
    "X_test_processed_3 = hstack([X_test_encoded_3, X_test_scaled_3]).astype(np.float32).toarray()\n",
    "\n",
    "# Stage 5\n",
    "X_train_processed_4 = hstack([X_train_encoded_4, X_train_scaled_4]).astype(np.float32).toarray()\n",
    "X_test_processed_4 = hstack([X_test_encoded_4, X_test_scaled_4]).astype(np.float32).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvYoUCeHHjx_",
    "outputId": "61b6f3c1-d6bf-4b4a-fcd5-cc6f7e54ab90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of X_train_processed: float32\n",
      "Data type of X_test_processed: float32\n",
      "X_train_processed shape: (40032, 2196)\n",
      "X_test_processed shape: (10009, 2196)\n"
     ]
    }
   ],
   "source": [
    "# Dim 1\n",
    "print(\"Data type of X_train_processed:\", X_train_processed.dtype)\n",
    "print(\"Data type of X_test_processed:\", X_test_processed.dtype)\n",
    "print(\"X_train_processed shape:\", X_train_processed.shape)\n",
    "print(\"X_test_processed shape:\", X_test_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VhfSkN9I1vK",
    "outputId": "180da8c5-683c-4361-98ce-f51e50cd01ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of X_train_processed_1: float32\n",
      "Data type of X_test_processed_1: float32\n",
      "X_train_processed_1 shape: (40032, 2219)\n",
      "X_test_processed_1 shape: (10009, 2219)\n"
     ]
    }
   ],
   "source": [
    "# Dim 2\n",
    "print(\"Data type of X_train_processed_1:\", X_train_processed_1.dtype)\n",
    "print(\"Data type of X_test_processed_1:\", X_test_processed_1.dtype)\n",
    "print(\"X_train_processed_1 shape:\", X_train_processed_1.shape)\n",
    "print(\"X_test_processed_1 shape:\", X_test_processed_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Az3OeCXI1rI",
    "outputId": "3b70f69e-056d-4351-9485-bd9313c99b87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of X_train_processed_2: float32\n",
      "Data type of X_test_processed_2: float32\n",
      "X_train_processed_2 shape: (40032, 2333)\n",
      "X_test_processed_2 shape: (10009, 2333)\n"
     ]
    }
   ],
   "source": [
    "# Dim 3\n",
    "print(\"Data type of X_train_processed_2:\", X_train_processed_2.dtype)\n",
    "print(\"Data type of X_test_processed_2:\", X_test_processed_2.dtype)\n",
    "print(\"X_train_processed_2 shape:\", X_train_processed_2.shape)\n",
    "print(\"X_test_processed_2 shape:\", X_test_processed_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EBSG8gbeI1ng",
    "outputId": "902e994e-05fa-4a26-997f-66ff75d4eef8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of X_train_processed_3: float32\n",
      "Data type of X_test_processed_3: float32\n",
      "X_train_processed_3 shape: (40032, 2682)\n",
      "X_test_processed_3 shape: (10009, 2682)\n"
     ]
    }
   ],
   "source": [
    "# Dim 4\n",
    "print(\"Data type of X_train_processed_3:\", X_train_processed_3.dtype)\n",
    "print(\"Data type of X_test_processed_3:\",X_test_processed_3.dtype)\n",
    "print(\"X_train_processed_3 shape:\", X_train_processed_3.shape)\n",
    "print(\"X_test_processed_3 shape:\", X_test_processed_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vIkzAILmI5Iv",
    "outputId": "945746cf-2be2-42d4-f3d9-49007732e383"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of X_train_processed_4: float32\n",
      "Data type of X_test_processed_4: float32\n",
      "X_train_processed_4 shape: (40032, 2998)\n",
      "X_test_processed_4 shape: (10009, 2998)\n"
     ]
    }
   ],
   "source": [
    "# Dim 5\n",
    "print(\"Data type of X_train_processed_4:\", X_train_processed_4.dtype)\n",
    "print(\"Data type of X_test_processed_4:\", X_test_processed_4.dtype)\n",
    "print(\"X_train_processed_4 shape:\", X_train_processed_4.shape)\n",
    "print(\"X_test_processed_4 shape:\", X_test_processed_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vc5TdcMv0an5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define file paths to save the arrays\n",
    "file_paths = {\n",
    "    'X_train_processed.npy': X_train_processed,\n",
    "    'X_test_processed.npy': X_test_processed,\n",
    "    'X_train_processed_1.npy': X_train_processed_1,\n",
    "    'X_test_processed_1.npy': X_test_processed_1,\n",
    "    'X_train_processed_2.npy': X_train_processed_2,\n",
    "    'X_test_processed_2.npy': X_test_processed_2,\n",
    "    'X_train_processed_3.npy': X_train_processed_3,\n",
    "    'X_test_processed_3.npy': X_test_processed_3,\n",
    "    'X_train_processed_4.npy': X_train_processed_4,\n",
    "    'X_test_processed_4.npy': X_test_processed_4\n",
    "}\n",
    "\n",
    "# Save each array\n",
    "for file_name, array in file_paths.items():\n",
    "    np.save(file_name, array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EVfWlKtNKCOR"
   },
   "outputs": [],
   "source": [
    "X_train_name_embeddings_loaded = np.load('X_train_name_embeddings.npy', allow_pickle= True)\n",
    "X_train_description_embeddings_loaded = np.load('X_train_description_embeddings.npy',allow_pickle= True)\n",
    "X_test_name_embeddings_loaded = np.load('X_test_name_embeddings.npy', allow_pickle= True)\n",
    "X_test_description_embeddings_loaded = np.load('X_test_description_embeddings.npy', allow_pickle= True)\n",
    "\n",
    "# Load the saved NumPy arrays\n",
    "X_train_processed_loaded = np.load('X_train_processed.npy', allow_pickle=True)\n",
    "X_test_processed_loaded = np.load('X_test_processed.npy', allow_pickle=True)\n",
    "X_train_processed_1_loaded = np.load('X_train_processed_1.npy', allow_pickle=True)\n",
    "X_test_processed_1_loaded = np.load('X_test_processed_1.npy', allow_pickle=True)\n",
    "X_train_processed_2_loaded = np.load('X_train_processed_2.npy', allow_pickle=True)\n",
    "X_test_processed_2_loaded = np.load('X_test_processed_2.npy', allow_pickle=True)\n",
    "X_train_processed_3_loaded = np.load('X_train_processed_3.npy', allow_pickle=True)\n",
    "X_test_processed_3_loaded = np.load('X_test_processed_3.npy', allow_pickle=True)\n",
    "X_train_processed_4_loaded = np.load('X_train_processed_4.npy', allow_pickle=True)\n",
    "X_test_processed_4_loaded = np.load('X_test_processed_4.npy', allow_pickle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8juEMUSc0an6"
   },
   "outputs": [],
   "source": [
    "X_train_name_last_hidden = np.array([x[0][-1] for x in X_train_name_embeddings_loaded])\n",
    "X_train_description_last_hidden = np.array([x[0][-1] for x in X_train_description_embeddings_loaded])\n",
    "X_test_name_last_hidden = np.array([x[0][-1] for x in X_test_name_embeddings_loaded])\n",
    "X_test_description_last_hidden = np.array([x[0][-1] for x in X_test_description_embeddings_loaded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hooy6LuP0an6",
    "outputId": "5a962114-e6e5-41e3-d68b-5e65625fd349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First element of X_train_name_last_hidden: [ 6.20537519e-01 -1.57028392e-01 -4.39105332e-01  5.87245941e-01\n",
      " -4.92567480e-01 -6.75922573e-01  3.66373003e-01 -7.91122556e-01\n",
      "  6.63730741e-01  4.76211309e-02  4.97472771e-02 -3.77824754e-01\n",
      " -5.29451743e-02 -3.52970883e-03 -7.33473897e-01 -2.74465412e-01\n",
      " -8.19092095e-02 -1.52533606e-01  7.26244077e-02 -4.86062840e-02\n",
      "  3.07591200e-01 -1.32735014e-01  8.47112298e-01  2.39423364e-01\n",
      "  1.34860486e-01  3.51377934e-01 -4.78440404e-01 -1.80202276e-02\n",
      " -2.26639926e-01 -3.52599382e-01 -6.21600211e-01 -2.67526209e-01\n",
      " -1.92636084e-02  3.99675339e-01  1.55551210e-01 -8.61436129e-02\n",
      "  3.39647025e-01 -4.60110493e-02 -5.71235001e-01 -4.14561182e-01\n",
      " -3.34018916e-01 -1.61173679e-02 -1.93653673e-01  6.32311583e-01\n",
      "  5.47741950e-02 -6.00057304e-01  6.22461319e-01  3.42181236e-01\n",
      " -2.25496083e-01  4.89310294e-01  2.93806463e-01  1.60992384e-01\n",
      " -7.31535181e-02  8.67539346e-02  5.76151237e-02  1.21880889e-01\n",
      "  2.94119507e-01 -4.34998453e-01  1.54902250e-01  2.93051004e-01\n",
      " -5.07322550e-02  6.77793384e-01 -2.17716694e-01 -1.94208890e-01\n",
      "  6.51268899e-01 -1.67188928e-01  2.17404403e-02 -3.18291545e-01\n",
      " -6.07384741e-01 -3.05744082e-01 -2.39384830e-01 -1.02852356e+00\n",
      "  6.55281067e-01  3.35646331e-01  3.62706840e-01  2.41505504e-01\n",
      " -3.31891775e-01  7.45274603e-01  1.18391871e-01  3.59835505e-01\n",
      "  3.76000077e-01 -3.06956947e-01 -1.38037503e-01  7.29502961e-02\n",
      "  5.02546012e-01  1.56718288e-02 -2.42989823e-01  4.20575216e-02\n",
      " -4.59762454e-01 -1.26091674e-01  3.46461594e-01  2.71966606e-01\n",
      "  3.90934289e-01 -3.59424323e-01 -1.19082555e-01  3.55039179e-01\n",
      " -6.93194717e-02 -9.02826637e-02 -2.01892227e-01 -1.14928253e-01\n",
      " -3.77589911e-01 -1.72685519e-01 -5.20075373e-02  8.87612224e-01\n",
      " -1.62285715e-01 -2.95471847e-01  4.46627766e-01  5.57538629e-01\n",
      "  2.56792873e-01  1.03553367e+00  5.43226182e-01  2.22238839e-01\n",
      "  1.73543707e-01 -6.79688826e-02 -4.89283442e-01 -5.52646935e-01\n",
      "  2.85861969e-01  2.83273697e-01  3.80976677e-01  2.35821024e-01\n",
      " -6.67967856e-01 -4.66061831e-01  5.99375069e-01  1.08154857e+00\n",
      " -1.25421882e-01 -3.18098664e-02  2.50165947e-02 -7.18430936e-01\n",
      "  9.47480053e-02 -7.66403854e-01 -3.98136169e-01  6.48566902e-01\n",
      "  2.57072091e-01  8.71164203e-01 -1.05473615e-01  2.04653174e-01\n",
      " -3.08098674e-01  5.59956357e-02 -6.77700162e-01  1.01367123e-01\n",
      " -3.72281134e-01  9.31154370e-01  6.59990549e-01 -1.15582418e+00\n",
      "  5.36541790e-02  6.25010610e-01  5.59506238e-01 -3.16040702e-02\n",
      "  4.84125316e-02 -3.06834847e-01  7.54427016e-01 -1.69089168e-01\n",
      " -2.54145682e-01 -2.30913237e-02 -5.35159945e-01  2.63796747e-01\n",
      " -1.52081802e-01  1.89791620e-02  4.29030150e-01  7.86521673e-01\n",
      "  2.92653799e-01  3.41052055e-01  3.65956217e-01  5.37699759e-01\n",
      " -5.17349124e-01  2.24996656e-01 -1.17838478e+00 -1.76467597e-01\n",
      "  1.01287454e-01  4.32819426e-01 -4.23639059e-01 -4.54228640e-01\n",
      "  7.73141310e-02  3.79181325e-01 -3.45093966e-01  3.52966428e-01\n",
      " -1.62603110e-01  8.23184326e-02 -2.84529865e-01 -6.81628287e-01\n",
      " -8.46690559e+00 -2.35476375e-01 -9.76541191e-02  2.22685993e-01\n",
      " -3.64512168e-02 -3.91305238e-01 -8.25014532e-01 -1.73412472e-01\n",
      "  3.74747545e-01 -8.75730038e-01 -1.22479826e-01 -1.77380100e-01\n",
      " -9.63426471e-01  8.22258413e-01  3.41257453e-01 -2.38749608e-01\n",
      "  2.57653482e-02  2.47886866e-01 -3.30268562e-01  3.26861292e-01\n",
      " -1.97851792e-01 -3.42524916e-01  9.84942913e-02  6.40032470e-01\n",
      " -2.42812037e-01 -1.43791389e+00  2.46120483e-01 -2.29564041e-01\n",
      "  5.11401772e-01  5.85837178e-02 -1.31213963e+00 -1.12423360e-01\n",
      " -3.62519175e-03 -7.86731243e-01  1.56666100e-01 -5.34660220e-01\n",
      "  4.07156013e-02 -5.64395070e-01 -9.06348109e-01 -2.95303822e-01\n",
      " -5.59946835e-01 -3.20167810e-01 -1.84398927e-02  2.15938147e-02\n",
      "  5.29996753e-01 -1.46843731e+00  3.76851022e-01  7.21755743e-01\n",
      "  6.36393428e-01  2.52907544e-01 -8.59751627e-02 -1.71806812e-01\n",
      "  7.80056894e-01  1.51630104e-01  2.96293616e-01  1.60506576e-01\n",
      " -6.33846670e-02 -5.69900796e-02 -5.88919036e-02 -6.84572160e-01\n",
      " -7.04938546e-04  2.46744156e-01  2.25677311e-01 -8.23454112e-02\n",
      " -5.27979791e-01 -5.08032322e-01 -1.84435844e-01  9.23074484e-01\n",
      "  7.35809445e-01 -4.10479635e-01 -2.21967623e-01 -5.50180316e-01\n",
      "  3.03729922e-01 -4.96013671e-01  5.50130188e-01  7.58742869e-01\n",
      "  5.94226606e-02 -4.39812601e-01  1.16967094e+00 -5.56134701e-01\n",
      "  4.20879245e-01  7.08146334e-01  3.12095106e-01  1.29798785e-01\n",
      " -6.85978770e-01  6.66718185e-01  4.30409670e-01  2.85361290e-01\n",
      " -3.43734175e-01  3.40557098e-01  4.58756328e-01 -1.30768120e-01\n",
      " -4.67268795e-01  5.87800920e-01 -1.30464152e-01 -1.07199299e+00\n",
      "  6.74340010e-01 -8.66399184e-02  3.83873284e-01 -1.83765680e-01\n",
      " -3.93801302e-01  2.69577444e-01 -5.39098233e-02  1.67211309e-01\n",
      "  2.02100113e-01 -4.57387537e-01 -8.52275074e-01 -1.42785877e-01\n",
      "  3.35738182e-01 -6.06438577e-01 -1.52843416e-01 -3.03091884e-01\n",
      " -8.47115964e-02  6.67190492e-01 -6.68784678e-02  6.33220226e-02\n",
      "  5.23253739e-01 -1.75359398e-02 -4.24083918e-01 -2.04071775e-01\n",
      "  2.14214072e-01 -7.02822745e-01  1.12920888e-01 -3.13348323e-02\n",
      " -2.11466819e-01 -1.50750086e-01  4.50119257e-01  1.24140903e-01\n",
      "  7.55189002e-01 -1.10170841e-01  2.85554498e-01 -6.85934961e-01\n",
      "  2.90729553e-01 -1.57349512e-01 -2.48254389e-02  7.73136169e-02\n",
      " -1.95251510e-01 -1.05724163e-01  1.81615889e-01 -4.38701361e-01\n",
      "  2.71253109e-01  2.69789636e-01  1.97617477e-03  4.88260210e-01\n",
      " -6.08754009e-02 -6.35233000e-02 -8.48654211e-01 -4.67859924e-01\n",
      " -4.04063538e-02  3.92924100e-01  4.71455455e-01 -1.16113812e-01\n",
      "  6.34941638e-01 -2.62468249e-01 -4.95653987e-01 -3.08744982e-02\n",
      "  3.34599704e-01 -8.20729434e-02 -3.69854458e-02 -4.42685336e-01\n",
      " -5.49810231e-01  7.30598047e-02  2.70330966e-01 -1.09698489e-01\n",
      " -2.68085241e-01  5.26564658e-01  2.56138742e-01 -1.54329166e-01\n",
      "  2.68264174e-01  6.50385201e-01  1.24321252e-01 -8.18036258e-01\n",
      " -7.96757817e-01 -3.77051294e-01 -2.34010071e-01 -4.08915311e-01\n",
      " -4.76937480e-02  3.31464559e-01  7.78878927e-01  2.71527432e-02\n",
      " -3.22321892e-01  6.98770434e-02 -4.85345066e-01 -7.42784023e-01\n",
      " -4.95838150e-02  2.48317659e-01 -6.83598459e-01 -2.63965130e-01\n",
      " -3.53393927e-02 -4.28863764e-01  3.14770162e-01  1.37096956e-01\n",
      " -3.14997852e-01  8.23536664e-02  2.95320004e-02  5.10599613e-01\n",
      " -3.71191561e-01 -7.13964030e-02  2.93738581e-02 -3.19731176e-01\n",
      " -5.60358286e-01 -6.47917867e-01 -4.73039091e-01  1.92232206e-01\n",
      " -4.33800578e-01  1.69615537e-01  2.53361315e-01  1.28410399e-01\n",
      "  2.39444315e-01 -5.11149056e-02  2.00972959e-01  4.52268481e-01\n",
      " -9.15191919e-02  7.91754797e-02  6.82296529e-02 -2.93338329e-01\n",
      "  4.06531304e-01 -4.03168797e-01  3.09270024e-01  6.50663003e-02\n",
      "  1.05046615e-01 -8.64279717e-02 -1.53797373e-01  4.02077079e-01\n",
      "  5.03367066e-01  7.63851777e-02  2.09626377e-01  1.53182715e-01\n",
      " -5.65243840e-01 -1.32839739e-01  6.27765238e-01 -3.82222414e-01\n",
      " -3.88237000e-01  4.48667586e-01 -4.94298071e-01 -4.10451323e-01\n",
      " -4.89565134e-01 -4.12086457e-01  5.01163781e-01 -6.34864271e-01\n",
      "  4.93994743e-01  3.40991318e-02 -7.70612210e-02 -5.23390770e-01\n",
      " -3.90536785e-01  9.76225793e-01 -2.31955290e-01  4.92922813e-01\n",
      "  2.07122847e-01  3.43242586e-01  6.75997019e-01  3.43689382e-01\n",
      " -7.34328479e-03 -7.62901306e-02 -1.36262581e-01 -3.49554360e-01\n",
      "  2.33103514e-01 -2.97866374e-01  1.42095387e-01  2.46145166e-02\n",
      "  6.91457465e-02 -7.26145744e-01 -2.68725991e-01  4.27473038e-01\n",
      "  8.14948857e-01  1.12877059e+00  5.72656631e-01  6.83157027e-01\n",
      "  2.91611552e-01  4.32616830e-01 -8.02971900e-01 -2.75246471e-01\n",
      "  1.94451630e-01  6.13069296e-01 -5.72932422e-01  2.11954072e-01\n",
      "  1.04959095e+00 -7.37529248e-02  1.31617635e-01  5.35595417e-01\n",
      "  5.16681373e-01 -9.72960353e-01  2.33713865e-01 -6.80972874e-01\n",
      " -4.43347394e-02  6.06121868e-02 -8.95191729e-01  6.56643152e-01\n",
      " -4.67941612e-01  1.72935054e-01  3.06211114e-01 -2.09628448e-01\n",
      " -4.73560929e-01 -7.77069032e-01  5.25709808e-01 -5.47120214e-01\n",
      " -4.76924509e-01  3.44251424e-01  5.33317804e-01 -1.14928357e-01\n",
      "  8.92056108e-01 -1.09298661e-01 -1.78937271e-01  4.77421999e-01\n",
      "  1.20972060e-02 -6.01830721e-01  1.15526125e-01  1.84282243e-01\n",
      "  1.20737918e-01 -8.41489851e-01  2.74324179e-01  6.53214380e-02\n",
      "  3.10614675e-01  1.87517211e-01 -3.63761693e-01 -4.86926019e-01\n",
      "  2.67216444e-01  7.08758384e-02  4.93382275e-01 -6.62216306e-01\n",
      " -8.03277671e-01  5.06674275e-02 -4.52651903e-02  8.58727932e-01\n",
      "  3.86713773e-01 -2.26233333e-01  2.94005901e-01  8.16828609e-02\n",
      "  4.67826068e-01  9.88701731e-02 -5.52253127e-01 -6.25416636e-02\n",
      " -4.36638117e-01 -1.23846389e-01  3.10184360e-01  1.10362805e-01\n",
      " -3.76352072e-01 -6.95727170e-01 -2.82260239e-01 -2.98604459e-01\n",
      " -5.82896113e-01 -7.70874918e-02  6.86300695e-01  4.38593328e-01\n",
      "  2.09501594e-01  1.93385899e-01  1.10943151e+00 -6.18437052e-01\n",
      " -5.46705842e-01 -3.53303879e-01 -4.70864028e-03  2.02219620e-01\n",
      "  1.96173102e-01 -8.64403367e-01 -6.46913230e-01  1.45509869e-01\n",
      " -6.57370865e-01  2.44000092e-01  6.11473203e-01  5.38556337e-01\n",
      " -6.71112657e-01 -4.79236394e-02  1.10620749e+00  2.27204785e-01\n",
      " -2.44950041e-01 -4.12875004e-02 -4.92067188e-02 -3.21430787e-02\n",
      " -3.99663895e-01 -2.86540627e-01 -4.12346452e-01  3.79928648e-02\n",
      "  3.89240086e-01 -1.03023134e-01  3.54121447e-01  1.34739459e+00\n",
      " -1.63724944e-02 -6.84470415e-01 -2.10255329e-02 -1.12153515e-01\n",
      "  4.70662117e-01  5.75038865e-02 -6.25386477e-01 -3.15227062e-01\n",
      " -4.69694585e-01 -4.81898487e-02 -1.43374532e-01 -3.73101383e-01\n",
      "  1.92334324e-01 -1.23024061e-01  1.10399842e+00 -8.03215504e-01\n",
      "  3.67378086e-01  8.49291235e-02 -2.87107050e-01 -3.32370818e-01\n",
      " -2.46271253e-01  4.15957689e-01  1.03018686e-01  4.71279770e-01\n",
      " -1.91447139e-01  3.02230835e-01 -6.40176773e-01  4.34333146e-01\n",
      "  4.13303167e-01 -2.25464195e-01 -2.43023872e-01 -2.54389524e-01\n",
      "  1.05514765e-01  4.62910652e-01 -4.52698588e-01  4.98102456e-02\n",
      " -2.12586150e-01 -5.03674865e-01  1.03526384e-01  2.60310173e-01\n",
      " -1.91697702e-01 -4.90235597e-01  9.73624110e-01  1.67644136e-02\n",
      " -3.09523135e-01 -5.45606792e-01 -3.38727415e-01  1.95590585e-01\n",
      " -3.95997971e-01  4.34039265e-01 -4.79470164e-01 -1.79774463e-01\n",
      " -1.33216277e-01  2.92425573e-01  1.17567241e-01 -2.01351941e-04\n",
      " -2.28282869e-01 -2.98369490e-03  1.14583872e-01  1.87827110e-01\n",
      " -6.16419092e-02 -2.99429864e-01 -5.49328566e-01  1.95448071e-01\n",
      "  3.30738798e-02  4.45143133e-01 -1.45918047e+00  2.76990116e-01\n",
      "  1.06867522e-01 -6.36705995e-01  1.49721503e-02  6.21623933e-01\n",
      "  4.35345471e-01  3.67273450e-01  2.21252292e-01 -1.68745726e-01\n",
      "  6.34661615e-01  3.05576414e-01 -6.60773218e-01 -3.48220825e-01\n",
      " -6.01494908e-01  1.62416726e-01  8.51277590e-01  5.64038873e-01\n",
      " -1.32888541e-01  5.78130960e-01  4.37329769e-01 -2.50419378e-01\n",
      "  1.27389640e-01  3.04841608e-01  1.69228345e-01 -6.80671453e-01\n",
      " -7.91647136e-02 -3.90768163e-02 -5.89853674e-02  3.26032192e-01\n",
      "  2.79810995e-01  2.01112419e-01  2.79959261e-01 -3.94225419e-01\n",
      " -5.61534055e-02 -2.80866593e-01  4.21973437e-01 -1.25217527e-01\n",
      " -2.44032800e-01  2.56264925e-01 -5.77546299e-01 -1.79337002e-02\n",
      "  3.75045419e-01  3.90127748e-01  3.08235317e-01  4.32461239e-02\n",
      " -3.19815397e-01 -7.31928587e-01 -8.57445300e-01 -4.56196636e-01\n",
      "  1.91792414e-01  1.12777472e+00  1.14098623e-01 -3.93427730e-01\n",
      " -5.31382799e-01  3.73633385e-01  6.49822295e-01  6.61252618e-01\n",
      " -5.59039831e-01 -5.07438898e-01  1.88692242e-01  4.30638194e-01\n",
      " -4.43620563e-01  4.72782195e-01 -6.59415543e-01  6.56473190e-02\n",
      "  5.67307770e-01 -2.75379837e-01 -4.96693611e-01  7.40167964e-03\n",
      "  3.16577435e-01 -4.18295413e-01 -4.22885656e-01 -5.52101433e-01\n",
      "  1.22607075e-01  9.61042792e-02  3.23055595e-01 -8.41065586e-01\n",
      " -7.24421814e-02 -1.82764068e-01  6.32212877e-01  1.67815357e-01\n",
      "  9.77995574e-01 -5.84435463e-03  5.92191696e-01  3.41564238e-01\n",
      "  6.90299749e-01 -1.18450627e-01 -7.60542631e-01  3.70549768e-01\n",
      "  7.42236316e-01 -1.17789373e-01  1.43134284e+00 -5.23150861e-01\n",
      "  7.84933329e-01 -1.76844656e-01 -7.12502420e-01 -9.65571776e-02\n",
      " -3.18498445e+00  3.49936277e-01  1.60431802e-01 -4.65894155e-02\n",
      "  1.10750936e-01  5.58575392e-01  3.64335775e-01 -2.92843252e-01\n",
      " -2.93849111e-01 -2.34929547e-01  4.15985495e-01 -2.82904059e-01\n",
      " -2.30949983e-01  4.11721736e-01  1.61260486e-01  7.83595920e-01\n",
      "  9.95904356e-02 -6.22513071e-02  6.16447330e-01  1.61838517e-01\n",
      "  1.10445112e-01  9.79023241e-03  1.38397485e-01 -5.57122171e-01\n",
      " -3.70276511e-01  4.98058796e-02 -4.47070837e-01 -5.60444772e-01\n",
      " -3.11797470e-01 -1.47280797e-01  5.75177312e-01  6.68729022e-02\n",
      "  5.60362518e-01 -1.32139444e-01  8.84481013e-01 -8.28564614e-02\n",
      "  2.30413064e-01 -3.49385709e-01  4.17937599e-02 -9.30054039e-02\n",
      " -3.41964692e-01 -6.47252619e-01  1.84758946e-01 -8.61653328e-01\n",
      " -2.63148900e-02  2.52711296e-01 -6.25010908e-01  6.25658184e-02]\n"
     ]
    }
   ],
   "source": [
    "print(\"First element of X_train_name_last_hidden:\", X_train_name_last_hidden[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QuYJSuMQ0an6",
    "outputId": "6f8239d9-7b0a-4496-aa93-aa4cbbe3675b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_name_last_hidden: (40032, 768)\n",
      "Data type of X_train_name_last_hidden: float32\n",
      "Shape of X_train_description_last_hidden: (40032, 768)\n",
      "Data type of X_train_description_last_hidden: float32\n",
      "Shape of X_test_name_last_hidden: (10009, 768)\n",
      "Data type of X_test_name_last_hidden: float32\n",
      "Shape of X_test_description_last_hidden: (10009, 768)\n",
      "Data type of X_test_description_last_hidden: float32\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train_name_last_hidden:\", X_train_name_last_hidden.shape)\n",
    "print(\"Data type of X_train_name_last_hidden:\", X_train_name_last_hidden.dtype)\n",
    "\n",
    "print(\"Shape of X_train_description_last_hidden:\", X_train_description_last_hidden.shape)\n",
    "print(\"Data type of X_train_description_last_hidden:\", X_train_description_last_hidden.dtype)\n",
    "\n",
    "print(\"Shape of X_test_name_last_hidden:\", X_test_name_last_hidden.shape)\n",
    "print(\"Data type of X_test_name_last_hidden:\", X_test_name_last_hidden.dtype)\n",
    "\n",
    "print(\"Shape of X_test_description_last_hidden:\", X_test_description_last_hidden.shape)\n",
    "print(\"Data type of X_test_description_last_hidden:\", X_test_description_last_hidden.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bW3HYwqN0an6"
   },
   "outputs": [],
   "source": [
    "X_train_concatenated = np.concatenate((X_train_name_last_hidden, X_train_description_last_hidden), axis=1)\n",
    "X_test_concatenated = np.concatenate((X_test_name_last_hidden, X_test_description_last_hidden), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nek3jHOW0an7",
    "outputId": "e045dbad-cb67-475e-e2b9-88a20a00d5d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_concatenated: (40032, 1536)\n",
      "Data type of X_train_concatenated: float32\n",
      "Shape of X_test_concatenated: (10009, 1536)\n",
      "Data type of X_test_concatenated: float32\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train_concatenated:\", X_train_concatenated.shape)\n",
    "print(\"Data type of X_train_concatenated:\", X_train_concatenated.dtype)\n",
    "\n",
    "print(\"Shape of X_test_concatenated:\", X_test_concatenated.shape)\n",
    "print(\"Data type of X_test_concatenated:\", X_test_concatenated.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Avm1rZM0an7"
   },
   "outputs": [],
   "source": [
    "# Stage 1\n",
    "X_train_combined = np.concatenate((X_train_processed_loaded, X_train_concatenated), axis=1)\n",
    "X_test_combined = np.concatenate((X_test_processed_loaded, X_test_concatenated), axis=1)\n",
    "\n",
    "# Stage 2\n",
    "X_train_combined_1 = np.concatenate((X_train_processed_1_loaded, X_train_concatenated), axis=1)\n",
    "X_test_combined_1 = np.concatenate((X_test_processed_1_loaded, X_test_concatenated), axis=1)\n",
    "\n",
    "# Stage 3\n",
    "X_train_combined_2 = np.concatenate((X_train_processed_2_loaded, X_train_concatenated), axis=1)\n",
    "X_test_combined_2 = np.concatenate((X_test_processed_2_loaded, X_test_concatenated), axis=1)\n",
    "\n",
    "# Stage 4\n",
    "X_train_combined_3 = np.concatenate((X_train_processed_3_loaded, X_train_concatenated), axis=1)\n",
    "X_test_combined_3 = np.concatenate((X_test_processed_3_loaded, X_test_concatenated), axis=1)\n",
    "\n",
    "# Stage 5\n",
    "X_train_combined_4 = np.concatenate((X_train_processed_4_loaded, X_train_concatenated), axis=1)\n",
    "X_test_combined_4 = np.concatenate((X_test_processed_4_loaded, X_test_concatenated), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ldYOHBqt0an7",
    "outputId": "ad2205db-056d-4925-8c7b-dfd613ee32f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 - Train combined shape: (40032, 3732)\n",
      "Stage 1 - Test combined shape: (10009, 3732)\n",
      "Stage 2 - Train combined shape: (40032, 3755)\n",
      "Stage 2 - Test combined shape: (10009, 3755)\n",
      "Stage 3 - Train combined shape: (40032, 3869)\n",
      "Stage 3 - Test combined shape: (10009, 3869)\n",
      "Stage 4 - Train combined shape: (40032, 4218)\n",
      "Stage 4 - Test combined shape: (10009, 4218)\n",
      "Stage 5 - Train combined shape: (40032, 4534)\n",
      "Stage 5 - Test combined shape: (10009, 4534)\n"
     ]
    }
   ],
   "source": [
    "print(\"Stage 1 - Train combined shape:\", X_train_combined.shape)\n",
    "print(\"Stage 1 - Test combined shape:\", X_test_combined.shape)\n",
    "print(\"Stage 2 - Train combined shape:\", X_train_combined_1.shape)\n",
    "print(\"Stage 2 - Test combined shape:\", X_test_combined_1.shape)\n",
    "print(\"Stage 3 - Train combined shape:\", X_train_combined_2.shape)\n",
    "print(\"Stage 3 - Test combined shape:\", X_test_combined_2.shape)\n",
    "print(\"Stage 4 - Train combined shape:\", X_train_combined_3.shape)\n",
    "print(\"Stage 4 - Test combined shape:\", X_test_combined_3.shape)\n",
    "print(\"Stage 5 - Train combined shape:\", X_train_combined_4.shape)\n",
    "print(\"Stage 5 - Test combined shape:\", X_test_combined_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9U2sfygl0an7"
   },
   "outputs": [],
   "source": [
    "#Define num_clases\n",
    "\n",
    "num_classes = len(np.unique(y_encoded))\n",
    "num_classes_1 = len(np.unique(y_1_encoded))\n",
    "num_classes_2 = len(np.unique(y_2_encoded))\n",
    "num_classes_3 = len(np.unique(y_3_encoded))\n",
    "num_classes_4 = len(np.unique(y_4_encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5tRxGuTA0an7",
    "outputId": "6ecd1032-f28c-4af0-8136-6628f06e993f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "114\n",
      "349\n",
      "316\n",
      "162\n"
     ]
    }
   ],
   "source": [
    "print(num_classes)\n",
    "print(num_classes_1)\n",
    "print(num_classes_2)\n",
    "print(num_classes_3)\n",
    "print(num_classes_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XD3o1se0an7",
    "outputId": "ae901956-957e-485b-d75b-a89780618496"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 22:23:08.276598: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 22:23:08.543005: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-21 22:23:08.543060: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-21 22:23:08.589042: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-21 22:23:08.682693: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-21 22:23:09.523299: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_combined' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 28\u001B[0m\n\u001B[1;32m     24\u001B[0m lr_scheduler_callback \u001B[38;5;241m=\u001B[39m callbacks\u001B[38;5;241m.\u001B[39mLearningRateScheduler(lr_scheduler)\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Compile the model\u001B[39;00m\n\u001B[1;32m     27\u001B[0m model \u001B[38;5;241m=\u001B[39m models\u001B[38;5;241m.\u001B[39mSequential([\n\u001B[0;32m---> 28\u001B[0m     layers\u001B[38;5;241m.\u001B[39mDense(\u001B[38;5;241m128\u001B[39m, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m, input_shape\u001B[38;5;241m=\u001B[39m(\u001B[43mX_train_combined\u001B[49m\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m],)),\n\u001B[1;32m     29\u001B[0m     layers\u001B[38;5;241m.\u001B[39mBatchNormalization(),\n\u001B[1;32m     30\u001B[0m     layers\u001B[38;5;241m.\u001B[39mDropout(\u001B[38;5;241m0.5\u001B[39m),\n\u001B[1;32m     31\u001B[0m     layers\u001B[38;5;241m.\u001B[39mDense(\u001B[38;5;241m64\u001B[39m, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[1;32m     32\u001B[0m     layers\u001B[38;5;241m.\u001B[39mBatchNormalization(),\n\u001B[1;32m     33\u001B[0m     layers\u001B[38;5;241m.\u001B[39mDropout(\u001B[38;5;241m0.5\u001B[39m),\n\u001B[1;32m     34\u001B[0m     layers\u001B[38;5;241m.\u001B[39mDense(num_classes, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msoftmax\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     35\u001B[0m ])\n\u001B[1;32m     37\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     38\u001B[0m               loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msparse_categorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     39\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# Model fit\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train_combined' is not defined"
     ]
    }
   ],
   "source": [
    "#Stage1\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.models import save_model\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define learning rate function\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 4:\n",
    "        return lr * 0.94\n",
    "    elif epoch < 8:\n",
    "        return lr * 0.9\n",
    "    elif epoch < 16:\n",
    "        return lr * 0.80\n",
    "    elif epoch < 19:\n",
    "        return lr * 0.70\n",
    "    else:\n",
    "        return lr * 0.6\n",
    "\n",
    "# Define common callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler_callback = callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Compile the model\n",
    "model = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_combined.shape[1],)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model fit\n",
    "run_1 = model.fit(X_train_combined, y_train, epochs=60, batch_size=32,\n",
    "                  validation_data=(X_test_combined, y_test),\n",
    "                  callbacks=[early_stopping, lr_scheduler_callback])\n",
    "\n",
    "save_model(model, 'model_1_preberttune.h5')\n",
    "\n",
    "y_pred_probabilities = model.predict(X_test_combined)\n",
    "y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_combined, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mxt7cNba0an8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-U-036HC0an8",
    "outputId": "72caba46-cf52-476d-d098-7162994fd468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 1.8211 - accuracy: 0.5912 - val_loss: 0.6835 - val_accuracy: 0.8192 - lr: 9.4000e-04\n",
      "Epoch 2/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.8864 - accuracy: 0.7609 - val_loss: 0.4522 - val_accuracy: 0.8706 - lr: 8.8360e-04\n",
      "Epoch 3/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.7085 - accuracy: 0.7980 - val_loss: 0.3618 - val_accuracy: 0.8892 - lr: 8.3058e-04\n",
      "Epoch 4/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6533 - accuracy: 0.8100 - val_loss: 0.3351 - val_accuracy: 0.8971 - lr: 7.8075e-04\n",
      "Epoch 5/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6046 - accuracy: 0.8224 - val_loss: 0.3008 - val_accuracy: 0.9075 - lr: 7.0267e-04\n",
      "Epoch 6/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.5497 - accuracy: 0.8370 - val_loss: 0.2820 - val_accuracy: 0.9127 - lr: 6.3241e-04\n",
      "Epoch 7/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.5160 - accuracy: 0.8456 - val_loss: 0.2556 - val_accuracy: 0.9243 - lr: 5.6917e-04\n",
      "Epoch 8/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.4898 - accuracy: 0.8540 - val_loss: 0.2459 - val_accuracy: 0.9281 - lr: 5.1225e-04\n",
      "Epoch 9/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.4640 - accuracy: 0.8604 - val_loss: 0.2339 - val_accuracy: 0.9313 - lr: 4.0980e-04\n",
      "Epoch 10/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.4458 - accuracy: 0.8661 - val_loss: 0.2264 - val_accuracy: 0.9346 - lr: 3.2784e-04\n",
      "Epoch 11/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.4142 - accuracy: 0.8744 - val_loss: 0.2170 - val_accuracy: 0.9344 - lr: 2.6227e-04\n",
      "Epoch 12/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.4054 - accuracy: 0.8769 - val_loss: 0.2131 - val_accuracy: 0.9346 - lr: 2.0982e-04\n",
      "Epoch 13/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3924 - accuracy: 0.8823 - val_loss: 0.2144 - val_accuracy: 0.9363 - lr: 1.6785e-04\n",
      "Epoch 14/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3802 - accuracy: 0.8836 - val_loss: 0.2065 - val_accuracy: 0.9385 - lr: 1.3428e-04\n",
      "Epoch 15/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3758 - accuracy: 0.8881 - val_loss: 0.2039 - val_accuracy: 0.9383 - lr: 1.0743e-04\n",
      "Epoch 16/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3719 - accuracy: 0.8864 - val_loss: 0.2012 - val_accuracy: 0.9393 - lr: 8.5941e-05\n",
      "Epoch 17/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3556 - accuracy: 0.8908 - val_loss: 0.1993 - val_accuracy: 0.9405 - lr: 6.0159e-05\n",
      "Epoch 18/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3633 - accuracy: 0.8912 - val_loss: 0.1992 - val_accuracy: 0.9409 - lr: 4.2111e-05\n",
      "Epoch 19/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3541 - accuracy: 0.8934 - val_loss: 0.1985 - val_accuracy: 0.9405 - lr: 2.9478e-05\n",
      "Epoch 20/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3565 - accuracy: 0.8914 - val_loss: 0.1973 - val_accuracy: 0.9408 - lr: 1.7687e-05\n",
      "Epoch 21/60\n",
      "1251/1251 [==============================] - 3s 3ms/step - loss: 0.3455 - accuracy: 0.8960 - val_loss: 0.1972 - val_accuracy: 0.9415 - lr: 1.0612e-05\n",
      "Epoch 22/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3468 - accuracy: 0.8948 - val_loss: 0.1968 - val_accuracy: 0.9419 - lr: 6.3672e-06\n",
      "Epoch 23/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3499 - accuracy: 0.8972 - val_loss: 0.1970 - val_accuracy: 0.9411 - lr: 3.8203e-06\n",
      "Epoch 24/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3482 - accuracy: 0.8947 - val_loss: 0.1971 - val_accuracy: 0.9413 - lr: 2.2922e-06\n",
      "Epoch 25/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3491 - accuracy: 0.8944 - val_loss: 0.1970 - val_accuracy: 0.9416 - lr: 1.3753e-06\n",
      "Epoch 26/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3549 - accuracy: 0.8931 - val_loss: 0.1970 - val_accuracy: 0.9413 - lr: 8.2519e-07\n",
      "Epoch 27/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3514 - accuracy: 0.8929 - val_loss: 0.1966 - val_accuracy: 0.9411 - lr: 4.9511e-07\n",
      "Epoch 28/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3513 - accuracy: 0.8940 - val_loss: 0.1965 - val_accuracy: 0.9415 - lr: 2.9707e-07\n",
      "Epoch 29/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3466 - accuracy: 0.8951 - val_loss: 0.1967 - val_accuracy: 0.9416 - lr: 1.7824e-07\n",
      "Epoch 30/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3429 - accuracy: 0.8973 - val_loss: 0.1965 - val_accuracy: 0.9416 - lr: 1.0694e-07\n",
      "Epoch 31/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3485 - accuracy: 0.8954 - val_loss: 0.1971 - val_accuracy: 0.9413 - lr: 6.4167e-08\n",
      "Epoch 32/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3490 - accuracy: 0.8957 - val_loss: 0.1970 - val_accuracy: 0.9418 - lr: 3.8500e-08\n",
      "Epoch 33/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3500 - accuracy: 0.8945 - val_loss: 0.1971 - val_accuracy: 0.9411 - lr: 2.3100e-08\n",
      "Epoch 34/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3504 - accuracy: 0.8937 - val_loss: 0.1968 - val_accuracy: 0.9412 - lr: 1.3860e-08\n",
      "Epoch 35/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3464 - accuracy: 0.8954 - val_loss: 0.1971 - val_accuracy: 0.9414 - lr: 8.3160e-09\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1965 - accuracy: 0.9416\n",
      "Accuracy for Stage 2 model: 0.9415525794029236\n",
      "313/313 [==============================] - 0s 945us/step\n",
      "Classification Report for Stage 2 model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90        35\n",
      "           1       0.83      0.65      0.73        23\n",
      "           2       1.00      0.83      0.91         6\n",
      "           3       0.96      1.00      0.98        54\n",
      "           4       0.94      0.93      0.93       128\n",
      "           5       0.93      1.00      0.96        13\n",
      "           6       1.00      0.88      0.93         8\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       1.00      0.96      0.98        79\n",
      "           9       1.00      1.00      1.00         9\n",
      "          10       0.95      0.92      0.94       156\n",
      "          11       0.85      0.56      0.68        71\n",
      "          12       1.00      0.73      0.84        11\n",
      "          13       1.00      0.33      0.50         3\n",
      "          14       0.88      0.97      0.92       128\n",
      "          15       0.83      0.83      0.83         6\n",
      "          16       0.94      0.97      0.96       278\n",
      "          17       0.80      0.67      0.73        12\n",
      "          18       1.00      0.50      0.67        12\n",
      "          19       0.88      0.70      0.78        10\n",
      "          20       0.00      0.00      0.00         3\n",
      "          21       0.99      1.00      1.00      1242\n",
      "          22       0.50      0.25      0.33         4\n",
      "          23       0.96      0.99      0.97       464\n",
      "          24       1.00      0.88      0.94        74\n",
      "          25       0.92      0.99      0.95       125\n",
      "          26       0.84      0.54      0.66        39\n",
      "          27       1.00      0.99      0.99        83\n",
      "          28       0.90      0.98      0.94       372\n",
      "          29       0.95      0.92      0.94        88\n",
      "          30       1.00      0.96      0.98        57\n",
      "          31       0.00      0.00      0.00         8\n",
      "          32       0.81      0.75      0.78        28\n",
      "          33       0.00      0.00      0.00         7\n",
      "          34       1.00      1.00      1.00        14\n",
      "          35       1.00      1.00      1.00       245\n",
      "          36       1.00      0.50      0.67         6\n",
      "          37       0.97      0.81      0.89        43\n",
      "          38       0.89      0.91      0.90       105\n",
      "          39       0.94      0.91      0.92        32\n",
      "          40       1.00      0.75      0.86         4\n",
      "          41       1.00      1.00      1.00         6\n",
      "          42       1.00      1.00      1.00       132\n",
      "          43       1.00      1.00      1.00         7\n",
      "          44       0.88      0.96      0.92        24\n",
      "          45       0.99      1.00      0.99       207\n",
      "          46       0.95      0.98      0.97       200\n",
      "          47       0.90      0.97      0.93       275\n",
      "          48       0.93      0.79      0.86        34\n",
      "          49       0.95      0.86      0.90        43\n",
      "          50       0.95      0.96      0.96       134\n",
      "          51       0.67      1.00      0.80         2\n",
      "          52       1.00      0.74      0.85        19\n",
      "          53       1.00      0.71      0.83         7\n",
      "          54       1.00      0.64      0.78        25\n",
      "          55       0.99      0.99      0.99       113\n",
      "          56       1.00      1.00      1.00        27\n",
      "          57       0.82      0.67      0.73        27\n",
      "          58       1.00      1.00      1.00        27\n",
      "          59       0.70      0.87      0.78       100\n",
      "          60       1.00      1.00      1.00        58\n",
      "          61       1.00      1.00      1.00        52\n",
      "          62       1.00      1.00      1.00         6\n",
      "          63       1.00      1.00      1.00         4\n",
      "          64       0.60      0.80      0.68        99\n",
      "          65       0.98      0.97      0.97        58\n",
      "          66       0.78      0.60      0.68        30\n",
      "          67       0.88      0.91      0.89        32\n",
      "          68       0.91      0.62      0.74        16\n",
      "          69       0.97      0.97      0.97       217\n",
      "          70       0.82      0.87      0.84        53\n",
      "          71       0.93      0.87      0.90       108\n",
      "          72       1.00      0.66      0.79        32\n",
      "          73       0.00      0.00      0.00        10\n",
      "          74       0.00      0.00      0.00         2\n",
      "          75       0.94      0.73      0.82        22\n",
      "          76       0.00      0.00      0.00        13\n",
      "          77       0.29      0.14      0.19        37\n",
      "          78       0.48      0.87      0.62        68\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.99      1.00      1.00       722\n",
      "          81       0.97      0.97      0.97        31\n",
      "          82       1.00      1.00      1.00       236\n",
      "          83       0.68      0.53      0.59        57\n",
      "          84       0.95      0.97      0.96       197\n",
      "          85       1.00      1.00      1.00         9\n",
      "          86       0.00      0.00      0.00         8\n",
      "          87       0.88      0.78      0.82         9\n",
      "          88       0.98      0.99      0.99       181\n",
      "          89       0.98      0.99      0.98       614\n",
      "          90       1.00      0.99      0.99        84\n",
      "          91       1.00      0.25      0.40         8\n",
      "          92       0.93      0.96      0.94       117\n",
      "          93       0.71      1.00      0.83         5\n",
      "          94       0.96      0.98      0.97       191\n",
      "          95       0.98      0.97      0.98        61\n",
      "          96       0.96      1.00      0.98        68\n",
      "          97       0.97      1.00      0.99        72\n",
      "          98       0.89      1.00      0.94        55\n",
      "          99       0.00      0.00      0.00         1\n",
      "         100       1.00      1.00      1.00        64\n",
      "         101       0.95      0.97      0.96        62\n",
      "         102       0.80      0.76      0.78        21\n",
      "         103       1.00      0.98      0.99        96\n",
      "         104       0.71      0.81      0.76        21\n",
      "         105       0.64      0.47      0.54        15\n",
      "         106       0.72      0.66      0.69        65\n",
      "         107       0.83      0.96      0.89        54\n",
      "         108       0.96      0.97      0.96       243\n",
      "         109       0.95      1.00      0.97        18\n",
      "         110       0.95      0.83      0.88        23\n",
      "         111       1.00      1.00      1.00        12\n",
      "         112       0.98      0.91      0.94       154\n",
      "         113       0.88      0.33      0.48        21\n",
      "\n",
      "    accuracy                           0.94     10009\n",
      "   macro avg       0.83      0.78      0.79     10009\n",
      "weighted avg       0.94      0.94      0.94     10009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OWNER\\Desktop\\AnyoneAI\\final_project\\venv2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\OWNER\\Desktop\\AnyoneAI\\final_project\\venv2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\OWNER\\Desktop\\AnyoneAI\\final_project\\venv2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Stage2\n",
    "# Define learning rate function\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 4:\n",
    "        return lr * 0.94\n",
    "    elif epoch < 8:\n",
    "        return lr * 0.9\n",
    "    elif epoch < 16:\n",
    "        return lr * 0.80\n",
    "    elif epoch < 19:\n",
    "        return lr * 0.70\n",
    "    else:\n",
    "        return lr * 0.6\n",
    "\n",
    "# Define common callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler_callback = callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Create model\n",
    "model_2 = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_combined_1.shape[1],)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes_1, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model_2.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Fit model\n",
    "history_2 = model_2.fit(X_train_combined_1, y_train_1, epochs=60, batch_size=32,\n",
    "                        validation_data=(X_test_combined_1, y_test_1),\n",
    "                        callbacks=[early_stopping, lr_scheduler_callback])\n",
    "\n",
    "# Save model\n",
    "save_model(model_2, 'model_2_preberttune.h5')\n",
    "\n",
    "# Evaluate model\n",
    "loss_2, accuracy_2 = model_2.evaluate(X_test_combined_1, y_test_1)\n",
    "print(\"Accuracy for Stage 2 model:\", accuracy_2)\n",
    "\n",
    "# Generate classification report\n",
    "y_pred_probabilities_2 = model_2.predict(X_test_combined_1)\n",
    "y_pred_2 = np.argmax(y_pred_probabilities_2, axis=1)\n",
    "report_2 = classification_report(y_test_1, y_pred_2)\n",
    "print(\"Classification Report for Stage 2 model:\")\n",
    "print(report_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "doHjuheb0an8",
    "outputId": "75049d16-090f-4de7-b3c9-d49dd0ff7a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1251/1251 [==============================] - 5s 4ms/step - loss: 2.8616 - accuracy: 0.4597 - val_loss: 1.4320 - val_accuracy: 0.6822 - lr: 9.4000e-04\n",
      "Epoch 2/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 1.5729 - accuracy: 0.6391 - val_loss: 1.0036 - val_accuracy: 0.7520 - lr: 8.8360e-04\n",
      "Epoch 3/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 1.2517 - accuracy: 0.6884 - val_loss: 0.6970 - val_accuracy: 0.8118 - lr: 8.3058e-04\n",
      "Epoch 4/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 1.0994 - accuracy: 0.7125 - val_loss: 0.6239 - val_accuracy: 0.8291 - lr: 7.8075e-04\n",
      "Epoch 5/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.9939 - accuracy: 0.7369 - val_loss: 0.5500 - val_accuracy: 0.8410 - lr: 7.0267e-04\n",
      "Epoch 6/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.9307 - accuracy: 0.7497 - val_loss: 0.5146 - val_accuracy: 0.8466 - lr: 6.3241e-04\n",
      "Epoch 7/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.8748 - accuracy: 0.7604 - val_loss: 0.4752 - val_accuracy: 0.8613 - lr: 5.6917e-04\n",
      "Epoch 8/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.8265 - accuracy: 0.7729 - val_loss: 0.4495 - val_accuracy: 0.8733 - lr: 5.1225e-04\n",
      "Epoch 9/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.7920 - accuracy: 0.7799 - val_loss: 0.4511 - val_accuracy: 0.8730 - lr: 4.3541e-04\n",
      "Epoch 10/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.7554 - accuracy: 0.7881 - val_loss: 0.4220 - val_accuracy: 0.8800 - lr: 3.7010e-04\n",
      "Epoch 11/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.7403 - accuracy: 0.7921 - val_loss: 0.4077 - val_accuracy: 0.8865 - lr: 3.1459e-04\n",
      "Epoch 12/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.7119 - accuracy: 0.8008 - val_loss: 0.4012 - val_accuracy: 0.8868 - lr: 2.6740e-04\n",
      "Epoch 13/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6939 - accuracy: 0.8058 - val_loss: 0.3889 - val_accuracy: 0.8910 - lr: 2.2729e-04\n",
      "Epoch 14/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6779 - accuracy: 0.8082 - val_loss: 0.3914 - val_accuracy: 0.8943 - lr: 1.9319e-04\n",
      "Epoch 15/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6605 - accuracy: 0.8121 - val_loss: 0.3827 - val_accuracy: 0.8947 - lr: 1.6422e-04\n",
      "Epoch 16/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6499 - accuracy: 0.8156 - val_loss: 0.3825 - val_accuracy: 0.8948 - lr: 1.3958e-04\n",
      "Epoch 17/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6338 - accuracy: 0.8207 - val_loss: 0.3768 - val_accuracy: 0.8940 - lr: 1.0469e-04\n",
      "Epoch 18/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6335 - accuracy: 0.8184 - val_loss: 0.3734 - val_accuracy: 0.8954 - lr: 7.8515e-05\n",
      "Epoch 19/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6257 - accuracy: 0.8207 - val_loss: 0.3723 - val_accuracy: 0.8964 - lr: 5.8887e-05\n",
      "Epoch 20/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6103 - accuracy: 0.8247 - val_loss: 0.3703 - val_accuracy: 0.8959 - lr: 4.1221e-05\n",
      "Epoch 21/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6218 - accuracy: 0.8220 - val_loss: 0.3691 - val_accuracy: 0.8974 - lr: 2.8854e-05\n",
      "Epoch 22/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6049 - accuracy: 0.8255 - val_loss: 0.3679 - val_accuracy: 0.8974 - lr: 2.0198e-05\n",
      "Epoch 23/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.5993 - accuracy: 0.8279 - val_loss: 0.3672 - val_accuracy: 0.8969 - lr: 1.4139e-05\n",
      "Epoch 24/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.5953 - accuracy: 0.8279 - val_loss: 0.3679 - val_accuracy: 0.8978 - lr: 9.8971e-06\n",
      "Epoch 25/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6017 - accuracy: 0.8277 - val_loss: 0.3672 - val_accuracy: 0.8981 - lr: 6.9280e-06\n",
      "Epoch 26/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.5962 - accuracy: 0.8288 - val_loss: 0.3664 - val_accuracy: 0.8983 - lr: 4.8496e-06\n",
      "Epoch 27/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.5994 - accuracy: 0.8289 - val_loss: 0.3664 - val_accuracy: 0.8986 - lr: 3.3947e-06\n",
      "Epoch 28/60\n",
      "1251/1251 [==============================] - 5s 4ms/step - loss: 0.6028 - accuracy: 0.8292 - val_loss: 0.3653 - val_accuracy: 0.8980 - lr: 2.3763e-06\n",
      "Epoch 29/60\n",
      "1251/1251 [==============================] - 5s 4ms/step - loss: 0.5921 - accuracy: 0.8300 - val_loss: 0.3656 - val_accuracy: 0.8979 - lr: 1.6634e-06\n",
      "Epoch 30/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6031 - accuracy: 0.8277 - val_loss: 0.3670 - val_accuracy: 0.8982 - lr: 1.1644e-06\n",
      "Epoch 31/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6031 - accuracy: 0.8259 - val_loss: 0.3660 - val_accuracy: 0.8980 - lr: 8.1507e-07\n",
      "Epoch 32/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6024 - accuracy: 0.8286 - val_loss: 0.3666 - val_accuracy: 0.8985 - lr: 5.7055e-07\n",
      "Epoch 33/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.5925 - accuracy: 0.8323 - val_loss: 0.3667 - val_accuracy: 0.8981 - lr: 3.9938e-07\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3653 - accuracy: 0.8980\n",
      "Accuracy for Stage 3 model: 0.8979918360710144\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "Classification Report for Stage 3 model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        18\n",
      "           2       0.78      1.00      0.88        70\n",
      "           3       1.00      0.33      0.50         3\n",
      "           4       1.00      0.86      0.92         7\n",
      "           5       0.67      1.00      0.80         6\n",
      "           6       0.88      0.88      0.88         8\n",
      "           7       1.00      1.00      1.00        10\n",
      "           8       0.83      0.97      0.89        39\n",
      "           9       1.00      0.33      0.50         6\n",
      "          10       0.75      1.00      0.86         3\n",
      "          11       0.80      0.91      0.85        35\n",
      "          12       0.86      0.95      0.91       101\n",
      "          13       0.88      0.92      0.90        25\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       1.00      0.95      0.98        21\n",
      "          16       1.00      1.00      1.00        83\n",
      "          17       0.63      1.00      0.77        34\n",
      "          18       1.00      0.24      0.38        21\n",
      "          19       1.00      1.00      1.00       113\n",
      "          20       0.93      1.00      0.96        25\n",
      "          21       0.95      1.00      0.97        55\n",
      "          22       0.00      0.00      0.00        18\n",
      "          23       1.00      1.00      1.00        16\n",
      "          24       0.69      1.00      0.82       135\n",
      "          25       0.91      0.98      0.95        53\n",
      "          26       0.98      1.00      0.99        63\n",
      "          27       1.00      0.70      0.82        10\n",
      "          28       1.00      1.00      1.00         9\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.89      1.00      0.94         8\n",
      "          31       1.00      1.00      1.00        43\n",
      "          32       1.00      0.67      0.80         3\n",
      "          33       1.00      0.25      0.40        12\n",
      "          34       1.00      0.67      0.80         6\n",
      "          35       0.60      1.00      0.75         6\n",
      "          36       1.00      0.90      0.95        10\n",
      "          37       1.00      1.00      1.00         9\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         6\n",
      "          40       1.00      1.00      1.00        13\n",
      "          41       0.87      0.97      0.91        61\n",
      "          42       1.00      1.00      1.00         4\n",
      "          43       0.67      0.22      0.33         9\n",
      "          44       0.00      0.00      0.00         4\n",
      "          45       1.00      1.00      1.00         4\n",
      "          46       1.00      1.00      1.00         1\n",
      "          47       0.00      0.00      0.00         4\n",
      "          48       1.00      0.67      0.80         3\n",
      "          49       0.88      1.00      0.93        50\n",
      "          50       0.62      0.45      0.53        11\n",
      "          51       0.96      0.85      0.90        27\n",
      "          52       1.00      1.00      1.00         7\n",
      "          53       1.00      0.33      0.50         9\n",
      "          54       0.80      0.95      0.87        41\n",
      "          55       1.00      1.00      1.00         3\n",
      "          56       0.00      0.00      0.00         4\n",
      "          57       0.95      1.00      0.97        18\n",
      "          58       0.00      0.00      0.00         5\n",
      "          59       0.87      0.94      0.91        36\n",
      "          60       0.92      0.96      0.94        76\n",
      "          61       0.95      0.98      0.96        84\n",
      "          63       0.60      0.27      0.38        11\n",
      "          64       1.00      1.00      1.00         3\n",
      "          65       1.00      0.92      0.96        25\n",
      "          66       0.93      1.00      0.96       243\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.75      1.00      0.86         6\n",
      "          69       0.96      0.92      0.94        26\n",
      "          70       0.00      0.00      0.00         8\n",
      "          71       0.88      1.00      0.94        29\n",
      "          72       0.91      0.95      0.93        42\n",
      "          73       1.00      1.00      1.00         3\n",
      "          74       0.00      0.00      0.00         3\n",
      "          75       0.85      1.00      0.92       184\n",
      "          76       1.00      1.00      1.00         6\n",
      "          77       0.00      0.00      0.00         4\n",
      "          78       0.97      0.97      0.97       159\n",
      "          79       0.96      0.93      0.95       395\n",
      "          80       0.80      0.80      0.80         5\n",
      "          81       0.67      0.40      0.50         5\n",
      "          82       1.00      0.38      0.55        16\n",
      "          83       1.00      1.00      1.00         2\n",
      "          84       0.00      0.00      0.00         4\n",
      "          85       1.00      0.50      0.67         2\n",
      "          86       1.00      1.00      1.00         6\n",
      "          87       0.95      0.69      0.80        29\n",
      "          88       0.80      0.73      0.76        11\n",
      "          89       0.00      0.00      0.00        11\n",
      "          90       1.00      1.00      1.00         4\n",
      "          91       1.00      0.75      0.86         8\n",
      "          92       0.60      0.60      0.60         5\n",
      "          93       1.00      1.00      1.00       236\n",
      "          94       0.90      0.95      0.92       131\n",
      "          95       1.00      1.00      1.00       200\n",
      "          96       0.43      0.50      0.46         6\n",
      "          97       0.85      0.97      0.90        29\n",
      "          98       0.00      0.00      0.00         3\n",
      "          99       0.00      0.00      0.00         1\n",
      "         100       1.00      1.00      1.00         5\n",
      "         101       0.75      0.60      0.67        10\n",
      "         102       0.72      1.00      0.84        21\n",
      "         103       1.00      0.30      0.46        10\n",
      "         104       0.00      0.00      0.00         4\n",
      "         105       1.00      0.17      0.29         6\n",
      "         106       1.00      0.50      0.67        10\n",
      "         107       0.00      0.00      0.00         3\n",
      "         108       1.00      1.00      1.00         3\n",
      "         109       0.75      0.96      0.84        28\n",
      "         110       1.00      0.14      0.25         7\n",
      "         111       0.85      0.85      0.85        13\n",
      "         112       1.00      1.00      1.00         5\n",
      "         113       0.00      0.00      0.00         6\n",
      "         114       0.72      0.97      0.82        29\n",
      "         115       1.00      0.71      0.83        14\n",
      "         116       0.98      1.00      0.99        58\n",
      "         117       1.00      0.33      0.50         3\n",
      "         118       0.80      0.81      0.81        69\n",
      "         119       1.00      0.89      0.94        19\n",
      "         120       0.89      1.00      0.94        17\n",
      "         121       0.49      0.95      0.64        19\n",
      "         122       0.50      0.25      0.33         4\n",
      "         123       0.50      1.00      0.67         7\n",
      "         124       1.00      0.44      0.62         9\n",
      "         125       0.90      0.75      0.82        12\n",
      "         126       1.00      0.50      0.67         2\n",
      "         127       1.00      0.25      0.40         4\n",
      "         128       1.00      1.00      1.00         9\n",
      "         129       0.83      0.83      0.83         6\n",
      "         130       0.94      0.95      0.94        63\n",
      "         131       1.00      0.73      0.84        11\n",
      "         132       1.00      1.00      1.00        10\n",
      "         133       0.91      0.91      0.91        32\n",
      "         134       0.78      0.86      0.82        21\n",
      "         135       1.00      0.33      0.50         3\n",
      "         136       0.92      0.65      0.76        17\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.62      0.83      0.71         6\n",
      "         139       0.00      0.00      0.00         5\n",
      "         140       1.00      0.79      0.88        19\n",
      "         141       0.00      0.00      0.00         3\n",
      "         142       1.00      1.00      1.00         7\n",
      "         143       0.92      0.92      0.92        26\n",
      "         144       1.00      0.40      0.57         5\n",
      "         145       1.00      1.00      1.00         2\n",
      "         146       0.82      1.00      0.90         9\n",
      "         147       0.86      1.00      0.92         6\n",
      "         148       1.00      0.50      0.67         6\n",
      "         149       0.74      1.00      0.85        35\n",
      "         150       0.74      0.94      0.83        18\n",
      "         151       1.00      0.25      0.40         8\n",
      "         152       1.00      0.97      0.99        71\n",
      "         153       0.00      0.00      0.00         5\n",
      "         154       0.62      0.71      0.67         7\n",
      "         155       1.00      0.95      0.97        37\n",
      "         156       0.86      1.00      0.92        12\n",
      "         157       0.00      0.00      0.00         2\n",
      "         158       0.80      0.22      0.35        18\n",
      "         159       0.92      0.85      0.88        13\n",
      "         160       0.00      0.00      0.00        10\n",
      "         161       0.76      0.73      0.75        26\n",
      "         162       1.00      1.00      1.00        32\n",
      "         163       1.00      1.00      1.00        19\n",
      "         164       0.67      0.50      0.57        28\n",
      "         165       0.00      0.00      0.00         3\n",
      "         166       1.00      1.00      1.00         7\n",
      "         167       1.00      0.50      0.67         4\n",
      "         168       1.00      0.75      0.86         4\n",
      "         169       0.00      0.00      0.00         1\n",
      "         170       0.85      0.88      0.86       112\n",
      "         171       0.00      0.00      0.00         4\n",
      "         172       0.54      1.00      0.70        28\n",
      "         173       1.00      0.75      0.86         4\n",
      "         174       0.93      0.96      0.94       146\n",
      "         175       0.83      0.96      0.89        26\n",
      "         176       0.60      0.60      0.60         5\n",
      "         177       0.85      0.73      0.79        15\n",
      "         178       0.75      0.75      0.75        12\n",
      "         179       0.00      0.00      0.00         8\n",
      "         180       0.68      0.76      0.72        17\n",
      "         181       0.83      0.92      0.87        26\n",
      "         182       0.89      1.00      0.94        33\n",
      "         183       1.00      1.00      1.00         7\n",
      "         185       1.00      1.00      1.00        23\n",
      "         186       0.00      0.00      0.00         2\n",
      "         187       0.50      0.86      0.63         7\n",
      "         188       0.00      0.00      0.00         1\n",
      "         189       1.00      0.50      0.67         2\n",
      "         190       0.85      1.00      0.92        17\n",
      "         191       0.85      1.00      0.92        60\n",
      "         192       1.00      1.00      1.00         5\n",
      "         193       0.79      1.00      0.88        59\n",
      "         194       0.85      0.92      0.88        12\n",
      "         195       0.88      1.00      0.93         7\n",
      "         196       0.96      0.92      0.94        26\n",
      "         197       0.94      0.89      0.91        35\n",
      "         198       1.00      0.50      0.67         2\n",
      "         199       0.87      0.62      0.72        21\n",
      "         200       1.00      0.68      0.81        25\n",
      "         201       1.00      1.00      1.00         5\n",
      "         202       1.00      1.00      1.00       191\n",
      "         203       0.00      0.00      0.00         4\n",
      "         204       0.53      0.95      0.68        21\n",
      "         205       1.00      1.00      1.00        16\n",
      "         206       0.00      0.00      0.00         4\n",
      "         207       0.80      1.00      0.89         4\n",
      "         208       1.00      1.00      1.00        25\n",
      "         209       0.97      1.00      0.98        31\n",
      "         210       0.96      0.98      0.97        52\n",
      "         211       0.00      0.00      0.00         2\n",
      "         212       1.00      0.33      0.50         3\n",
      "         213       1.00      1.00      1.00         6\n",
      "         214       0.94      1.00      0.97        88\n",
      "         215       1.00      0.88      0.93         8\n",
      "         216       0.66      0.97      0.78        80\n",
      "         217       1.00      0.33      0.50         6\n",
      "         218       0.75      1.00      0.86         3\n",
      "         219       1.00      0.95      0.98        21\n",
      "         220       1.00      0.50      0.67         4\n",
      "         221       0.50      0.45      0.48        11\n",
      "         222       0.00      0.00      0.00         3\n",
      "         223       1.00      1.00      1.00         8\n",
      "         224       1.00      1.00      1.00        13\n",
      "         225       0.67      1.00      0.80         2\n",
      "         226       0.97      1.00      0.99        33\n",
      "         227       0.93      1.00      0.96        13\n",
      "         228       1.00      1.00      1.00        54\n",
      "         229       0.78      1.00      0.88         7\n",
      "         230       0.92      0.98      0.95       102\n",
      "         231       1.00      0.62      0.76        13\n",
      "         232       0.82      1.00      0.90        14\n",
      "         233       0.97      0.91      0.94        35\n",
      "         235       0.94      1.00      0.97        47\n",
      "         236       0.00      0.00      0.00         7\n",
      "         237       1.00      1.00      1.00         4\n",
      "         238       0.55      0.92      0.69        13\n",
      "         239       0.67      1.00      0.80        10\n",
      "         240       1.00      0.50      0.67         8\n",
      "         241       0.86      1.00      0.92         6\n",
      "         242       0.62      0.45      0.53        11\n",
      "         243       0.67      1.00      0.80         4\n",
      "         244       1.00      0.86      0.92         7\n",
      "         245       1.00      1.00      1.00         3\n",
      "         246       1.00      1.00      1.00        15\n",
      "         247       1.00      1.00      1.00       213\n",
      "         248       0.95      1.00      0.97        19\n",
      "         249       1.00      1.00      1.00        31\n",
      "         250       0.75      1.00      0.86         3\n",
      "         251       1.00      1.00      1.00         2\n",
      "         252       1.00      1.00      1.00         8\n",
      "         253       1.00      0.12      0.22         8\n",
      "         254       0.71      0.83      0.77         6\n",
      "         255       0.77      0.97      0.86        31\n",
      "         256       0.96      0.96      0.96        25\n",
      "         257       0.79      1.00      0.88        15\n",
      "         258       0.67      1.00      0.80         2\n",
      "         259       0.90      0.56      0.69        16\n",
      "         260       0.86      0.80      0.83        15\n",
      "         261       1.00      1.00      1.00         2\n",
      "         262       1.00      0.78      0.88         9\n",
      "         263       1.00      1.00      1.00         9\n",
      "         264       0.46      0.81      0.59        21\n",
      "         265       1.00      1.00      1.00         1\n",
      "         266       1.00      0.83      0.91        12\n",
      "         267       1.00      0.62      0.77         8\n",
      "         268       1.00      0.40      0.57         5\n",
      "         269       0.88      0.74      0.81        39\n",
      "         270       0.72      1.00      0.83        53\n",
      "         271       0.83      0.94      0.88       134\n",
      "         272       0.86      0.92      0.89        13\n",
      "         273       0.00      0.00      0.00         7\n",
      "         274       0.60      0.75      0.67         8\n",
      "         275       1.00      0.67      0.80         3\n",
      "         276       0.00      0.00      0.00         6\n",
      "         277       0.90      0.75      0.82        12\n",
      "         278       0.76      0.85      0.80        26\n",
      "         279       0.90      1.00      0.95         9\n",
      "         280       0.82      1.00      0.90        18\n",
      "         281       1.00      0.67      0.80         3\n",
      "         282       1.00      1.00      1.00         2\n",
      "         283       0.46      1.00      0.63         6\n",
      "         284       0.98      0.96      0.97        67\n",
      "         285       0.62      1.00      0.77         5\n",
      "         286       1.00      1.00      1.00        34\n",
      "         287       0.93      0.96      0.95       170\n",
      "         288       0.81      0.91      0.86        65\n",
      "         289       0.89      1.00      0.94         8\n",
      "         290       1.00      0.57      0.73        14\n",
      "         291       1.00      1.00      1.00         2\n",
      "         292       1.00      0.33      0.50         3\n",
      "         293       1.00      0.25      0.40         8\n",
      "         294       0.86      0.75      0.80         8\n",
      "         295       0.85      0.82      0.84        28\n",
      "         296       1.00      1.00      1.00        19\n",
      "         297       0.50      0.40      0.44         5\n",
      "         298       1.00      0.30      0.46        10\n",
      "         299       0.00      0.00      0.00         1\n",
      "         300       1.00      0.73      0.85        15\n",
      "         301       0.96      0.96      0.96        27\n",
      "         302       0.76      0.88      0.81        25\n",
      "         303       1.00      1.00      1.00         4\n",
      "         304       0.93      0.82      0.88        17\n",
      "         305       0.95      0.83      0.89        24\n",
      "         306       1.00      1.00      1.00        79\n",
      "         307       0.93      0.64      0.76        22\n",
      "         308       0.89      0.97      0.93        33\n",
      "         309       0.75      0.75      0.75         4\n",
      "         310       0.00      0.00      0.00        12\n",
      "         311       0.50      0.67      0.57         3\n",
      "         312       1.00      1.00      1.00         3\n",
      "         313       0.71      0.92      0.80        26\n",
      "         314       1.00      0.50      0.67         8\n",
      "         315       1.00      0.95      0.97        55\n",
      "         316       1.00      0.40      0.57         5\n",
      "         317       0.44      1.00      0.62         8\n",
      "         318       0.69      0.69      0.69        13\n",
      "         319       0.90      1.00      0.95        38\n",
      "         320       0.00      0.00      0.00         1\n",
      "         321       0.83      1.00      0.91        10\n",
      "         322       1.00      0.60      0.75         5\n",
      "         323       0.00      0.00      0.00        10\n",
      "         324       1.00      1.00      1.00        28\n",
      "         325       1.00      0.50      0.67         2\n",
      "         326       1.00      1.00      1.00        25\n",
      "         327       1.00      1.00      1.00         2\n",
      "         328       1.00      0.67      0.80         3\n",
      "         329       0.95      1.00      0.97        18\n",
      "         330       1.00      1.00      1.00         3\n",
      "         331       1.00      1.00      1.00        10\n",
      "         332       0.00      0.00      0.00        11\n",
      "         333       0.86      0.38      0.52        16\n",
      "         334       0.00      0.00      0.00         9\n",
      "         335       1.00      0.67      0.80         3\n",
      "         336       0.71      1.00      0.83         5\n",
      "         337       1.00      0.83      0.91         6\n",
      "         338       0.98      1.00      0.99        55\n",
      "         339       0.89      1.00      0.94        16\n",
      "         340       0.00      0.00      0.00         1\n",
      "         341       1.00      0.97      0.99        37\n",
      "         342       0.64      0.88      0.74         8\n",
      "         343       0.00      0.00      0.00         9\n",
      "         344       0.92      0.97      0.94       403\n",
      "         345       1.00      1.00      1.00         7\n",
      "         346       1.00      1.00      1.00         5\n",
      "         347       0.96      0.94      0.95      1254\n",
      "         348       0.73      0.57      0.64       145\n",
      "\n",
      "    accuracy                           0.90     10009\n",
      "   macro avg       0.76      0.71      0.72     10009\n",
      "weighted avg       0.89      0.90      0.88     10009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OWNER\\Desktop\\AnyoneAI\\final_project\\venv2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\OWNER\\Desktop\\AnyoneAI\\final_project\\venv2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\OWNER\\Desktop\\AnyoneAI\\final_project\\venv2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Stage 3\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 4:\n",
    "        return lr * 0.94\n",
    "    elif epoch < 8:\n",
    "        return lr * 0.9\n",
    "    elif epoch < 16:\n",
    "        return lr * 0.85\n",
    "    elif epoch < 19:\n",
    "        return lr * 0.75\n",
    "    else:\n",
    "        return lr * 0.7\n",
    "\n",
    "# Define common callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler_callback = callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "\n",
    "model_3 = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_combined_2.shape[1],)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes_2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model_3.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Fit model\n",
    "history_3 = model_3.fit(X_train_combined_2, y_train_2, epochs=60, batch_size=32,\n",
    "                        validation_data=(X_test_combined_2, y_test_2),\n",
    "                        callbacks=[early_stopping, lr_scheduler_callback])\n",
    "\n",
    "# Save model\n",
    "save_model(model_3, 'model_3_preberttune.h5')\n",
    "\n",
    "# Evaluate model\n",
    "loss_3, accuracy_3 = model_3.evaluate(X_test_combined_2, y_test_2)\n",
    "print(\"Accuracy for Stage 3 model:\", accuracy_3)\n",
    "\n",
    "# Generate classification report\n",
    "y_pred_probabilities_3 = model_3.predict(X_test_combined_2)\n",
    "y_pred_3 = np.argmax(y_pred_probabilities_3, axis=1)\n",
    "report_3 = classification_report(y_test_2, y_pred_3)\n",
    "print(\"Classification Report for Stage 3 model:\")\n",
    "print(report_3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JAGW60Ur0an8",
    "outputId": "6e57daaf-4fe7-4684-a0f1-28e5ad732c65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1251/1251 [==============================] - 6s 4ms/step - loss: 2.5191 - accuracy: 0.5539 - val_loss: 1.2217 - val_accuracy: 0.7234 - lr: 9.4000e-04\n",
      "Epoch 2/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 1.3264 - accuracy: 0.7036 - val_loss: 0.7747 - val_accuracy: 0.8044 - lr: 8.8360e-04\n",
      "Epoch 3/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 1.0495 - accuracy: 0.7438 - val_loss: 0.5684 - val_accuracy: 0.8464 - lr: 8.3058e-04\n",
      "Epoch 4/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.9018 - accuracy: 0.7701 - val_loss: 0.5101 - val_accuracy: 0.8475 - lr: 7.8075e-04\n",
      "Epoch 5/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.8145 - accuracy: 0.7869 - val_loss: 0.4323 - val_accuracy: 0.8776 - lr: 7.0267e-04\n",
      "Epoch 6/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.7491 - accuracy: 0.8002 - val_loss: 0.4041 - val_accuracy: 0.8803 - lr: 6.3241e-04\n",
      "Epoch 7/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6874 - accuracy: 0.8124 - val_loss: 0.3744 - val_accuracy: 0.8804 - lr: 5.6917e-04\n",
      "Epoch 8/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6499 - accuracy: 0.8207 - val_loss: 0.3618 - val_accuracy: 0.8941 - lr: 5.1225e-04\n",
      "Epoch 9/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6130 - accuracy: 0.8281 - val_loss: 0.3446 - val_accuracy: 0.9001 - lr: 4.0980e-04\n",
      "Epoch 10/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.5802 - accuracy: 0.8366 - val_loss: 0.3406 - val_accuracy: 0.9030 - lr: 3.2784e-04\n",
      "Epoch 11/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.5565 - accuracy: 0.8433 - val_loss: 0.3277 - val_accuracy: 0.9041 - lr: 2.6227e-04\n",
      "Epoch 12/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.5334 - accuracy: 0.8502 - val_loss: 0.3304 - val_accuracy: 0.9075 - lr: 2.0982e-04\n",
      "Epoch 13/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.5163 - accuracy: 0.8536 - val_loss: 0.3101 - val_accuracy: 0.9124 - lr: 1.6785e-04\n",
      "Epoch 14/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.5068 - accuracy: 0.8548 - val_loss: 0.3113 - val_accuracy: 0.9129 - lr: 1.3428e-04\n",
      "Epoch 15/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.4955 - accuracy: 0.8588 - val_loss: 0.3102 - val_accuracy: 0.9133 - lr: 1.0743e-04\n",
      "Epoch 16/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.4804 - accuracy: 0.8621 - val_loss: 0.3075 - val_accuracy: 0.9146 - lr: 8.5941e-05\n",
      "Epoch 17/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.4804 - accuracy: 0.8632 - val_loss: 0.3034 - val_accuracy: 0.9150 - lr: 6.0159e-05\n",
      "Epoch 18/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.4780 - accuracy: 0.8638 - val_loss: 0.2995 - val_accuracy: 0.9159 - lr: 4.2111e-05\n",
      "Epoch 19/60\n",
      "1251/1251 [==============================] - 4s 4ms/step - loss: 0.4717 - accuracy: 0.8651 - val_loss: 0.3027 - val_accuracy: 0.9168 - lr: 2.9478e-05\n",
      "Epoch 20/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.4622 - accuracy: 0.8680 - val_loss: 0.3028 - val_accuracy: 0.9171 - lr: 1.7687e-05\n",
      "Epoch 21/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.4689 - accuracy: 0.8660 - val_loss: 0.3025 - val_accuracy: 0.9157 - lr: 1.0612e-05\n",
      "Epoch 22/60\n",
      "1251/1251 [==============================] - 5s 4ms/step - loss: 0.4688 - accuracy: 0.8654 - val_loss: 0.3023 - val_accuracy: 0.9164 - lr: 6.3672e-06\n",
      "Epoch 23/60\n",
      "1251/1251 [==============================] - 6s 5ms/step - loss: 0.4602 - accuracy: 0.8677 - val_loss: 0.3015 - val_accuracy: 0.9173 - lr: 3.8203e-06\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2995 - accuracy: 0.9159\n",
      "Accuracy for Stage 4 model: 0.9158757328987122\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "Classification Report for Stage 4 model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      1.00      1.00        56\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.50      0.88      0.64         8\n",
      "           5       0.50      0.17      0.25         6\n",
      "           6       0.60      0.75      0.67         4\n",
      "           7       0.82      0.93      0.88        15\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.00      0.00      0.00         3\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.66      1.00      0.79        23\n",
      "          12       1.00      1.00      1.00        22\n",
      "          13       0.97      0.97      0.97        33\n",
      "          14       0.95      0.95      0.95        22\n",
      "          15       0.77      0.91      0.83        11\n",
      "          16       1.00      1.00      1.00         6\n",
      "          17       0.67      0.44      0.53         9\n",
      "          18       0.83      1.00      0.91         5\n",
      "          19       1.00      0.62      0.77         8\n",
      "          20       1.00      0.20      0.33         5\n",
      "          21       0.92      1.00      0.96        24\n",
      "          22       0.70      1.00      0.82        28\n",
      "          23       1.00      1.00      1.00         3\n",
      "          24       0.00      0.00      0.00         3\n",
      "          25       1.00      0.11      0.20         9\n",
      "          26       0.86      1.00      0.92        12\n",
      "          27       0.90      1.00      0.95        26\n",
      "          28       0.79      1.00      0.88        11\n",
      "          29       0.00      0.00      0.00         3\n",
      "          30       1.00      1.00      1.00         3\n",
      "          31       1.00      1.00      1.00         4\n",
      "          32       0.00      0.00      0.00         4\n",
      "          33       1.00      1.00      1.00        33\n",
      "          34       1.00      1.00      1.00       131\n",
      "          35       0.75      1.00      0.86         6\n",
      "          36       1.00      0.90      0.95        10\n",
      "          37       0.00      0.00      0.00         3\n",
      "          38       1.00      0.62      0.77         8\n",
      "          39       0.80      1.00      0.89        39\n",
      "          40       0.94      0.96      0.95        47\n",
      "          41       0.78      1.00      0.88         7\n",
      "          42       0.50      0.67      0.57         3\n",
      "          43       0.60      1.00      0.75         3\n",
      "          44       0.79      0.74      0.77        31\n",
      "          45       0.00      0.00      0.00         2\n",
      "          46       1.00      1.00      1.00         3\n",
      "          47       1.00      0.50      0.67         2\n",
      "          48       1.00      0.92      0.96        13\n",
      "          49       0.00      0.00      0.00         4\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.50      1.00      0.67         5\n",
      "          52       1.00      1.00      1.00         6\n",
      "          53       1.00      0.67      0.80         3\n",
      "          54       1.00      1.00      1.00       101\n",
      "          55       0.00      0.00      0.00         5\n",
      "          56       0.90      0.94      0.92        48\n",
      "          57       0.65      0.87      0.74        15\n",
      "          58       0.67      0.67      0.67         3\n",
      "          59       0.00      0.00      0.00         2\n",
      "          60       0.76      1.00      0.86        25\n",
      "          61       0.00      0.00      0.00         4\n",
      "          62       1.00      1.00      1.00        36\n",
      "          63       1.00      1.00      1.00         5\n",
      "          64       1.00      0.83      0.91         6\n",
      "          65       1.00      0.60      0.75         5\n",
      "          66       0.00      0.00      0.00         4\n",
      "          67       0.00      0.00      0.00         9\n",
      "          68       1.00      0.77      0.87        13\n",
      "          69       0.00      0.00      0.00         5\n",
      "          70       1.00      0.67      0.80         3\n",
      "          71       0.71      0.77      0.74        13\n",
      "          72       0.00      0.00      0.00         5\n",
      "          73       1.00      0.86      0.92         7\n",
      "          74       0.90      1.00      0.95        18\n",
      "          75       0.93      1.00      0.96        41\n",
      "          76       0.76      1.00      0.87        13\n",
      "          77       1.00      1.00      1.00         7\n",
      "          78       1.00      1.00      1.00       184\n",
      "          79       1.00      1.00      1.00        26\n",
      "          80       0.55      1.00      0.71         6\n",
      "          81       1.00      0.33      0.50         6\n",
      "          82       0.77      1.00      0.87        54\n",
      "          83       1.00      0.17      0.29         6\n",
      "          84       1.00      1.00      1.00        14\n",
      "          85       0.56      1.00      0.71         5\n",
      "          86       0.91      1.00      0.96       204\n",
      "          87       1.00      1.00      1.00         6\n",
      "          88       1.00      0.88      0.93         8\n",
      "          89       0.76      1.00      0.87        13\n",
      "          90       0.83      1.00      0.91        10\n",
      "          91       0.88      0.58      0.70        12\n",
      "          92       0.94      0.94      0.94        18\n",
      "          93       0.67      1.00      0.80         8\n",
      "          94       0.54      1.00      0.70        26\n",
      "          95       1.00      0.33      0.50         3\n",
      "          96       0.00      0.00      0.00         5\n",
      "          97       0.59      1.00      0.74        23\n",
      "          98       1.00      0.95      0.98        44\n",
      "          99       0.60      1.00      0.75         3\n",
      "         100       1.00      1.00      1.00        31\n",
      "         101       0.75      1.00      0.86         3\n",
      "         102       0.85      0.65      0.73        17\n",
      "         103       0.78      0.98      0.87        61\n",
      "         104       0.82      1.00      0.90        14\n",
      "         105       1.00      0.62      0.77         8\n",
      "         106       0.62      1.00      0.76        13\n",
      "         107       0.40      1.00      0.57         2\n",
      "         109       1.00      0.31      0.48        32\n",
      "         110       1.00      0.86      0.92         7\n",
      "         111       0.00      0.00      0.00         2\n",
      "         112       1.00      1.00      1.00        30\n",
      "         113       0.40      1.00      0.57         2\n",
      "         114       0.89      1.00      0.94         8\n",
      "         115       1.00      0.50      0.67         2\n",
      "         116       1.00      1.00      1.00        14\n",
      "         117       1.00      1.00      1.00         3\n",
      "         118       0.88      1.00      0.94        15\n",
      "         119       0.77      0.83      0.80        36\n",
      "         120       0.92      0.92      0.92        13\n",
      "         121       1.00      1.00      1.00         3\n",
      "         122       1.00      0.40      0.57         5\n",
      "         123       0.00      0.00      0.00         1\n",
      "         124       1.00      0.33      0.50         6\n",
      "         125       0.82      0.97      0.89        29\n",
      "         126       1.00      1.00      1.00         4\n",
      "         127       0.62      0.91      0.74        11\n",
      "         128       1.00      1.00      1.00        13\n",
      "         129       0.93      1.00      0.96        26\n",
      "         130       0.75      0.75      0.75         8\n",
      "         131       0.39      0.90      0.55        10\n",
      "         132       0.00      0.00      0.00         4\n",
      "         133       0.61      0.95      0.75        40\n",
      "         134       0.75      0.30      0.43        10\n",
      "         135       1.00      1.00      1.00        19\n",
      "         136       1.00      0.83      0.91         6\n",
      "         137       1.00      0.73      0.84        11\n",
      "         138       0.96      0.90      0.92        48\n",
      "         139       0.60      0.43      0.50        14\n",
      "         140       1.00      0.75      0.86         8\n",
      "         141       1.00      0.77      0.87        13\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.67      1.00      0.80         2\n",
      "         144       0.98      1.00      0.99        80\n",
      "         145       0.98      1.00      0.99        41\n",
      "         146       0.95      0.95      0.95        20\n",
      "         147       1.00      1.00      1.00         2\n",
      "         148       0.70      1.00      0.82         7\n",
      "         149       1.00      1.00      1.00        21\n",
      "         150       0.50      0.71      0.59         7\n",
      "         151       1.00      0.67      0.80         6\n",
      "         152       0.00      0.00      0.00         7\n",
      "         153       0.89      1.00      0.94         8\n",
      "         154       1.00      1.00      1.00         3\n",
      "         155       1.00      1.00      1.00         5\n",
      "         156       1.00      1.00      1.00         4\n",
      "         157       0.91      0.94      0.93        33\n",
      "         158       1.00      0.38      0.55        16\n",
      "         159       0.79      1.00      0.88        41\n",
      "         160       1.00      0.57      0.73         7\n",
      "         161       0.90      1.00      0.95         9\n",
      "         162       0.77      0.48      0.59        21\n",
      "         163       1.00      1.00      1.00         6\n",
      "         164       1.00      0.40      0.57         5\n",
      "         165       0.93      1.00      0.96        13\n",
      "         166       1.00      1.00      1.00         6\n",
      "         167       0.58      1.00      0.73        11\n",
      "         168       1.00      0.33      0.50         3\n",
      "         169       1.00      0.25      0.40         4\n",
      "         170       1.00      0.33      0.50         3\n",
      "         171       0.00      0.00      0.00         5\n",
      "         172       1.00      1.00      1.00         3\n",
      "         173       1.00      1.00      1.00        23\n",
      "         174       1.00      1.00      1.00         6\n",
      "         175       1.00      1.00      1.00        25\n",
      "         176       0.83      0.42      0.56        12\n",
      "         177       0.80      0.80      0.80         5\n",
      "         178       1.00      0.67      0.80         3\n",
      "         179       1.00      0.86      0.92         7\n",
      "         180       1.00      0.78      0.88         9\n",
      "         181       0.00      0.00      0.00         4\n",
      "         182       1.00      1.00      1.00         4\n",
      "         183       0.75      0.50      0.60        36\n",
      "         184       1.00      0.91      0.95        11\n",
      "         185       1.00      0.83      0.91         6\n",
      "         186       0.00      0.00      0.00         6\n",
      "         187       0.92      1.00      0.96        11\n",
      "         188       0.90      1.00      0.95         9\n",
      "         189       0.93      0.87      0.90        46\n",
      "         190       0.61      0.89      0.73        37\n",
      "         191       0.78      0.99      0.87        69\n",
      "         192       0.73      0.92      0.81        12\n",
      "         193       0.00      0.00      0.00         3\n",
      "         195       1.00      0.83      0.91         6\n",
      "         196       0.86      1.00      0.92         6\n",
      "         198       0.97      0.94      0.96        34\n",
      "         199       1.00      1.00      1.00        17\n",
      "         200       1.00      1.00      1.00         6\n",
      "         201       0.95      1.00      0.98        21\n",
      "         202       1.00      0.67      0.80         3\n",
      "         203       0.88      0.78      0.82         9\n",
      "         204       1.00      1.00      1.00         7\n",
      "         205       0.74      1.00      0.85        14\n",
      "         206       0.85      0.94      0.89        65\n",
      "         207       1.00      1.00      1.00         4\n",
      "         208       1.00      0.33      0.50         3\n",
      "         209       1.00      0.40      0.57         5\n",
      "         210       0.00      0.00      0.00         1\n",
      "         211       0.96      0.96      0.96        91\n",
      "         212       0.94      0.89      0.92        38\n",
      "         213       0.50      0.50      0.50         4\n",
      "         214       1.00      1.00      1.00         5\n",
      "         215       0.60      0.86      0.71         7\n",
      "         216       0.75      0.75      0.75         4\n",
      "         217       1.00      1.00      1.00         1\n",
      "         218       1.00      1.00      1.00        47\n",
      "         219       0.99      1.00      1.00       110\n",
      "         220       1.00      0.89      0.94        19\n",
      "         221       0.85      0.92      0.88        12\n",
      "         222       0.90      1.00      0.95        19\n",
      "         223       1.00      1.00      1.00        19\n",
      "         224       1.00      1.00      1.00         2\n",
      "         226       1.00      1.00      1.00        11\n",
      "         227       0.00      0.00      0.00         1\n",
      "         228       0.96      0.76      0.85        29\n",
      "         229       0.00      0.00      0.00         5\n",
      "         230       0.80      1.00      0.89         4\n",
      "         231       1.00      1.00      1.00        10\n",
      "         232       1.00      1.00      1.00        28\n",
      "         233       1.00      0.88      0.93         8\n",
      "         234       0.62      0.80      0.70        10\n",
      "         235       1.00      0.50      0.67         6\n",
      "         236       1.00      1.00      1.00         9\n",
      "         237       1.00      0.22      0.36         9\n",
      "         238       0.77      1.00      0.87        27\n",
      "         239       0.73      0.73      0.73        15\n",
      "         240       0.88      1.00      0.94        23\n",
      "         241       1.00      1.00      1.00         5\n",
      "         242       0.00      0.00      0.00         1\n",
      "         243       0.72      0.90      0.80        29\n",
      "         244       0.50      0.67      0.57         3\n",
      "         245       0.00      0.00      0.00         4\n",
      "         246       0.00      0.00      0.00         5\n",
      "         247       0.89      0.73      0.80        11\n",
      "         248       1.00      1.00      1.00         2\n",
      "         249       1.00      0.78      0.88         9\n",
      "         250       1.00      1.00      1.00         1\n",
      "         251       1.00      1.00      1.00         2\n",
      "         252       0.96      1.00      0.98        51\n",
      "         253       1.00      0.88      0.93        16\n",
      "         254       0.00      0.00      0.00         2\n",
      "         255       1.00      1.00      1.00        18\n",
      "         256       1.00      0.42      0.59        12\n",
      "         257       0.80      1.00      0.89        20\n",
      "         258       1.00      0.50      0.67        10\n",
      "         259       0.76      0.87      0.81        15\n",
      "         260       0.73      1.00      0.84        16\n",
      "         261       1.00      0.20      0.33         5\n",
      "         262       0.67      0.67      0.67         3\n",
      "         263       0.80      0.67      0.73         6\n",
      "         264       1.00      0.10      0.18        10\n",
      "         265       0.80      0.80      0.80         5\n",
      "         266       0.67      0.50      0.57         8\n",
      "         267       0.50      0.25      0.33         4\n",
      "         268       0.00      0.00      0.00         1\n",
      "         269       0.25      0.50      0.33         2\n",
      "         270       0.89      0.67      0.76        12\n",
      "         271       0.65      0.85      0.73        13\n",
      "         272       1.00      0.25      0.40         4\n",
      "         273       1.00      0.90      0.95        10\n",
      "         274       0.93      0.88      0.90        16\n",
      "         275       0.81      1.00      0.90        13\n",
      "         276       0.77      1.00      0.87        23\n",
      "         277       0.85      0.94      0.89        36\n",
      "         278       0.92      0.97      0.94        91\n",
      "         279       1.00      1.00      1.00        11\n",
      "         280       1.00      1.00      1.00        29\n",
      "         281       0.88      0.88      0.88        16\n",
      "         282       0.00      0.00      0.00         3\n",
      "         283       0.76      0.94      0.84        17\n",
      "         284       0.92      0.95      0.94        61\n",
      "         285       1.00      0.36      0.53        11\n",
      "         286       0.00      0.00      0.00         8\n",
      "         287       0.80      0.80      0.80         5\n",
      "         288       0.58      0.85      0.69        13\n",
      "         289       0.88      1.00      0.94        22\n",
      "         290       0.93      1.00      0.97        28\n",
      "         291       0.44      1.00      0.62         4\n",
      "         292       0.67      1.00      0.80        10\n",
      "         293       1.00      0.67      0.80         3\n",
      "         294       1.00      1.00      1.00         1\n",
      "         295       0.89      0.89      0.89         9\n",
      "         296       1.00      0.50      0.67         2\n",
      "         297       0.00      0.00      0.00         1\n",
      "         298       1.00      1.00      1.00        10\n",
      "         299       0.83      1.00      0.91         5\n",
      "         300       1.00      1.00      1.00        34\n",
      "         301       0.00      0.00      0.00         4\n",
      "         302       1.00      1.00      1.00        15\n",
      "         303       0.00      0.00      0.00         2\n",
      "         304       0.90      0.75      0.82        24\n",
      "         305       0.75      1.00      0.86         9\n",
      "         306       1.00      0.60      0.75         5\n",
      "         307       0.95      1.00      0.97        19\n",
      "         308       0.73      1.00      0.84         8\n",
      "         309       1.00      1.00      1.00         4\n",
      "         310       1.00      1.00      1.00         3\n",
      "         311       0.92      1.00      0.96       358\n",
      "         312       1.00      0.62      0.76        13\n",
      "         313       0.67      1.00      0.80         2\n",
      "         314       0.97      0.97      0.97      4512\n",
      "         315       0.69      0.50      0.58       300\n",
      "\n",
      "    accuracy                           0.92     10009\n",
      "   macro avg       0.76      0.73      0.72     10009\n",
      "weighted avg       0.91      0.92      0.91     10009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OWNER\\Desktop\\AnyoneAI\\final_project\\venv2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\OWNER\\Desktop\\AnyoneAI\\final_project\\venv2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\OWNER\\Desktop\\AnyoneAI\\final_project\\venv2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Stage 4\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 4:\n",
    "        return lr * 0.94\n",
    "    elif epoch < 8:\n",
    "        return lr * 0.9\n",
    "    elif epoch < 16:\n",
    "        return lr * 0.80\n",
    "    elif epoch < 19:\n",
    "        return lr * 0.70\n",
    "    else:\n",
    "        return lr * 0.6\n",
    "\n",
    "# Define common callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler_callback = callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Create model\n",
    "model_4 = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_combined_3.shape[1],)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes_3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model_4.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Fit model\n",
    "history_4 = model_4.fit(X_train_combined_3, y_train_3, epochs=60, batch_size=32,\n",
    "                        validation_data=(X_test_combined_3, y_test_3),\n",
    "                        callbacks=[early_stopping, lr_scheduler_callback])\n",
    "\n",
    "# Save model\n",
    "save_model(model_4, 'model_4_preberttune.h5')\n",
    "\n",
    "# Evaluate model\n",
    "loss_4, accuracy_4 = model_4.evaluate(X_test_combined_3, y_test_3)\n",
    "print(\"Accuracy for Stage 4 model:\", accuracy_4)\n",
    "\n",
    "# Generate classification report\n",
    "y_pred_probabilities_4 = model_4.predict(X_test_combined_3)\n",
    "y_pred_4 = np.argmax(y_pred_probabilities_4, axis=1)\n",
    "report_4 = classification_report(y_test_3, y_pred_4)\n",
    "print(\"Classification Report for Stage 4 model:\")\n",
    "print(report_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZuOdg-p0an8",
    "outputId": "ebf96bf4-a924-41f8-9747-8223d215578c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Stage 5 model...\n",
      "Epoch 1/60\n",
      "1251/1251 [==============================] - 5s 4ms/step - loss: 1.5423 - accuracy: 0.7581 - val_loss: 0.5663 - val_accuracy: 0.8785 - lr: 9.4000e-04\n",
      "Epoch 2/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.6838 - accuracy: 0.8587 - val_loss: 0.4186 - val_accuracy: 0.9025 - lr: 8.8360e-04\n",
      "Epoch 3/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.5449 - accuracy: 0.8736 - val_loss: 0.3294 - val_accuracy: 0.9112 - lr: 8.3058e-04\n",
      "Epoch 4/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.4665 - accuracy: 0.8844 - val_loss: 0.2741 - val_accuracy: 0.9200 - lr: 7.8075e-04\n",
      "Epoch 5/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.4180 - accuracy: 0.8925 - val_loss: 0.2524 - val_accuracy: 0.9310 - lr: 7.0267e-04\n",
      "Epoch 6/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3787 - accuracy: 0.8972 - val_loss: 0.2349 - val_accuracy: 0.9314 - lr: 6.3241e-04\n",
      "Epoch 7/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3499 - accuracy: 0.9032 - val_loss: 0.2184 - val_accuracy: 0.9327 - lr: 5.6917e-04\n",
      "Epoch 8/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3216 - accuracy: 0.9100 - val_loss: 0.2072 - val_accuracy: 0.9366 - lr: 5.1225e-04\n",
      "Epoch 9/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.3027 - accuracy: 0.9130 - val_loss: 0.1970 - val_accuracy: 0.9389 - lr: 4.0980e-04\n",
      "Epoch 10/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.2952 - accuracy: 0.9163 - val_loss: 0.1985 - val_accuracy: 0.9409 - lr: 3.2784e-04\n",
      "Epoch 11/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.2804 - accuracy: 0.9199 - val_loss: 0.1881 - val_accuracy: 0.9441 - lr: 2.6227e-04\n",
      "Epoch 12/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.2756 - accuracy: 0.9207 - val_loss: 0.1838 - val_accuracy: 0.9446 - lr: 2.0982e-04\n",
      "Epoch 13/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.2664 - accuracy: 0.9232 - val_loss: 0.1817 - val_accuracy: 0.9451 - lr: 1.6785e-04\n",
      "Epoch 14/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.2551 - accuracy: 0.9253 - val_loss: 0.1772 - val_accuracy: 0.9457 - lr: 1.3428e-04\n",
      "Epoch 15/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.2535 - accuracy: 0.9240 - val_loss: 0.1776 - val_accuracy: 0.9447 - lr: 1.0743e-04\n",
      "Epoch 16/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.2487 - accuracy: 0.9270 - val_loss: 0.1791 - val_accuracy: 0.9454 - lr: 8.5941e-05\n",
      "Epoch 17/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.2439 - accuracy: 0.9273 - val_loss: 0.1764 - val_accuracy: 0.9450 - lr: 6.0159e-05\n",
      "Epoch 18/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.2421 - accuracy: 0.9295 - val_loss: 0.1751 - val_accuracy: 0.9459 - lr: 4.2111e-05\n",
      "Epoch 19/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.2388 - accuracy: 0.9305 - val_loss: 0.1751 - val_accuracy: 0.9461 - lr: 2.9478e-05\n",
      "Epoch 20/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.2340 - accuracy: 0.9301 - val_loss: 0.1736 - val_accuracy: 0.9466 - lr: 1.7687e-05\n",
      "Epoch 21/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.2307 - accuracy: 0.9297 - val_loss: 0.1753 - val_accuracy: 0.9463 - lr: 1.0612e-05\n",
      "Epoch 22/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.2364 - accuracy: 0.9285 - val_loss: 0.1742 - val_accuracy: 0.9458 - lr: 6.3672e-06\n",
      "Epoch 23/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.2363 - accuracy: 0.9293 - val_loss: 0.1747 - val_accuracy: 0.9466 - lr: 3.8203e-06\n",
      "Epoch 24/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.2383 - accuracy: 0.9293 - val_loss: 0.1736 - val_accuracy: 0.9463 - lr: 2.2922e-06\n",
      "Epoch 25/60\n",
      "1251/1251 [==============================] - 4s 3ms/step - loss: 0.2346 - accuracy: 0.9292 - val_loss: 0.1739 - val_accuracy: 0.9466 - lr: 1.3753e-06\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1736 - accuracy: 0.9466\n",
      "Accuracy for Stage 5 model: 0.9466480016708374\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "Classification Report for Stage 5 model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        13\n",
      "           1       0.85      0.94      0.89        18\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       1.00      0.75      0.86         4\n",
      "           4       1.00      0.80      0.89         5\n",
      "           5       0.78      1.00      0.88        71\n",
      "           6       1.00      0.60      0.75         5\n",
      "           7       1.00      1.00      1.00        18\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       1.00      1.00      1.00         1\n",
      "          10       0.93      0.84      0.89        32\n",
      "          11       0.00      0.00      0.00         3\n",
      "          12       0.67      0.67      0.67         6\n",
      "          13       0.55      0.67      0.60         9\n",
      "          14       0.00      0.00      0.00         4\n",
      "          15       0.59      1.00      0.74        10\n",
      "          16       0.50      0.59      0.54        17\n",
      "          17       0.76      0.91      0.83        65\n",
      "          18       1.00      1.00      1.00        12\n",
      "          19       0.50      1.00      0.67         6\n",
      "          20       0.22      0.40      0.29         5\n",
      "          21       0.00      0.00      0.00         1\n",
      "          22       0.92      0.85      0.88        13\n",
      "          23       1.00      0.50      0.67         2\n",
      "          24       0.75      0.86      0.80         7\n",
      "          25       0.50      0.93      0.65        14\n",
      "          26       0.93      0.98      0.96        88\n",
      "          27       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         8\n",
      "          29       1.00      1.00      1.00         3\n",
      "          31       0.45      0.71      0.56         7\n",
      "          32       1.00      0.91      0.95        11\n",
      "          33       0.00      0.00      0.00         5\n",
      "          34       1.00      1.00      1.00        14\n",
      "          35       0.97      0.99      0.98       140\n",
      "          36       0.53      0.62      0.57        13\n",
      "          37       0.82      0.96      0.89        28\n",
      "          38       0.80      0.31      0.44        13\n",
      "          39       1.00      1.00      1.00        13\n",
      "          40       1.00      0.50      0.67         4\n",
      "          41       0.50      0.86      0.63         7\n",
      "          42       0.62      1.00      0.77         5\n",
      "          43       0.00      0.00      0.00         3\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.00      0.00      0.00         9\n",
      "          46       0.80      1.00      0.89        16\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       1.00      1.00      1.00        54\n",
      "          49       0.00      0.00      0.00         6\n",
      "          50       0.75      1.00      0.86         6\n",
      "          51       0.00      0.00      0.00         5\n",
      "          52       0.90      1.00      0.95         9\n",
      "          53       0.87      1.00      0.93        13\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       0.00      0.00      0.00         5\n",
      "          56       1.00      0.60      0.75         5\n",
      "          57       0.50      0.50      0.50         2\n",
      "          58       0.53      1.00      0.69        19\n",
      "          59       0.67      1.00      0.80         4\n",
      "          60       0.60      0.60      0.60         5\n",
      "          61       0.54      0.88      0.67         8\n",
      "          62       0.96      1.00      0.98        54\n",
      "          63       0.00      0.00      0.00         3\n",
      "          64       1.00      0.67      0.80        12\n",
      "          65       1.00      0.30      0.46        10\n",
      "          66       0.65      1.00      0.79        11\n",
      "          67       0.25      0.17      0.20         6\n",
      "          68       1.00      0.75      0.86         8\n",
      "          69       0.29      1.00      0.44         2\n",
      "          70       0.00      0.00      0.00         4\n",
      "          71       0.00      0.00      0.00         6\n",
      "          72       0.75      1.00      0.86         6\n",
      "          73       0.71      0.77      0.74        22\n",
      "          74       0.62      0.62      0.62        16\n",
      "          75       0.00      0.00      0.00         3\n",
      "          76       0.82      0.60      0.69        15\n",
      "          77       0.56      1.00      0.71         5\n",
      "          78       0.00      0.00      0.00         7\n",
      "          80       0.00      0.00      0.00         4\n",
      "          81       1.00      0.78      0.88         9\n",
      "          82       1.00      0.94      0.97        17\n",
      "          83       1.00      0.90      0.95        10\n",
      "          84       1.00      1.00      1.00         6\n",
      "          85       0.33      0.60      0.43         5\n",
      "          86       0.50      0.11      0.18         9\n",
      "          87       0.91      1.00      0.95        30\n",
      "          88       0.00      0.00      0.00         3\n",
      "          89       0.82      1.00      0.90         9\n",
      "          90       0.47      0.82      0.60        11\n",
      "          91       1.00      1.00      1.00         1\n",
      "          92       0.00      0.00      0.00         1\n",
      "          93       0.64      0.75      0.69        12\n",
      "          94       0.00      0.00      0.00         5\n",
      "          95       0.60      0.43      0.50         7\n",
      "          96       1.00      1.00      1.00         5\n",
      "          97       1.00      1.00      1.00         2\n",
      "          98       0.00      0.00      0.00         3\n",
      "          99       1.00      1.00      1.00        13\n",
      "         100       0.91      1.00      0.95        10\n",
      "         101       0.69      1.00      0.82         9\n",
      "         102       0.67      0.50      0.57         4\n",
      "         103       0.00      0.00      0.00         2\n",
      "         104       1.00      1.00      1.00         2\n",
      "         105       0.86      1.00      0.92         6\n",
      "         106       0.94      1.00      0.97        15\n",
      "         107       1.00      0.67      0.80         3\n",
      "         108       0.91      1.00      0.95        10\n",
      "         109       0.40      1.00      0.57        20\n",
      "         110       0.88      0.88      0.88         8\n",
      "         111       0.97      1.00      0.98        29\n",
      "         112       0.00      0.00      0.00         2\n",
      "         113       0.57      0.67      0.62         6\n",
      "         114       0.76      1.00      0.87        13\n",
      "         115       1.00      0.07      0.13        14\n",
      "         116       0.54      1.00      0.70        15\n",
      "         117       1.00      0.17      0.29        18\n",
      "         118       1.00      0.60      0.75         5\n",
      "         119       0.82      1.00      0.90        42\n",
      "         120       0.00      0.00      0.00         2\n",
      "         121       0.00      0.00      0.00         4\n",
      "         122       0.00      0.00      0.00         3\n",
      "         123       1.00      0.33      0.50         3\n",
      "         124       0.00      0.00      0.00         1\n",
      "         125       0.80      1.00      0.89         4\n",
      "         126       1.00      1.00      1.00         5\n",
      "         127       1.00      1.00      1.00         6\n",
      "         128       0.00      0.00      0.00         6\n",
      "         129       0.75      0.75      0.75         4\n",
      "         130       0.00      0.00      0.00         2\n",
      "         131       0.00      0.00      0.00         4\n",
      "         132       0.67      0.25      0.36         8\n",
      "         133       0.00      0.00      0.00         5\n",
      "         134       0.44      1.00      0.61        14\n",
      "         135       0.50      0.33      0.40         3\n",
      "         136       1.00      1.00      1.00         3\n",
      "         137       1.00      1.00      1.00         3\n",
      "         138       0.00      0.00      0.00        10\n",
      "         139       0.00      0.00      0.00         1\n",
      "         140       0.64      0.78      0.70         9\n",
      "         141       0.00      0.00      0.00         4\n",
      "         142       0.44      1.00      0.61         7\n",
      "         143       0.74      0.74      0.74        19\n",
      "         144       0.85      1.00      0.92        40\n",
      "         145       1.00      0.20      0.33         5\n",
      "         146       0.93      0.93      0.93        14\n",
      "         147       1.00      0.33      0.50         3\n",
      "         148       1.00      0.86      0.92         7\n",
      "         149       0.75      0.50      0.60         6\n",
      "         150       0.50      0.75      0.60         8\n",
      "         151       0.33      0.12      0.18         8\n",
      "         152       1.00      0.50      0.67         6\n",
      "         153       0.00      0.00      0.00         4\n",
      "         154       0.46      1.00      0.63        13\n",
      "         155       0.00      0.00      0.00         2\n",
      "         156       0.00      0.00      0.00         3\n",
      "         157       0.00      0.00      0.00         3\n",
      "         158       0.94      0.72      0.82        40\n",
      "         159       0.94      0.65      0.77        26\n",
      "         160       0.99      0.99      0.99      8119\n",
      "         161       0.65      0.50      0.57       106\n",
      "\n",
      "    accuracy                           0.95     10009\n",
      "   macro avg       0.58      0.58      0.55     10009\n",
      "weighted avg       0.94      0.95      0.94     10009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OWNER\\Desktop\\AnyoneAI\\final_project\\venv2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\OWNER\\Desktop\\AnyoneAI\\final_project\\venv2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\OWNER\\Desktop\\AnyoneAI\\final_project\\venv2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Stage 5\n",
    "print(\"Running Stage 5 model...\")\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 4:\n",
    "        return lr * 0.94\n",
    "    elif epoch < 8:\n",
    "        return lr * 0.9\n",
    "    elif epoch < 16:\n",
    "        return lr * 0.80\n",
    "    elif epoch < 19:\n",
    "        return lr * 0.70\n",
    "    else:\n",
    "        return lr * 0.6\n",
    "\n",
    "# Define common callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler_callback = callbacks.LearningRateScheduler(lr_scheduler)\n",
    "# Create model\n",
    "model_5 = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_combined_4.shape[1],)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes_4, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model_5.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Fit model\n",
    "history_5 = model_5.fit(X_train_combined_4, y_train_4, epochs=60, batch_size=32,\n",
    "                        validation_data=(X_test_combined_4, y_test_4),\n",
    "                        callbacks=[early_stopping, lr_scheduler_callback])\n",
    "\n",
    "# Save model\n",
    "save_model(model_5, 'model_5_preberttune.h5')\n",
    "\n",
    "# Evaluate model\n",
    "loss_5, accuracy_5 = model_5.evaluate(X_test_combined_4, y_test_4)\n",
    "print(\"Accuracy for Stage 5 model:\", accuracy_5)\n",
    "\n",
    "# Generate classification report\n",
    "y_pred_probabilities_5 = model_5.predict(X_test_combined_4)\n",
    "y_pred_5 = np.argmax(y_pred_probabilities_5, axis=1)\n",
    "report_5 = classification_report(y_test_4, y_pred_5)\n",
    "print(\"Classification Report for Stage 5 model:\")\n",
    "print(report_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U86tSFRP0an9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "19e710cd65dd42f6b6e9cad415a95543": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b33fb027db2049f582d01999b6e781f6",
       "IPY_MODEL_0a8dc7b85690495ca5d606d0041f5df2",
       "IPY_MODEL_7148937877b846c4a41b3bc2008357b4"
      ],
      "layout": "IPY_MODEL_54326cdb44f54ae0807d93c9ee81199c"
     }
    },
    "b33fb027db2049f582d01999b6e781f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78acdd4bd63d4094a805d498cba90e7c",
      "placeholder": "​",
      "style": "IPY_MODEL_38623c1beb744dbca6b7293a188ce2c2",
      "value": "model.safetensors: 100%"
     }
    },
    "0a8dc7b85690495ca5d606d0041f5df2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e848d2663c74e1db983e16f8ca14a29",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6788ea4f28ad4b2580679f26ec449750",
      "value": 440449768
     }
    },
    "7148937877b846c4a41b3bc2008357b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44f00a5c78ee4171bdfa0492d05fd127",
      "placeholder": "​",
      "style": "IPY_MODEL_ab4a681379364c80b8d6b9d901b382c3",
      "value": " 440M/440M [00:01&lt;00:00, 359MB/s]"
     }
    },
    "54326cdb44f54ae0807d93c9ee81199c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78acdd4bd63d4094a805d498cba90e7c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38623c1beb744dbca6b7293a188ce2c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4e848d2663c74e1db983e16f8ca14a29": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6788ea4f28ad4b2580679f26ec449750": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "44f00a5c78ee4171bdfa0492d05fd127": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab4a681379364c80b8d6b9d901b382c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e80ff28fa61c4bf7b66e9f933f883459": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2e35b3521ef2456796fe6fb2c2563dd4",
       "IPY_MODEL_e9b86d98944a4158ac5e325b9bce29d8",
       "IPY_MODEL_630c3ad086f0450990871c2354adfe59"
      ],
      "layout": "IPY_MODEL_88734b83019743bcb0825339c7a88b23"
     }
    },
    "2e35b3521ef2456796fe6fb2c2563dd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_462282c30abe4d13ba07fcc2b614e858",
      "placeholder": "​",
      "style": "IPY_MODEL_3ea8a68984e74c99a4667022575b0bcb",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "e9b86d98944a4158ac5e325b9bce29d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bcf451f4418f4057a8a257fa63f9f19f",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5264108c2c894e84b1a17e3f24e128a2",
      "value": 48
     }
    },
    "630c3ad086f0450990871c2354adfe59": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa6eb28c0004448ca9d57ddfe77592e8",
      "placeholder": "​",
      "style": "IPY_MODEL_c2afb96ddf7a46b687b5663120d7d2d8",
      "value": " 48.0/48.0 [00:00&lt;00:00, 4.13kB/s]"
     }
    },
    "88734b83019743bcb0825339c7a88b23": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "462282c30abe4d13ba07fcc2b614e858": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ea8a68984e74c99a4667022575b0bcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bcf451f4418f4057a8a257fa63f9f19f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5264108c2c894e84b1a17e3f24e128a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fa6eb28c0004448ca9d57ddfe77592e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2afb96ddf7a46b687b5663120d7d2d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "becf2cd329f54f69a39e0e934e0dee52": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_40b06ec082c24feba9332763b23c3a3b",
       "IPY_MODEL_b37c23a49ca24774b520f1e926ad5fdd",
       "IPY_MODEL_06c69fd05e6b4219a11d16020fb5793b"
      ],
      "layout": "IPY_MODEL_0e9f8e8f8f8c443c9b42ec21f85951ce"
     }
    },
    "40b06ec082c24feba9332763b23c3a3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3227256403f441ebbbd36f4e0d67298b",
      "placeholder": "​",
      "style": "IPY_MODEL_97b8d3640af949b2bdc54ac0d3541020",
      "value": "vocab.txt: 100%"
     }
    },
    "b37c23a49ca24774b520f1e926ad5fdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d841380aadf946e9a9fe38298c13b15a",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d1912f4124fc41e2950dbbd9b6ad2c70",
      "value": 231508
     }
    },
    "06c69fd05e6b4219a11d16020fb5793b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08ffe43f797949f3b0bf526af2e1224a",
      "placeholder": "​",
      "style": "IPY_MODEL_9625d3e8f4034e09842f0e476424affd",
      "value": " 232k/232k [00:00&lt;00:00, 13.9MB/s]"
     }
    },
    "0e9f8e8f8f8c443c9b42ec21f85951ce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3227256403f441ebbbd36f4e0d67298b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97b8d3640af949b2bdc54ac0d3541020": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d841380aadf946e9a9fe38298c13b15a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1912f4124fc41e2950dbbd9b6ad2c70": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "08ffe43f797949f3b0bf526af2e1224a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9625d3e8f4034e09842f0e476424affd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11a44798da12452da205bdbf8b49b5f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a5e6aa5ff3264e858c2a9650f0b62038",
       "IPY_MODEL_28122700c83e40cc8cdd49f0a4576afe",
       "IPY_MODEL_2c9b838e2d9f48d88ab18924ab688e39"
      ],
      "layout": "IPY_MODEL_c9d5753fee8543bd9cba6892f7ebdea8"
     }
    },
    "a5e6aa5ff3264e858c2a9650f0b62038": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b37e461910b14693bd9f11d5c9cd7b12",
      "placeholder": "​",
      "style": "IPY_MODEL_c29078f6ec5e4cd4a287c049e9bccf6f",
      "value": "tokenizer.json: 100%"
     }
    },
    "28122700c83e40cc8cdd49f0a4576afe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b1759174eec433ebc5e002fd53cf862",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_73ff3cfd5ab245a09cf9215769234a55",
      "value": 466062
     }
    },
    "2c9b838e2d9f48d88ab18924ab688e39": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9192c824bad4e4781a6a7e68adfc1b4",
      "placeholder": "​",
      "style": "IPY_MODEL_81d6213433ff4faeaaa9622dd45250ac",
      "value": " 466k/466k [00:00&lt;00:00, 34.1MB/s]"
     }
    },
    "c9d5753fee8543bd9cba6892f7ebdea8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b37e461910b14693bd9f11d5c9cd7b12": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c29078f6ec5e4cd4a287c049e9bccf6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b1759174eec433ebc5e002fd53cf862": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73ff3cfd5ab245a09cf9215769234a55": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a9192c824bad4e4781a6a7e68adfc1b4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81d6213433ff4faeaaa9622dd45250ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca16fc679af04321ac5a62a5dbd951c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_70f7d810a2d1459e96de7cf70d3a5bbf",
       "IPY_MODEL_81840a7dd7bd4a14bce6a0a23747711b",
       "IPY_MODEL_df44cf854f3a4e72bbae4392ac91680a"
      ],
      "layout": "IPY_MODEL_2666a47bc9624d89a4a50e389c018001"
     }
    },
    "70f7d810a2d1459e96de7cf70d3a5bbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_256c82d6dba946429e497310eba68872",
      "placeholder": "​",
      "style": "IPY_MODEL_51697330d6d9456c8ab0d827150aac8c",
      "value": "config.json: 100%"
     }
    },
    "81840a7dd7bd4a14bce6a0a23747711b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df2df5bb2d8c4481921ba093fd799cac",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9b31888981d5443187ba5e68f61e2eee",
      "value": 570
     }
    },
    "df44cf854f3a4e72bbae4392ac91680a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e55056d3cabc4affa674336320d62e6c",
      "placeholder": "​",
      "style": "IPY_MODEL_f620efe782c34c80844a244ab03bc28d",
      "value": " 570/570 [00:00&lt;00:00, 49.1kB/s]"
     }
    },
    "2666a47bc9624d89a4a50e389c018001": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "256c82d6dba946429e497310eba68872": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51697330d6d9456c8ab0d827150aac8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df2df5bb2d8c4481921ba093fd799cac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b31888981d5443187ba5e68f61e2eee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e55056d3cabc4affa674336320d62e6c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f620efe782c34c80844a244ab03bc28d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
