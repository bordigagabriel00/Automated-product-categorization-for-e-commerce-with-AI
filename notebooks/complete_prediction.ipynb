{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgVLcjCaDSIo",
    "outputId": "5fa86645-4e69-4e99-eb7d-0ab9688899a8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Importing...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from typing import Optional\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "from transformers import AutoTokenizer\n",
    "from scipy.sparse import hstack\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import h5py\n",
    "import pickle\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "print(\"Importing...\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize NLTK resources\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return 'a'  # Adjective\n",
    "    elif tag.startswith('V'):\n",
    "        return 'v'  # Verb\n",
    "    elif tag.startswith('N'):\n",
    "        return 'n'  # Noun\n",
    "    elif tag.startswith('R'):\n",
    "        return 'r'  # Adverb\n",
    "    else:\n",
    "        return 'n'  # Default to noun if not recognized\n",
    "\n",
    "\n",
    "def remove_extra_new_lines(text):\n",
    "    if pd.isnull(text):  # check if text is nan\n",
    "        return ''  # replace with an empty string\n",
    "\n",
    "    clean_text = [i for i in str(text).splitlines() if i.strip()]\n",
    "    clean_text = ' '.join(clean_text)\n",
    "    return clean_text\n",
    "\n",
    "\n",
    "def remove_extra_whitespace(text: str) -> str:\n",
    "    spaceless_text = re.sub(r'\\s+', ' ', text)\n",
    "    return spaceless_text\n",
    "\n",
    "\n",
    "def remove_special_chars(text: str, remove_digits: Optional[bool] = False) -> str:\n",
    "    if remove_digits:\n",
    "        pattern = r'[^a-zA-Z\\s]'\n",
    "    else:\n",
    "        pattern = r'[^a-zA-Z0-9\\s]'\n",
    "\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = remove_extra_new_lines(text)\n",
    "\n",
    "    text = remove_extra_whitespace(text)\n",
    "\n",
    "    text = remove_special_chars(text, remove_digits=False)\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha() and token.lower() not in stop_words]\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    lemmas = [lemmatizer.lemmatize(token, get_wordnet_pos(tag)) for token, tag in tagged_tokens]\n",
    "\n",
    "    return ' '.join(lemmas)"
   ],
   "metadata": {
    "id": "M7eR8j1REleZ"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "categorical_columns = ['type', 'manufacturer']"
   ],
   "metadata": {
    "id": "KV2_EvFMG458"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "user_input = {\n",
    "    \"name\": \"LoDuca Bros Inc - Professional Digital Photo Studio Kit - Black/White/Blue\",\n",
    "    \"description\": \"LODUCA BROS INC Professional Digital Photo Studio Kit: Lets you take professional-quality photos; includes 2 high-output tabletop lights, a 16 cubed soft-lighting frame and an adjustable mini tabletop tripod; multicompartment, padded carrying case\",\n",
    "    \"price\": 49.99,\n",
    "    \"type\": \"HardGood\",\n",
    "    \"manufacturer\": \"LoDuca Bros Inc\",\n",
    "}"
   ],
   "metadata": {
    "id": "9cBytT7WEwfy"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predic 1: 'parent_category'"
   ],
   "metadata": {
    "id": "e_sAUfM-JVfr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 'model_1_preberttune.h5'\n",
    "model_1 = load_model('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/models/model_1_preberttune.h5')\n",
    "# 'encoder.pkl'\n",
    "with open('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/encoder/encoder.pkl', 'rb') as file:\n",
    "    encoder = pickle.load(file)\n",
    "# 'scaler.pkl'\n",
    "with open('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/scaler/scaler.pkl', 'rb') as file:\n",
    "    scaler = pickle.load(file)\n",
    "# 'label_encoder.h5'\n",
    "with h5py.File('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/label encoder/label_encoder.h5', 'r') as hf:\n",
    "    label_encoder_classes = hf['label_encoder'][:]\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DUUCveKvEzKh",
    "outputId": "f750536a-0cdc-4be6-efd3-8d0181102a32"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def extract_last_hidden_state(embeddings):\n",
    "    return embeddings[:, -1, :]\n",
    "\n",
    "def tokenize_and_get_embeddings(column):\n",
    "    # Tokenize text\n",
    "    if isinstance(column, str):\n",
    "        tokenized_text = tokenizer(column, padding=True, truncation=True, return_tensors='tf')\n",
    "    elif isinstance(column, list) and all(isinstance(item, str) for item in column):\n",
    "        tokenized_text = tokenizer(column, padding=True, truncation=True, return_tensors='tf')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid input format.\")\n",
    "\n",
    "    outputs = model(tokenized_text)\n",
    "    embeddings = outputs.last_hidden_state.numpy()\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def prepare_input(user_input, scaler, encoder, categorical_columns):\n",
    "\n",
    "    user_input['name'] = normalize_text(user_input['name'])\n",
    "    user_input['description'] = normalize_text(user_input['description'])\n",
    "\n",
    "    name_embeddings = tokenize_and_get_embeddings(user_input['name'])\n",
    "    description_embeddings = tokenize_and_get_embeddings(user_input['description'])\n",
    "    extracted_name_hidden = extract_last_hidden_state(name_embeddings)\n",
    "    extracted_description_hidden = extract_last_hidden_state(description_embeddings)\n",
    "    scaled_price = scaler.transform([[user_input['price']]])[0, 0]\n",
    "\n",
    "    encoded_user_input = [[user_input[column]] for column in categorical_columns]\n",
    "    encoded_user_input = np.array(encoded_user_input).reshape(1, -1)\n",
    "    encoded_categorical_features = encoder.transform(encoded_user_input)\n",
    "    print(encoded_categorical_features.shape)\n",
    "\n",
    "    combined_features = hstack([encoded_categorical_features, np.array([[scaled_price]])])\n",
    "    print(combined_features.shape)\n",
    "    num_cat_input_array = combined_features.toarray().astype(np.float32)\n",
    "    final_input_array = np.concatenate((num_cat_input_array,extracted_name_hidden,extracted_description_hidden), axis=1)\n",
    "\n",
    "    return extracted_name_hidden, extracted_description_hidden, final_input_array, scaled_price"
   ],
   "metadata": {
    "id": "X2j9QTR5E29g"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "extracted_name_hidden, extracted_description_hidden, final_input_array, scaled_price = prepare_input(user_input, scaler, encoder, categorical_columns)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vmg7B-K9FFIw",
    "outputId": "28a171a5-7fa2-45d9-84bf-f97bf6445b3a"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 2195)\n",
      "(1, 2196)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def predict_model_1(final_input_array, model_1):\n",
    "    predictions = model_1.predict(final_input_array)\n",
    "    subcategory_pred_labels = np.argmax(predictions, axis=1)\n",
    "    print(predictions)\n",
    "    print(subcategory_pred_labels)\n",
    "    return subcategory_pred_labels\n",
    "\n",
    "def compare_predictions(subcategory_pred_labels, label_encoder_classes):\n",
    "    predicted_labels = []\n",
    "    for idx in subcategory_pred_labels:\n",
    "        if idx < len(label_encoder_classes):\n",
    "            predicted_labels.append(label_encoder_classes[idx])\n",
    "        else:\n",
    "            predicted_labels.append('unknown')\n",
    "    return predicted_labels"
   ],
   "metadata": {
    "id": "vDH0-fs0FHWP"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "predicted_labels = predict_model_1(final_input_array, model_1)\n",
    "predicted_labels_2 = compare_predictions(predicted_labels, label_encoder_classes)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rhE7-FtaFKzJ",
    "outputId": "d560ab00-2bf9-4637-ef3a-88b8617fc079"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 289ms/step\n",
      "[[1.0994968e-04 7.9649151e-04 1.2140860e-03 5.3583179e-02 1.4598008e-03\n",
      "  2.5725579e-03 2.2873802e-03 1.0619973e-01 4.3067613e-04 3.0624733e-04\n",
      "  1.6319037e-04 8.6571947e-03 3.8944132e-04 9.3414586e-05 1.3874416e-04\n",
      "  2.9502739e-03 7.7835256e-01 5.2608363e-04 9.0454130e-05 3.6915749e-02\n",
      "  9.8234147e-04 7.8012527e-04 1.0003197e-03]]\n",
      "[16]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(predicted_labels_2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHzPfAlIFQU2",
    "outputId": "4b0093e5-d776-4f79-a7fd-a067225405c4"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[b'Musical Instruments']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predic 2: 'sub_category_1'"
   ],
   "metadata": {
    "id": "48s9C0ciLbbR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 'model_2_preberttune.h5'\n",
    "model_2 = load_model('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/models/model_2_preberttune.h5')\n",
    "# decode previous output of prediction 1\n",
    "decoded_labels = [label.decode() for label in predicted_labels_2]\n",
    "# 'encoder_1.pkl'\n",
    "with open('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/encoder/encoder_1.pkl', 'rb') as file:\n",
    "    encoder_1 = pickle.load(file)\n",
    "# 'scaler_1.pkl'\n",
    "with open('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/scaler/scaler_1.pkl', 'rb') as file:\n",
    "    scaler_1 = pickle.load(file)\n",
    "\n",
    "\n",
    "def prepare_input_2(user_input, encoder_1, decoded_labels, scaler_1):\n",
    "\n",
    "\n",
    "    user_input['name'] = normalize_text(user_input['name'])\n",
    "    user_input['description'] = normalize_text(user_input['description'])\n",
    "    name_embeddings = tokenize_and_get_embeddings(user_input['name'])\n",
    "    description_embeddings = tokenize_and_get_embeddings(user_input['description'])\n",
    "    extracted_name_hidden = extract_last_hidden_state(name_embeddings)\n",
    "    extracted_description_hidden = extract_last_hidden_state(description_embeddings)\n",
    "\n",
    "    input_data = np.array([[user_input['type'], user_input['manufacturer']]])\n",
    "    predicted_labels_array = np.array(decoded_labels)[:3].reshape(1, -1)\n",
    "    input_with_labels = np.hstack((input_data, predicted_labels_array))\n",
    "\n",
    "\n",
    "    predicted_labels_one_hot = encoder_1.transform(input_with_labels)\n",
    "\n",
    "\n",
    "    scaled_price_array = scaler_1.transform(np.array(user_input['price']).reshape(-1, 1))\n",
    "\n",
    "    final_input_array_with_label = np.hstack((predicted_labels_one_hot.toarray(), scaled_price_array))\n",
    "    final_input_array_2 = np.concatenate((final_input_array_with_label, extracted_name_hidden, extracted_description_hidden), axis=1)\n",
    "\n",
    "    return final_input_array_2"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ZT_pqtgFQ7t",
    "outputId": "ad02052a-642e-4e44-d7e0-a7ae4e54f201"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator OneHotEncoder from version 1.4.1.post1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.4.1.post1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "final_input_array_with_label_1 = prepare_input_2(user_input, encoder_1, decoded_labels, scaler_1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxSvMLU3FZen",
    "outputId": "a27ed9fb-2e5b-462d-86f7-6a74a0fddb3b"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def predict_model_2(final_input_array_with_label_1, model_2):\n",
    "    predictions_1 = model_2.predict(final_input_array_with_label_1)\n",
    "    subcategory_pred_labels = np.argmax(predictions_1, axis=1)\n",
    "    print(predictions_1)\n",
    "    print(subcategory_pred_labels)\n",
    "    return subcategory_pred_labels\n",
    "\n",
    "def compare_predictions_2(subcategory_pred_labels, label_encoder_classes_1):\n",
    "    predicted_labels = []\n",
    "    for idx in subcategory_pred_labels:\n",
    "        if idx < len(label_encoder_classes_1):\n",
    "            predicted_labels.append(label_encoder_classes_1[idx])\n",
    "        else:\n",
    "            predicted_labels.append('unknown')\n",
    "    return predicted_labels"
   ],
   "metadata": {
    "id": "Ot6v7GeqFcKt"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "final_input_array_with_label_1 = prepare_input_2(user_input, encoder_1, decoded_labels, scaler_1)\n",
    "subcategory_pred_labels = predict_model_2(final_input_array_with_label_1, model_2)\n",
    "predicted_labels_3 = compare_predictions_2(subcategory_pred_labels, label_encoder_classes_1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TnP1GqX9FgJn",
    "outputId": "65bf55c4-a234-434e-8082-eb23722752ce"
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 109ms/step\n",
      "[[1.63322730e-10 9.24247224e-03 3.52612830e-07 7.30372633e-08\n",
      "  4.35859349e-08 7.08782750e-07 6.87059062e-03 4.09882887e-06\n",
      "  1.12313048e-08 3.46122597e-09 1.76686399e-09 2.39322901e-07\n",
      "  5.70962388e-09 1.80817409e-07 6.87435772e-07 1.27569191e-08\n",
      "  3.55181925e-07 1.35334830e-07 2.00965715e-08 2.15664699e-07\n",
      "  2.29864156e-07 3.34467423e-08 2.48789860e-08 5.68401374e-05\n",
      "  7.94910375e-05 7.86217740e-08 1.82330087e-02 5.10007752e-08\n",
      "  1.19414352e-07 2.87019777e-08 4.65168704e-08 4.69537476e-08\n",
      "  5.82247600e-03 1.75301966e-06 5.02646287e-07 7.00657381e-07\n",
      "  1.50596432e-03 4.69041822e-07 2.50505946e-06 1.17480567e-08\n",
      "  1.11170471e-06 7.92985873e-08 1.35558439e-05 5.65360324e-07\n",
      "  1.64734456e-03 3.64446691e-07 3.41789018e-06 7.12557338e-08\n",
      "  4.79635275e-07 5.17396393e-06 1.27256430e-06 7.21144886e-07\n",
      "  4.11295076e-07 8.51561141e-04 2.08846610e-02 2.78479860e-07\n",
      "  8.94914422e-07 1.16796059e-07 1.33506688e-07 4.09294665e-02\n",
      "  1.15968897e-08 9.35552578e-08 1.35986173e-08 4.83558495e-07\n",
      "  7.24044800e-01 6.51390110e-07 4.42501317e-07 1.83487003e-07\n",
      "  1.82549009e-09 1.65421875e-06 1.19276528e-05 2.34837717e-05\n",
      "  5.08851485e-08 4.52519970e-07 3.98442438e-07 2.81367124e-06\n",
      "  6.57591528e-08 4.35007820e-07 4.84528812e-07 2.64796171e-07\n",
      "  2.00512409e-06 5.02902742e-09 1.70545107e-07 1.47740975e-01\n",
      "  3.87765567e-06 5.45856728e-11 1.53588395e-08 2.47101212e-07\n",
      "  1.69825424e-02 2.12831992e-07 7.80518803e-07 1.91509053e-09\n",
      "  1.17003811e-08 2.55124419e-08 5.33598374e-08 2.45681930e-11\n",
      "  9.36889109e-08 1.27148348e-06 7.43257772e-07 9.15906817e-09\n",
      "  3.04382873e-11 9.04865516e-08 3.46210618e-06 1.19937980e-07\n",
      "  3.46770548e-07 5.53431050e-07 1.21398489e-06 1.67188671e-06\n",
      "  1.12889975e-05 1.05074248e-10 4.86712217e-08 4.58297289e-10\n",
      "  4.99198632e-03 1.01267437e-06]]\n",
      "[64]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(predicted_labels_3)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lKgnp-MFiyJ",
    "outputId": "c0c77b64-7b7f-48a7-e312-bde07a4ac186"
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[b' Musical Instrument Accessories']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predic 3: 'sub_category_2'"
   ],
   "metadata": {
    "id": "oCsnGwIiLXGW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 'model_3_preberttune.h5'\n",
    "model_3 = load_model('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/models/model_3_preberttune.h5')\n",
    "# decode previous output of prediction 2\n",
    "decoded_labels_2 = [label.decode() for label in predicted_labels_3]\n",
    "# 'encoder_2.pkl'\n",
    "with open('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/encoder/encoder_2.pkl', 'rb') as file:\n",
    "    encoder_2 = pickle.load(file)\n",
    "# 'scaler_2.pkl'\n",
    "with open('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/scaler/scaler_2.pkl', 'rb') as file:\n",
    "    scaler_2 = pickle.load(file)\n",
    "# 'label_encoder_2.h5'\n",
    "with h5py.File('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/label encoder/label_encoder_2.h5', 'r') as hf:\n",
    "    label_encoder_classes_2 = hf['label_encoder_2'][:]\n",
    "\n",
    "def prepare_input_3(user_input, encoder_2, decoded_labels, decoded_labels_2, scaler_2):\n",
    "\n",
    "\n",
    "    user_input['name'] = normalize_text(user_input['name'])\n",
    "    user_input['description'] = normalize_text(user_input['description'])\n",
    "    name_embeddings = tokenize_and_get_embeddings(user_input['name'])\n",
    "    description_embeddings = tokenize_and_get_embeddings(user_input['description'])\n",
    "    extracted_name_hidden = extract_last_hidden_state(name_embeddings)\n",
    "    extracted_description_hidden = extract_last_hidden_state(description_embeddings)\n",
    "\n",
    "    input_data = np.array([[user_input['type'], user_input['manufacturer']]])\n",
    "    predicted_labels_array = np.array(decoded_labels)[:3].reshape(1, -1)\n",
    "    predicted_labels_array_2 = np.array(decoded_labels_2)[:4].reshape(1, -1)\n",
    "    input_with_labels = np.hstack((input_data, predicted_labels_array, predicted_labels_array_2))\n",
    "\n",
    "\n",
    "    predicted_labels_one_hot = encoder_2.transform(input_with_labels)\n",
    "\n",
    "\n",
    "    scaled_price_array = scaler_2.transform(np.array(user_input['price']).reshape(-1, 1))\n",
    "\n",
    "    final_input_array_with_label = np.hstack((predicted_labels_one_hot.toarray(), scaled_price_array))\n",
    "    final_input_array_3 = np.concatenate((final_input_array_with_label, extracted_name_hidden, extracted_description_hidden), axis=1)\n",
    "\n",
    "    return final_input_array_3"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cj56v6-WFlAJ",
    "outputId": "150f552f-f5e0-4759-a612-0a53ddf0e4f9"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator OneHotEncoder from version 1.4.1.post1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.4.1.post1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "final_input_array_with_label_2 = prepare_input_3(user_input, encoder_2, decoded_labels, decoded_labels_2, scaler_2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYK1uCmlFs5Z",
    "outputId": "c5be51a1-0cb5-48aa-f64d-41bb405cc8d3"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def predict_model_3(final_input_array_with_label_2, model_3):\n",
    "    predictions_2 = model_3.predict(final_input_array_with_label_2)\n",
    "    subcategory_pred_labels_2 = np.argmax(predictions_2, axis=1)\n",
    "    print(predictions_2)\n",
    "    print(subcategory_pred_labels_2)\n",
    "    return subcategory_pred_labels_2\n",
    "\n",
    "def compare_predictions_3(subcategory_pred_labels_2, label_encoder_classes_2):\n",
    "    predicted_labels_4 = []\n",
    "    for idx in subcategory_pred_labels_2:\n",
    "        if idx < len(label_encoder_classes_2):\n",
    "            predicted_labels_4.append(label_encoder_classes_2[idx])\n",
    "        else:\n",
    "            predicted_labels_4.append('unknown')\n",
    "    return predicted_labels_4"
   ],
   "metadata": {
    "id": "JVGh865LFvXR"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "subcategory_pred_labels_2 = predict_model_3(final_input_array_with_label_2, model_3)\n",
    "predicted_labels_5 = compare_predictions_2(subcategory_pred_labels_2, label_encoder_classes_2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w7es2ZrIFx-g",
    "outputId": "31d33e61-6102-4140-9ea6-7998aeaf64b4"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 92ms/step\n",
      "[[1.12019552e-06 1.13052090e-06 2.28617523e-06 1.66467203e-06\n",
      "  3.97478580e-05 2.34333293e-05 1.73665001e-04 4.61353702e-05\n",
      "  2.00526702e-05 1.33288677e-05 7.43866758e-06 7.67152869e-07\n",
      "  6.40058033e-08 3.17638069e-06 1.27486419e-04 3.41650463e-07\n",
      "  8.61173188e-10 2.25794633e-06 8.29954515e-05 6.56466881e-10\n",
      "  8.13052594e-08 2.40425805e-07 2.50137532e-07 3.96551094e-08\n",
      "  1.79948056e-05 1.91063009e-06 1.38132627e-05 2.51572255e-05\n",
      "  3.46558352e-07 2.56160274e-05 5.34442916e-06 1.01338571e-06\n",
      "  1.11924726e-06 7.19470336e-05 5.63906553e-07 6.37364923e-04\n",
      "  2.68000131e-05 2.10973269e-07 9.32760315e-07 1.18801909e-05\n",
      "  6.34380115e-07 7.57125918e-08 1.40449138e-05 4.46870551e-03\n",
      "  1.81001560e-05 9.31837076e-06 2.63293913e-07 8.09406675e-09\n",
      "  8.93142442e-06 3.36447641e-07 1.07381766e-06 5.51221601e-05\n",
      "  1.15474954e-08 2.89647105e-05 2.41307293e-06 8.48824754e-07\n",
      "  1.92448806e-06 1.20558934e-06 7.17551643e-07 5.48925209e-06\n",
      "  1.78887944e-08 2.16770495e-08 2.70806072e-06 1.17872993e-07\n",
      "  7.15320202e-05 3.44149917e-08 1.28335230e-07 1.21479871e-07\n",
      "  1.24685175e-06 6.54120242e-08 8.01444955e-08 1.24262226e-06\n",
      "  2.54665139e-07 3.19643938e-08 9.21467563e-06 1.22417950e-05\n",
      "  9.97726020e-05 3.09095213e-07 5.71279513e-09 2.67667531e-07\n",
      "  1.69838799e-07 1.01475941e-07 2.64635310e-06 1.51125477e-07\n",
      "  7.63157743e-07 2.50439734e-05 1.39562646e-04 6.49583171e-07\n",
      "  2.73101505e-05 3.16930323e-06 3.72592609e-07 6.23022629e-07\n",
      "  3.28518800e-04 8.97188954e-08 9.24619741e-08 4.46441773e-05\n",
      "  2.95755046e-04 1.04116109e-04 1.14074783e-06 1.15738226e-06\n",
      "  6.73222928e-07 1.16038263e-01 3.12385993e-04 2.16061162e-04\n",
      "  3.39777253e-05 1.94984182e-06 1.16037295e-08 9.41172289e-07\n",
      "  1.51299755e-04 4.00284407e-05 1.42902181e-05 5.19955574e-05\n",
      "  2.20615475e-04 1.97995818e-04 7.84673466e-06 1.61585473e-02\n",
      "  1.93459144e-07 1.47058466e-03 8.37087209e-05 5.23949154e-07\n",
      "  8.54612153e-05 2.62221800e-08 5.11408434e-05 2.43988034e-05\n",
      "  3.69767877e-05 1.95228012e-07 1.20465738e-04 1.08365718e-07\n",
      "  2.22845374e-05 1.08804170e-05 8.11024421e-08 2.83542613e-06\n",
      "  1.12523441e-03 3.83992017e-07 5.07045456e-07 1.21730205e-04\n",
      "  4.64266225e-09 2.25050371e-06 4.28633143e-07 1.19333208e-07\n",
      "  1.18041230e-08 2.30301303e-05 2.47039179e-06 2.66575720e-04\n",
      "  2.38953053e-05 1.21093251e-06 4.60797719e-06 2.69052862e-07\n",
      "  6.19053026e-06 4.87945862e-02 1.28052707e-05 1.41070461e-06\n",
      "  5.20985965e-09 1.35244172e-05 7.38839208e-06 1.05574654e-05\n",
      "  7.91304899e-07 4.70476408e-07 3.70153502e-05 3.87370019e-05\n",
      "  1.01375690e-06 1.70358380e-05 2.03654906e-08 6.28509383e-07\n",
      "  2.35910065e-05 7.80636947e-06 2.15086053e-04 2.93776765e-02\n",
      "  2.18139339e-05 3.46059505e-06 3.57040705e-07 1.55537748e-07\n",
      "  3.12642698e-07 3.27116322e-05 8.48802131e-07 3.54151052e-05\n",
      "  2.34897932e-04 2.26393965e-07 5.62883429e-02 1.30013195e-05\n",
      "  4.45391197e-06 8.58747808e-05 4.01071957e-05 1.99521128e-06\n",
      "  2.35075277e-07 1.15190301e-06 1.05185322e-07 2.96284473e-08\n",
      "  1.04287167e-07 3.83982659e-08 3.39884143e-09 1.17420780e-06\n",
      "  4.82741707e-05 4.38087918e-05 2.47339867e-05 6.78778888e-05\n",
      "  1.19672268e-05 2.14961062e-07 4.16028934e-06 8.93697134e-08\n",
      "  1.03404420e-06 2.46099185e-09 4.71873682e-06 5.69647469e-04\n",
      "  4.09000307e-07 1.05456170e-02 1.31838431e-06 6.37736619e-08\n",
      "  1.26223760e-08 2.41477895e-08 6.69973815e-05 5.31580336e-05\n",
      "  7.42274040e-07 2.00405665e-07 3.97404847e-06 7.07182380e-06\n",
      "  2.53613805e-04 9.01563271e-06 1.25678912e-06 2.52298776e-07\n",
      "  1.55789985e-05 7.54440748e-07 4.26961662e-07 9.26863140e-06\n",
      "  1.01528167e-06 3.74833326e-05 1.92061489e-05 1.32645255e-07\n",
      "  9.00681041e-09 9.28717654e-08 1.12058763e-06 2.24226028e-06\n",
      "  3.90390516e-04 3.24610755e-06 9.17610232e-05 7.74598175e-06\n",
      "  8.06017511e-07 8.82047880e-06 8.85242059e-07 1.01497535e-05\n",
      "  3.06879269e-06 4.50573374e-08 1.40709941e-08 2.25611227e-08\n",
      "  2.81985194e-05 5.41061308e-05 2.21859659e-06 3.33317502e-07\n",
      "  4.30608634e-06 3.68546367e-08 1.78416258e-07 9.90464969e-07\n",
      "  3.24318648e-06 6.05455944e-06 3.55246048e-05 1.04765309e-06\n",
      "  1.26283499e-03 4.45350196e-07 1.86965990e-05 2.32241428e-06\n",
      "  5.07562390e-06 2.78789012e-05 3.10266955e-06 4.77747017e-06\n",
      "  1.59044350e-06 3.78274103e-06 3.91404683e-05 2.30853789e-06\n",
      "  5.36767232e-07 2.94513768e-07 3.15707221e-05 1.28756539e-04\n",
      "  2.72479345e-04 1.51749737e-06 4.64226019e-07 4.01890384e-06\n",
      "  7.69464137e-08 2.19892058e-06 7.43131334e-10 4.41778713e-04\n",
      "  1.04459323e-04 2.33289165e-06 1.06564144e-07 5.68252988e-04\n",
      "  7.91035930e-08 1.54636669e-04 4.68247526e-06 6.48452124e-06\n",
      "  2.10684135e-07 5.75921906e-04 3.94986855e-05 7.62296040e-08\n",
      "  6.74398223e-07 1.56009737e-05 2.89814398e-06 4.13731849e-09\n",
      "  2.10887083e-06 1.27481126e-05 4.85451892e-06 1.08572043e-04\n",
      "  2.65366325e-05 3.45250874e-06 1.41644763e-04 1.66047570e-07\n",
      "  2.04653020e-07 4.91149258e-05 7.97709232e-10 1.39951467e-07\n",
      "  1.38016603e-07 4.43114812e-04 4.34697949e-06 5.51467383e-06\n",
      "  7.52377900e-07 1.71355410e-07 5.69651820e-05 2.19374670e-08\n",
      "  3.21803411e-04 4.52296808e-06 1.36438857e-05 1.32505429e-05\n",
      "  3.61940238e-08 2.47439624e-09 2.44063995e-06 9.68335456e-08\n",
      "  3.87288383e-05 7.32501121e-06 2.59583732e-09 3.54840850e-08\n",
      "  3.93065136e-07 6.09502194e-07 3.77478409e-06 1.20099105e-06\n",
      "  3.97682561e-05 2.00554823e-05 2.20344227e-04 2.55954183e-05\n",
      "  4.32431480e-05 2.81512393e-06 2.42800138e-06 1.23902612e-06\n",
      "  6.62630464e-06 1.41066621e-07 1.37377883e-05 7.30804868e-06\n",
      "  1.08000485e-07 4.87012267e-06 2.16840385e-06 6.60098493e-01\n",
      "  4.26042676e-02]]\n",
      "[347]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(predicted_labels_5)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Kg-BVXXF0FY",
    "outputId": "a9e78f6d-ead8-4ab0-e221-f7908f58aae9"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[b'missing']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predic 4: 'sub_category_3'"
   ],
   "metadata": {
    "id": "KF6s-VJuOTzH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 'model_4_preberttune.h5'\n",
    "model_4 = load_model('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/models/model_4_preberttune.h5')\n",
    "# decode previous output of prediction 3\n",
    "decoded_labels_3 = [label.decode() for label in predicted_labels_5]\n",
    "# 'encoder_3.pkl'\n",
    "with open('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/encoder/encoder_3.pkl', 'rb') as file:\n",
    "    encoder_3 = pickle.load(file)\n",
    "# 'scaler_3.pkl'\n",
    "with open('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/scaler/scaler_3.pkl', 'rb') as file:\n",
    "    scaler_3 = pickle.load(file)\n",
    "# 'label_encoder_3.h5'\n",
    "with h5py.File('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/label encoder/label_encoder_3.h5', 'r') as hf:\n",
    "    label_encoder_classes_3 = hf['label_encoder_3'][:]\n",
    "\n",
    "def prepare_input_4(user_input, encoder_3, decoded_labels, decoded_labels_2, decoded_labels_3, scaler_3):\n",
    "\n",
    "\n",
    "    user_input['name'] = normalize_text(user_input['name'])\n",
    "    user_input['description'] = normalize_text(user_input['description'])\n",
    "    name_embeddings = tokenize_and_get_embeddings(user_input['name'])\n",
    "    description_embeddings = tokenize_and_get_embeddings(user_input['description'])\n",
    "    extracted_name_hidden = extract_last_hidden_state(name_embeddings)\n",
    "    extracted_description_hidden = extract_last_hidden_state(description_embeddings)\n",
    "\n",
    "    input_data = np.array([[user_input['type'], user_input['manufacturer']]])\n",
    "    predicted_labels_array = np.array(decoded_labels)[:3].reshape(1, -1)\n",
    "    predicted_labels_array_2 = np.array(decoded_labels_2)[:4].reshape(1, -1)\n",
    "    predicted_labels_array_3 = np.array(decoded_labels_3)[:5].reshape(1, -1)\n",
    "    input_with_labels = np.hstack((input_data, predicted_labels_array, predicted_labels_array_2, predicted_labels_array_3))\n",
    "\n",
    "\n",
    "    predicted_labels_one_hot = encoder_3.transform(input_with_labels)\n",
    "\n",
    "\n",
    "    scaled_price_array = scaler_3.transform(np.array(user_input['price']).reshape(-1, 1))\n",
    "\n",
    "    final_input_array_with_label = np.hstack((predicted_labels_one_hot.toarray(), scaled_price_array))\n",
    "    final_input_array_4 = np.concatenate((final_input_array_with_label, extracted_name_hidden, extracted_description_hidden), axis=1)\n",
    "\n",
    "    return final_input_array_4"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Av0go0pVF2TH",
    "outputId": "d563ac5a-7acf-42da-8354-d1ee4b985706"
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator OneHotEncoder from version 1.4.1.post1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.4.1.post1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "final_input_array_with_label_3 = prepare_input_4(user_input, encoder_3, decoded_labels, decoded_labels_2, decoded_labels_3, scaler_3)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5msk-s97F9Ra",
    "outputId": "782e1186-a5ba-484d-8163-8e7784fff4f6"
   },
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def predict_model_4(final_input_array_with_label_3, model_4):\n",
    "    predictions_3 = model_4.predict(final_input_array_with_label_3)\n",
    "    subcategory_pred_labels_3 = np.argmax(predictions_3, axis=1)\n",
    "    print(predictions_3)\n",
    "    print(subcategory_pred_labels_3)\n",
    "    return subcategory_pred_labels_3\n",
    "\n",
    "def compare_predictions_3(subcategory_pred_labels_3, label_encoder_classes_3):\n",
    "    predicted_labels_6 = []\n",
    "    for idx in label_encoder_classes_3:\n",
    "        if idx < len(label_encoder_classes_3):\n",
    "            predicted_labels_6.append(label_encoder_classes_3[idx])\n",
    "        else:\n",
    "            predicted_labels_6.append('unknown')\n",
    "    return predicted_labels_6"
   ],
   "metadata": {
    "id": "8XaUrLRKF_5L"
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "subcategory_pred_labels_3 = predict_model_4(final_input_array_with_label_3, model_4)\n",
    "predicted_labels_7 = compare_predictions_2(subcategory_pred_labels_3, label_encoder_classes_3)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "idqXdE2VGDha",
    "outputId": "fddc72d0-6bfe-4407-9868-8879876543c4"
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 120ms/step\n",
      "[[1.22693189e-10 1.73246389e-10 1.61119132e-10 5.56444668e-10\n",
      "  2.25295310e-10 2.23974051e-13 3.55915436e-10 2.07534558e-08\n",
      "  1.84050509e-06 1.07475469e-08 3.33443779e-08 2.27218067e-08\n",
      "  4.77060023e-11 9.14231883e-15 1.19763585e-12 1.66595185e-13\n",
      "  2.65424644e-11 4.40834903e-11 3.04344688e-10 1.49374380e-08\n",
      "  2.28899510e-10 2.12920778e-10 2.03017914e-09 5.43238565e-10\n",
      "  1.04970837e-07 1.55666147e-08 4.82114799e-11 6.73179637e-11\n",
      "  8.42902192e-10 1.68191822e-10 6.20664381e-13 2.79229667e-10\n",
      "  1.82920890e-09 2.64439790e-11 4.45659926e-10 1.16489574e-09\n",
      "  9.34191405e-11 7.98367381e-08 3.70771053e-10 1.52366487e-11\n",
      "  8.80752971e-10 1.66445843e-10 6.32769187e-14 4.14509005e-09\n",
      "  3.07556633e-13 7.27202187e-11 8.21347417e-12 9.61033544e-11\n",
      "  7.48349679e-14 5.05397529e-11 1.82542981e-10 2.10754591e-11\n",
      "  1.42282011e-11 7.69992820e-11 2.20529519e-12 5.03492060e-07\n",
      "  1.48841617e-09 1.46257811e-10 3.53652929e-08 1.48522006e-09\n",
      "  1.14419021e-12 3.40197759e-10 1.15083351e-11 2.94900682e-09\n",
      "  1.87292500e-07 4.22869042e-13 2.49936916e-09 6.47723303e-13\n",
      "  9.46826439e-09 2.89341034e-11 7.09283543e-13 2.61845441e-11\n",
      "  1.69098680e-09 3.17379178e-11 2.33650113e-11 2.70758540e-13\n",
      "  1.91718003e-10 3.31516724e-11 1.29593808e-10 9.91815657e-12\n",
      "  6.87093576e-11 1.31613262e-10 3.91274818e-10 1.47985148e-11\n",
      "  3.50750512e-10 3.56271501e-09 8.40961647e-08 5.67835235e-14\n",
      "  2.61332553e-11 1.53023672e-09 1.37829179e-12 1.64013647e-09\n",
      "  2.47876155e-08 2.56758277e-08 1.00673005e-10 8.30679723e-14\n",
      "  2.46496878e-10 4.60882305e-10 5.50396283e-14 5.09197268e-11\n",
      "  4.55297997e-15 5.70940734e-12 5.45313957e-13 2.23372543e-09\n",
      "  5.10384478e-11 3.22814220e-10 2.08394704e-10 7.78217490e-09\n",
      "  1.23004233e-12 5.55028246e-11 1.02425135e-09 1.05916116e-10\n",
      "  4.22050546e-12 1.45110075e-08 1.13865841e-08 1.05517381e-08\n",
      "  4.11319895e-10 4.88212581e-09 7.07037684e-12 3.87131218e-13\n",
      "  1.10633747e-09 1.81915460e-08 6.51683651e-10 3.20202503e-10\n",
      "  3.34615891e-09 3.99873412e-14 4.80649687e-10 9.02990926e-09\n",
      "  3.40719203e-10 3.99249481e-13 3.45897859e-11 7.12432613e-11\n",
      "  2.24109308e-11 1.29402988e-12 6.48066656e-10 3.32709027e-10\n",
      "  4.77274165e-10 5.95383798e-10 1.70965819e-08 1.39114287e-09\n",
      "  2.23369234e-08 1.65093006e-09 9.16982029e-12 5.63765756e-10\n",
      "  3.33711149e-11 6.68417231e-12 1.51534330e-12 3.08596149e-09\n",
      "  5.16480803e-10 9.30077335e-11 1.43734902e-09 7.98946260e-08\n",
      "  1.37154426e-12 6.41162679e-11 8.24980535e-12 3.18484972e-09\n",
      "  6.37968758e-12 1.06786689e-11 7.93602406e-10 1.79125340e-10\n",
      "  4.52461766e-12 5.85194782e-10 7.89594917e-11 4.24198708e-13\n",
      "  2.75123657e-09 5.55834198e-12 5.79415422e-12 8.32821173e-11\n",
      "  1.04288115e-11 2.98571159e-08 7.20041093e-09 1.10763820e-09\n",
      "  2.38627174e-12 1.77184392e-10 5.96838759e-11 6.89109464e-11\n",
      "  8.32620986e-11 1.75179360e-09 6.29910568e-10 6.01795858e-09\n",
      "  2.40850397e-08 8.74333592e-11 1.07673155e-10 7.40666461e-09\n",
      "  1.12351697e-10 2.34750414e-10 2.33933073e-09 5.04704405e-13\n",
      "  1.52650310e-12 1.28458171e-12 7.07508185e-09 8.09246628e-11\n",
      "  4.77731410e-10 2.33542824e-10 7.17705340e-11 9.55413457e-11\n",
      "  3.23298957e-11 1.48629188e-12 9.60669586e-13 2.85987856e-09\n",
      "  3.41705164e-10 2.42791360e-11 9.58952140e-10 2.75937162e-09\n",
      "  3.39747605e-11 3.96634357e-11 1.35708206e-07 1.50666715e-10\n",
      "  1.18239299e-11 9.67203054e-11 1.26371336e-09 9.28850538e-11\n",
      "  1.50631504e-12 7.76741560e-10 4.00647598e-10 2.73710332e-10\n",
      "  1.93799021e-09 1.15515608e-09 3.86628880e-12 1.67878200e-12\n",
      "  1.35456316e-11 3.31010908e-13 5.08046512e-08 5.47376762e-11\n",
      "  9.04164077e-10 1.22741872e-10 1.85336035e-09 9.31961068e-08\n",
      "  3.30794615e-12 6.18527807e-09 1.07363285e-10 1.29236300e-11\n",
      "  1.80680332e-11 2.02062629e-12 2.74222950e-10 2.61257932e-10\n",
      "  3.71659474e-11 2.40932413e-10 1.31269551e-10 1.68300596e-10\n",
      "  3.20218518e-09 3.83303084e-10 1.86117854e-09 1.90847407e-11\n",
      "  2.24004166e-11 1.77341128e-08 2.00048593e-12 3.09719645e-08\n",
      "  4.47954340e-09 9.86801574e-09 7.85526311e-09 1.50989499e-10\n",
      "  2.42035503e-10 2.55402616e-10 4.66573946e-10 1.84281285e-10\n",
      "  2.33709940e-10 1.97108458e-11 1.20653624e-07 3.65553334e-12\n",
      "  3.20776287e-11 9.00656794e-09 2.27341826e-10 9.39201841e-13\n",
      "  6.50170347e-13 2.39301023e-10 8.63790484e-13 7.22429894e-11\n",
      "  3.02060182e-11 5.55613466e-09 1.82477362e-12 1.52436197e-08\n",
      "  1.70753377e-11 2.45035004e-12 6.14345543e-13 5.07617148e-09\n",
      "  2.17497154e-09 3.04014057e-13 2.44603752e-14 1.49779755e-12\n",
      "  1.37453704e-09 2.54011118e-11 5.31005378e-15 2.10426537e-10\n",
      "  6.45752757e-11 4.83189433e-10 1.37505185e-06 3.60736413e-10\n",
      "  9.70440155e-08 4.05986994e-10 1.60405067e-09 2.60574406e-08\n",
      "  9.40504785e-10 2.57937033e-10 1.89782721e-11 4.18983098e-10\n",
      "  7.09005632e-11 6.11724182e-09 1.93212356e-11 6.05171260e-11\n",
      "  1.54183047e-12 2.89695559e-11 7.20260171e-11 1.62545255e-09\n",
      "  9.52549428e-11 1.06207633e-10 3.98853346e-11 1.26668631e-09\n",
      "  4.20047302e-10 3.10089177e-11 2.94880986e-09 1.71520398e-08\n",
      "  3.40729134e-09 1.31372422e-11 9.99989152e-01 5.38864560e-06]]\n",
      "[314]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(predicted_labels_7)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdOeERVSGEcT",
    "outputId": "7fa774c6-3654-4ccd-f25f-6371f0a39d5c"
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[b'missing']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict 5: 'sub_category_4'"
   ],
   "metadata": {
    "id": "2CD6t65rzFHi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 'model_5_preberttune.h5'\n",
    "model_5 = load_model('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/models/model_5_preberttune.h5')\n",
    "# decode previous output of prediction 4\n",
    "decoded_labels_4 = [label.decode() for label in predicted_labels_7]\n",
    "# 'encoder_4.pkl'\n",
    "with open('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/encoder/encoder_4.pkl', 'rb') as file:\n",
    "    encoder_4 = pickle.load(file)\n",
    "# 'scaler_4.pkl'\n",
    "with open('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/scaler/scaler_4.pkl', 'rb') as file:\n",
    "    scaler_4 = pickle.load(file)\n",
    "# 'label_encoder_4.h5'\n",
    "with h5py.File('/content/drive/MyDrive/prueba_encoder/predic_model_1/final/label encoder/label_encoder_4.h5', 'r') as hf:\n",
    "    label_encoder_classes_4 = hf['label_encoder_4'][:]\n",
    "\n",
    "def prepare_input_5(user_input, encoder_4, decoded_labels, decoded_labels_2, decoded_labels_3, decoded_labels_4, scaler_4):\n",
    "\n",
    "\n",
    "    user_input['name'] = normalize_text(user_input['name'])\n",
    "    user_input['description'] = normalize_text(user_input['description'])\n",
    "    name_embeddings = tokenize_and_get_embeddings(user_input['name'])\n",
    "    description_embeddings = tokenize_and_get_embeddings(user_input['description'])\n",
    "    extracted_name_hidden = extract_last_hidden_state(name_embeddings)\n",
    "    extracted_description_hidden = extract_last_hidden_state(description_embeddings)\n",
    "\n",
    "    input_data = np.array([[user_input['type'], user_input['manufacturer']]])\n",
    "    predicted_labels_array = np.array(decoded_labels)[:3].reshape(1, -1)\n",
    "    predicted_labels_array_2 = np.array(decoded_labels_2)[:4].reshape(1, -1)\n",
    "    predicted_labels_array_3 = np.array(decoded_labels_3)[:5].reshape(1, -1)\n",
    "    predicted_labels_array_4 = np.array(decoded_labels_4)[:6].reshape(1, -1)\n",
    "    input_with_labels = np.hstack((input_data, predicted_labels_array, predicted_labels_array_2, predicted_labels_array_3, predicted_labels_array_4))\n",
    "\n",
    "\n",
    "    predicted_labels_one_hot = encoder_4.transform(input_with_labels)\n",
    "\n",
    "\n",
    "    scaled_price_array = scaler_4.transform(np.array(user_input['price']).reshape(-1, 1))\n",
    "\n",
    "    final_input_array_with_label = np.hstack((predicted_labels_one_hot.toarray(), scaled_price_array))\n",
    "    final_input_array_5 = np.concatenate((final_input_array_with_label, extracted_name_hidden, extracted_description_hidden), axis=1)\n",
    "\n",
    "    return final_input_array_5"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "veZjcLSVGKnC",
    "outputId": "26bb44eb-1131-4796-8c82-b4de5aff07ee"
   },
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator OneHotEncoder from version 1.4.1.post1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.4.1.post1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "final_input_array_with_label_4 = prepare_input_5(user_input, encoder_4, decoded_labels, decoded_labels_2, decoded_labels_3, decoded_labels_4, scaler_4)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gT2RONUYGNnz",
    "outputId": "426dcb34-0347-457d-e2a5-296f54d664ec"
   },
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def predict_model_5(final_input_array_with_label_4, model_5):\n",
    "    predictions_4 = model_5.predict(final_input_array_with_label_4)\n",
    "    subcategory_pred_labels_4 = np.argmax(predictions_4, axis=1)\n",
    "    print(predictions_4)\n",
    "    print(subcategory_pred_labels_4)\n",
    "    return subcategory_pred_labels_4\n",
    "\n",
    "def compare_predictions_4(subcategory_pred_labels_4, label_encoder_classes_4):\n",
    "    predicted_labels_8 = []\n",
    "    for idx in label_encoder_classes_4:\n",
    "        if idx < len(label_encoder_classes_4):\n",
    "            predicted_labels_8.append(label_encoder_classes_4[idx])\n",
    "        else:\n",
    "            predicted_labels_8.append('unknown')\n",
    "    return predicted_labels_8"
   ],
   "metadata": {
    "id": "T50eFOwOGP2i"
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "subcategory_pred_labels_4 = predict_model_4(final_input_array_with_label_4, model_5)\n",
    "predicted_labels_9 = compare_predictions_2(subcategory_pred_labels_4, label_encoder_classes_4)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3GZ8tIKGTeh",
    "outputId": "db1da55c-daad-4113-c41d-567fe56b3a24"
   },
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x79065db812d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 107ms/step\n",
      "[[4.53251978e-08 2.55513233e-09 9.76024861e-09 2.58665450e-11\n",
      "  3.81413727e-08 2.76196772e-08 7.91640850e-11 8.96482055e-11\n",
      "  9.23418217e-11 1.93440073e-08 3.39417427e-09 4.16434830e-07\n",
      "  8.83128237e-09 1.55097926e-08 5.09740528e-10 1.81329485e-09\n",
      "  2.43397295e-07 9.67605502e-06 1.25408883e-09 1.27100497e-10\n",
      "  1.49762425e-10 3.67749102e-08 9.17367085e-11 3.39476017e-11\n",
      "  4.32860969e-11 3.76030833e-08 2.40257023e-08 1.73815684e-09\n",
      "  6.51794267e-07 1.02076809e-08 1.05980034e-08 1.91903968e-08\n",
      "  2.13211759e-09 1.87655439e-06 3.24516081e-10 7.73781306e-09\n",
      "  1.08735094e-07 3.37322337e-10 8.47575066e-11 2.56696331e-09\n",
      "  2.93560398e-09 9.89183135e-09 2.43740694e-10 2.09551682e-10\n",
      "  1.49164392e-09 1.56300661e-08 1.19633597e-07 1.42755002e-10\n",
      "  4.67189953e-10 1.57908728e-10 7.18361370e-10 1.92163929e-09\n",
      "  8.32278080e-10 4.86628848e-10 2.37782007e-08 2.67114082e-08\n",
      "  1.55833166e-10 1.32631666e-08 5.25088728e-09 1.11956111e-10\n",
      "  5.77618531e-09 8.17259871e-10 2.30533392e-09 1.87989047e-09\n",
      "  1.39467507e-10 6.85822510e-09 3.03099341e-08 3.59691619e-08\n",
      "  3.83403809e-10 2.69811036e-08 8.29231439e-09 2.86882114e-05\n",
      "  1.98303951e-09 3.66501283e-08 4.19683168e-08 2.45915371e-10\n",
      "  1.50328500e-10 1.39808415e-10 1.78276638e-09 2.80655166e-10\n",
      "  3.49988738e-07 7.54868346e-09 8.72943523e-11 2.08810902e-09\n",
      "  1.44661557e-11 3.99844513e-09 2.18148074e-07 6.05968331e-10\n",
      "  1.56606686e-10 3.44914722e-11 1.96507588e-09 3.25103361e-10\n",
      "  5.19551646e-09 2.15201079e-09 6.93241375e-09 5.23538123e-11\n",
      "  5.20412949e-11 1.81429218e-08 2.33403474e-09 5.31723332e-09\n",
      "  1.72731007e-09 2.14633616e-10 6.25341792e-11 3.34892669e-10\n",
      "  1.04657616e-09 1.61656417e-11 2.01080153e-09 5.08911524e-11\n",
      "  1.38226597e-09 1.84051927e-07 1.22852603e-10 8.36682168e-10\n",
      "  1.88420071e-10 1.68238576e-10 6.03005468e-09 8.29674889e-08\n",
      "  5.38519264e-11 4.25117896e-09 6.39440723e-10 1.78252760e-10\n",
      "  2.78467360e-10 2.24650257e-10 1.40233788e-11 9.71548064e-10\n",
      "  4.91872265e-10 5.05314945e-09 1.36301470e-10 9.09055609e-10\n",
      "  5.52627739e-08 1.05797905e-11 1.40501388e-09 2.90667757e-08\n",
      "  4.33183729e-08 2.29386399e-09 1.27751747e-08 2.56779700e-08\n",
      "  2.17730195e-10 1.46025689e-08 1.05423394e-08 7.15788651e-10\n",
      "  1.51837987e-09 2.39025191e-08 1.35622291e-10 4.15133243e-08\n",
      "  1.45310186e-09 3.05245634e-10 1.89085125e-09 2.40928277e-09\n",
      "  1.03247961e-08 1.03834841e-09 2.91355340e-09 1.40004159e-08\n",
      "  6.74655620e-09 2.07571982e-09 5.41766099e-09 5.64184210e-09\n",
      "  8.71588441e-07 3.00965576e-06 4.11929386e-06 7.29563317e-06\n",
      "  9.99939084e-01 1.87896842e-06]]\n",
      "[160]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(predicted_labels_9)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N-MwCfpzGVgZ",
    "outputId": "46e06054-756f-4abc-b1b9-7afe814968c2"
   },
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[b'missing']\n"
     ]
    }
   ]
  }
 ]
}
